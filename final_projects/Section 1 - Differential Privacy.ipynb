{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Project:\n",
    "\n",
    "For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:31:59.905424Z",
     "start_time": "2019-06-22T14:31:57.274111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:32:00.069565Z",
     "start_time": "2019-06-22T14:31:59.909357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 60000\n",
      "Test Set Size: 10000\n",
      "\n",
      "Min Data Value: tensor(0, dtype=torch.uint8)\n",
      "Max Data Value: tensor(255, dtype=torch.uint8)\n",
      "\n",
      "Train Label Counts: {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test Label Counts: {0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset  = datasets.MNIST(root='../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset.true_targets = mnist_testset.targets.clone() # data points that are considered \"unlabeled\" will be re-labeled by teachers later\n",
    "\n",
    "print(\"Training Set Size:\", len(mnist_trainset))\n",
    "print(\"Test Set Size:\", len(mnist_testset))\n",
    "print()\n",
    "print(\"Min Data Value:\", torch.min(mnist_trainset.data.min(), mnist_testset.data.min()))\n",
    "print(\"Max Data Value:\", torch.max(mnist_trainset.data.max(), mnist_testset.data.max()))\n",
    "print()\n",
    "print(\"Train Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_trainset.targets, return_counts=True))})\n",
    "print(\"Test Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_testset.targets, return_counts=True))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:32:00.087915Z",
     "start_time": "2019-06-22T14:32:00.072541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each teacher dataset: 240\n",
      "Size of the dataset available to the student: 9000\n",
      "Size of the test dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "n_teachers = 250\n",
    "\n",
    "_teacher_dataset_len = len(mnist_trainset) // n_teachers\n",
    "\n",
    "teacher_datasets = [data.Subset(mnist_trainset, list(range(i*_teacher_dataset_len, (i+1)*_teacher_dataset_len))) for i in range(n_teachers)]\n",
    "student_dataset  = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9))))\n",
    "test_dataset     = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9), len(mnist_testset))))\n",
    "\n",
    "print(\"Size of each teacher dataset:\", _teacher_dataset_len)\n",
    "print(\"Size of the dataset available to the student:\", len(student_dataset))\n",
    "print(\"Size of the test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:32:01.243058Z",
     "start_time": "2019-06-22T14:32:01.231682Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        # 1x28x28\n",
    "        self.bn0        = nn.BatchNorm2d(1)\n",
    "        self.conv0      = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.bn1        = nn.BatchNorm2d(5)\n",
    "        self.maxpool0   = nn.MaxPool2d(2)\n",
    "        # 5x14x14\n",
    "        self.conv1      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn2        = nn.BatchNorm2d(5)\n",
    "        self.maxpool1   = nn.MaxPool2d(2)\n",
    "        # 5x 7x 7\n",
    "        self.conv2      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn3        = nn.BatchNorm2d(5)\n",
    "        self.maxpool2   = nn.MaxPool2d(2, padding=1)\n",
    "        # 5x 4x 4 = 80\n",
    "        self.fc         = nn.Linear(80, 10)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(self.bn0(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.fc(x.view(-1, 80))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Teacher & DF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:32:05.466065Z",
     "start_time": "2019-06-22T14:32:01.958863Z"
    }
   },
   "outputs": [],
   "source": [
    "teachers      = [MNISTClassifier().to(device) for _ in range(n_teachers)]\n",
    "student       = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:38:26.106988Z",
     "start_time": "2019-06-22T14:32:07.293422Z"
    },
    "code_folding": [
     12
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9             \n",
      "    Avg Losses: [2.21073, 2.23919, 2.28086, 2.15874, 2.23866, 2.31621, 2.30713, 2.18633, 2.1743, 2.16536, 2.21159, 2.13759, 2.29504, 2.13437, 2.26481, 2.26822, 2.36746, 1.982, 2.2323, 2.13046, 2.18558, 2.3023, 2.18393, 2.23326, 2.22305, 2.19719, 2.31659, 2.25757, 2.18945, 2.30273, 2.24863, 2.29796, 2.19766, 2.19736, 2.23516, 2.10273, 2.25671, 2.16018, 2.15332, 2.15617, 2.16629, 2.16903, 2.29991, 2.15375, 2.35322, 2.26402, 2.16145, 2.11861, 1.9837, 2.22307, 2.18739, 2.1666, 2.20664, 2.20077, 2.16129, 2.13993, 2.22303, 2.21677, 2.25294, 2.318, 2.30551, 2.1139, 2.02318, 2.24366, 2.12847, 2.18998, 2.38609, 2.24913, 2.11516, 2.1852, 2.28901, 2.16478, 2.27972, 2.20896, 2.18185, 2.15838, 2.26615, 2.29928, 1.90267, 2.15768, 2.23865, 2.09571, 2.17137, 2.01474, 2.18474, 2.08203, 2.26916, 2.14139, 2.13376, 2.00431, 2.27429, 2.25236, 2.2412, 2.15806, 2.06265, 2.15356, 2.22228, 2.06031, 2.17198, 2.18582, 2.32406, 2.3228, 2.16512, 2.31682, 2.1459, 2.20135, 2.27286, 2.17005, 2.24154, 2.33773, 2.09488, 2.32376, 2.29292, 2.13337, 2.168, 2.31548, 2.10926, 2.1934, 2.36461, 2.26305, 2.09429, 2.28596, 2.17563, 2.25983, 2.3113, 2.20922, 2.22492, 2.2454, 2.21729, 2.0837, 2.29063, 2.25299, 2.18992, 2.16562, 2.30043, 2.34616, 2.26113, 2.27231, 2.16817, 2.31263, 2.33401, 2.21849, 2.1174, 2.11123, 2.20396, 2.25619, 2.01475, 2.05484, 2.22974, 2.09647, 2.29722, 2.36117, 2.28311, 2.20881, 2.26532, 2.33023, 2.186, 2.31897, 2.23161, 2.18338, 2.10811, 2.29595, 2.16346, 2.25251, 2.2622, 2.17528, 2.3172, 2.135, 2.23191, 2.23288, 1.9902, 2.2193, 2.10468, 2.25035, 2.24638, 2.11847, 2.11505, 2.22427, 2.30591, 2.21544, 2.17284, 2.21771, 2.1784, 2.30839, 2.2152, 2.10152, 2.18159, 2.31007, 2.21134, 2.10331, 2.26013, 2.27187, 2.08699, 2.29745, 2.22577, 2.25388, 2.13596, 2.23598, 2.11999, 2.24028, 2.13461, 2.11814, 2.13933, 2.21759, 2.20369, 2.33002, 2.3528, 2.17646, 2.17335, 2.25637, 2.02236, 2.22642, 2.36992, 2.27649, 2.25047, 2.25078, 2.27415, 2.32967, 2.21808, 2.24284, 2.14604, 2.29484, 2.23476, 2.2296, 2.0718, 2.20586, 2.07811, 2.17823, 2.17631, 2.17855, 2.09659, 2.25036, 2.19659, 2.28594, 2.27595, 2.23097, 2.03611, 2.11549, 2.17534, 2.2058, 2.12737, 2.22151, 2.07211, 2.28076, 1.97502, 2.21552, 1.90485, 2.16851, 2.28436, 2.01619]\n",
      "    Avg Accuracies: [0.1917, 0.2208, 0.1833, 0.2458, 0.2542, 0.1583, 0.1917, 0.3167, 0.2333, 0.2083, 0.2292, 0.3167, 0.1458, 0.275, 0.2292, 0.1792, 0.1292, 0.3625, 0.1833, 0.2208, 0.2125, 0.2083, 0.1875, 0.1917, 0.25, 0.2708, 0.1708, 0.1833, 0.2333, 0.1583, 0.1958, 0.2208, 0.2875, 0.2208, 0.1875, 0.2625, 0.2042, 0.2292, 0.275, 0.2333, 0.2625, 0.2458, 0.1333, 0.275, 0.1583, 0.1958, 0.3167, 0.2583, 0.3708, 0.2583, 0.2042, 0.2292, 0.2042, 0.2583, 0.2417, 0.225, 0.1958, 0.2292, 0.1667, 0.1542, 0.1708, 0.3042, 0.3333, 0.25, 0.2667, 0.2167, 0.125, 0.2, 0.2458, 0.2708, 0.1375, 0.2125, 0.1417, 0.2292, 0.225, 0.2333, 0.2542, 0.1792, 0.35, 0.2458, 0.2542, 0.3292, 0.2417, 0.2792, 0.2208, 0.3, 0.1333, 0.2417, 0.2417, 0.3125, 0.1375, 0.2375, 0.225, 0.2417, 0.2708, 0.2708, 0.2833, 0.3708, 0.2417, 0.2125, 0.1458, 0.1458, 0.2333, 0.1833, 0.3333, 0.2292, 0.1917, 0.2875, 0.2333, 0.2125, 0.2333, 0.1667, 0.2375, 0.2167, 0.2542, 0.1458, 0.3542, 0.2083, 0.1333, 0.2292, 0.275, 0.1208, 0.2125, 0.2083, 0.2125, 0.2708, 0.1792, 0.1958, 0.2292, 0.275, 0.1292, 0.2167, 0.2083, 0.2042, 0.1875, 0.1292, 0.2042, 0.1708, 0.2458, 0.2167, 0.2042, 0.2333, 0.2708, 0.2667, 0.2, 0.1708, 0.2542, 0.3083, 0.1958, 0.2875, 0.1833, 0.1458, 0.1667, 0.2458, 0.1875, 0.1208, 0.1958, 0.175, 0.1958, 0.1917, 0.3042, 0.2083, 0.2417, 0.2292, 0.2292, 0.2792, 0.1208, 0.2458, 0.2, 0.225, 0.2542, 0.1625, 0.2875, 0.2292, 0.2167, 0.2792, 0.2458, 0.1917, 0.1833, 0.2042, 0.25, 0.2333, 0.2042, 0.1625, 0.2333, 0.2583, 0.2333, 0.1292, 0.2333, 0.3, 0.2208, 0.2458, 0.2958, 0.2792, 0.2083, 0.1792, 0.2417, 0.1917, 0.275, 0.2, 0.275, 0.2583, 0.2083, 0.2083, 0.2375, 0.2167, 0.1708, 0.25, 0.2542, 0.2083, 0.325, 0.2458, 0.1542, 0.1792, 0.2792, 0.1583, 0.1958, 0.1583, 0.1792, 0.2208, 0.2833, 0.2333, 0.1583, 0.2083, 0.3125, 0.1625, 0.2625, 0.2792, 0.1625, 0.2625, 0.3, 0.1958, 0.2417, 0.2333, 0.1792, 0.2667, 0.2917, 0.2833, 0.2208, 0.1625, 0.275, 0.1875, 0.2833, 0.1375, 0.3833, 0.2375, 0.375, 0.2083, 0.2125, 0.4208]\n",
      "\n",
      "Epoch 1/9             \n",
      "    Avg Losses: [1.42381, 1.39608, 1.74487, 1.53985, 1.55253, 1.90142, 1.62009, 1.4135, 1.31075, 1.38843, 1.39188, 1.24705, 1.86741, 1.33969, 1.33815, 1.3306, 1.84276, 0.95245, 1.50066, 1.12283, 1.53449, 1.89858, 1.44705, 1.65217, 1.69226, 1.19985, 1.83251, 1.62285, 1.36112, 1.75379, 1.60446, 1.61523, 1.31669, 1.62977, 1.77638, 1.47225, 1.79817, 1.33695, 1.43391, 1.46353, 1.23988, 1.35401, 1.95149, 1.29823, 1.95154, 1.67819, 1.28619, 1.34109, 1.0076, 1.47126, 1.53107, 1.47704, 1.4076, 1.44465, 1.53864, 1.19278, 1.57052, 1.58738, 1.74866, 1.90252, 1.76197, 1.24593, 0.97451, 1.6813, 1.32292, 1.42092, 1.98004, 1.57496, 1.40484, 1.46477, 1.99371, 1.40583, 1.98369, 1.61364, 1.48053, 1.37721, 1.69897, 1.82911, 0.89683, 1.29328, 1.677, 1.21664, 1.66508, 1.06224, 1.48296, 1.14285, 1.77176, 1.5192, 1.2997, 0.97415, 1.58493, 1.57691, 1.5984, 1.42763, 1.31415, 1.30406, 1.28475, 1.02804, 1.39818, 1.60773, 2.01164, 1.98581, 1.45242, 1.91757, 1.1857, 1.58552, 1.68537, 1.42052, 1.60991, 1.6828, 1.38486, 1.90846, 1.51598, 1.37456, 1.53038, 1.73341, 1.20852, 1.49144, 2.04071, 1.58566, 1.33482, 1.86689, 1.42537, 1.6486, 1.61695, 1.55603, 1.67671, 1.76015, 1.44691, 1.31895, 1.7989, 1.76222, 1.55916, 1.43701, 1.8509, 2.10753, 1.44544, 1.75486, 1.3932, 1.51323, 1.61157, 1.45711, 1.19002, 1.31292, 1.51953, 1.72311, 1.14192, 1.23265, 1.65739, 1.17559, 1.53354, 1.79744, 1.68659, 1.6411, 1.76463, 1.91536, 1.58413, 1.71895, 1.64444, 1.37587, 1.43552, 1.55067, 1.30771, 1.43608, 1.48642, 1.50677, 1.78678, 1.30656, 1.59476, 1.4626, 0.94181, 1.57376, 1.39517, 1.44049, 1.55957, 1.43553, 1.14401, 1.64256, 1.89102, 1.6014, 1.41941, 1.42416, 1.29406, 1.71719, 1.59306, 1.30824, 1.39038, 1.98514, 1.37188, 1.38513, 1.60011, 1.69304, 1.2743, 1.70502, 1.72458, 1.61647, 1.40712, 1.64285, 1.29312, 1.69142, 1.45707, 1.25022, 1.36998, 1.65383, 1.41487, 1.89952, 1.86792, 1.38564, 1.43751, 1.57334, 1.26326, 1.64884, 2.19366, 1.82912, 1.47181, 1.47486, 1.49856, 1.95917, 1.60749, 1.52544, 1.44046, 1.75859, 1.48846, 1.5461, 1.33984, 1.42182, 1.01291, 1.31295, 1.54863, 1.51149, 1.26342, 1.4558, 1.5351, 1.69838, 1.81812, 1.30321, 1.19927, 1.47293, 1.43928, 1.66977, 1.34175, 1.52437, 1.02248, 1.69081, 0.92742, 1.42398, 0.70244, 1.35278, 1.61002, 0.88342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.5667, 0.6292, 0.4625, 0.6042, 0.5083, 0.3833, 0.4833, 0.5375, 0.6792, 0.6333, 0.5708, 0.6292, 0.4917, 0.6375, 0.7042, 0.6333, 0.4708, 0.7708, 0.5583, 0.7542, 0.5, 0.3833, 0.5417, 0.4417, 0.5, 0.7458, 0.375, 0.4208, 0.6583, 0.4542, 0.5583, 0.5, 0.6792, 0.4875, 0.3792, 0.5375, 0.4833, 0.6292, 0.6083, 0.5458, 0.6792, 0.625, 0.4125, 0.6292, 0.3167, 0.5583, 0.6125, 0.6125, 0.7375, 0.6125, 0.5417, 0.5417, 0.6542, 0.6, 0.5792, 0.7667, 0.5417, 0.5042, 0.4083, 0.4125, 0.4583, 0.6458, 0.7042, 0.5125, 0.6083, 0.525, 0.3542, 0.6208, 0.5292, 0.5875, 0.325, 0.6375, 0.2875, 0.4833, 0.5458, 0.6083, 0.5917, 0.4, 0.7417, 0.6958, 0.4833, 0.6792, 0.475, 0.6792, 0.5875, 0.6917, 0.475, 0.5542, 0.6167, 0.7833, 0.6125, 0.5208, 0.5583, 0.5708, 0.6333, 0.6792, 0.6292, 0.725, 0.5958, 0.5208, 0.3375, 0.3875, 0.5833, 0.3958, 0.7, 0.5167, 0.5042, 0.5625, 0.5042, 0.5625, 0.5875, 0.4042, 0.5667, 0.6, 0.575, 0.4917, 0.7375, 0.525, 0.325, 0.5333, 0.6167, 0.4708, 0.5625, 0.4833, 0.5542, 0.525, 0.5208, 0.4667, 0.6167, 0.6208, 0.475, 0.4292, 0.4792, 0.5667, 0.4208, 0.2667, 0.575, 0.3958, 0.6875, 0.5542, 0.6542, 0.5375, 0.7042, 0.6042, 0.5792, 0.5375, 0.7167, 0.6292, 0.4292, 0.6792, 0.5, 0.5333, 0.4708, 0.475, 0.4167, 0.4167, 0.5583, 0.475, 0.5, 0.5875, 0.5375, 0.5708, 0.6458, 0.6583, 0.5458, 0.5292, 0.3667, 0.6, 0.5208, 0.5667, 0.775, 0.5333, 0.6333, 0.5667, 0.525, 0.5458, 0.6917, 0.5125, 0.4083, 0.4667, 0.6, 0.6042, 0.6875, 0.4542, 0.4792, 0.6625, 0.6375, 0.4083, 0.6, 0.5583, 0.6, 0.5292, 0.6208, 0.425, 0.4708, 0.575, 0.5875, 0.5625, 0.6083, 0.4833, 0.5417, 0.6833, 0.5875, 0.4667, 0.5958, 0.3625, 0.4542, 0.6458, 0.6208, 0.5375, 0.625, 0.5292, 0.1833, 0.3708, 0.5375, 0.6375, 0.575, 0.3708, 0.525, 0.5958, 0.5958, 0.4583, 0.6458, 0.5167, 0.5583, 0.6542, 0.7875, 0.6083, 0.5417, 0.5375, 0.725, 0.6375, 0.5667, 0.4792, 0.4042, 0.7167, 0.6167, 0.5292, 0.6667, 0.4875, 0.625, 0.6167, 0.7542, 0.5625, 0.75, 0.5625, 0.8708, 0.6833, 0.6, 0.7958]\n",
      "\n",
      "Epoch 2/9             \n",
      "    Avg Losses: [0.66599, 0.67731, 1.12474, 0.94035, 0.87837, 1.19405, 0.95927, 0.68644, 0.61673, 0.6313, 0.68368, 0.53514, 1.05277, 0.73045, 0.72797, 0.57532, 1.11161, 0.43986, 0.73435, 0.49876, 0.86732, 1.18369, 0.89181, 1.06066, 0.99738, 0.48883, 1.09057, 0.80912, 0.67014, 1.06789, 0.84542, 0.8452, 0.69559, 0.92172, 1.10743, 0.88686, 1.10064, 0.68435, 0.69713, 0.90724, 0.49672, 0.58697, 1.35203, 0.60153, 1.20756, 0.94735, 0.5831, 0.64751, 0.58494, 0.64268, 0.79085, 0.83259, 0.62535, 0.74519, 0.95486, 0.4387, 0.94367, 1.00357, 1.14919, 1.29178, 1.03752, 0.66397, 0.58902, 0.9811, 0.64928, 0.82384, 1.34556, 0.76407, 0.68749, 0.77847, 1.34026, 0.59694, 1.39065, 1.05931, 0.77265, 0.65953, 0.75683, 1.25792, 0.40736, 0.59923, 0.98679, 0.60373, 1.02912, 0.47348, 0.8163, 0.53822, 1.03332, 0.85762, 0.62361, 0.41193, 0.71429, 0.65668, 0.87922, 0.81375, 0.80651, 0.58685, 0.68455, 0.42698, 0.66215, 0.91345, 1.41813, 1.51601, 0.76186, 1.18984, 0.53504, 0.8023, 0.91004, 0.75111, 0.81586, 1.0115, 0.81306, 1.21674, 0.87108, 0.76017, 0.87342, 0.94199, 0.61365, 0.91401, 1.51914, 0.84708, 0.79193, 1.06661, 0.72766, 0.91778, 0.84166, 0.94358, 1.04842, 1.04955, 0.75506, 0.80042, 1.08596, 1.11449, 0.8611, 0.77262, 1.31092, 1.61769, 0.74286, 1.07584, 0.60249, 0.75645, 0.76992, 0.86336, 0.53998, 0.7142, 0.8105, 0.98294, 0.62944, 0.5848, 0.96158, 0.53288, 0.84607, 1.105, 0.96856, 1.00391, 1.03573, 1.09328, 0.90632, 1.1071, 0.98881, 0.73693, 0.83677, 0.85334, 0.58533, 0.71735, 0.85879, 0.80836, 1.18665, 0.67979, 0.87918, 0.79398, 0.49305, 0.77364, 0.8869, 0.64375, 0.78308, 0.77796, 0.60326, 0.97946, 1.2149, 0.87099, 0.7001, 0.70706, 0.62539, 0.87781, 0.94258, 0.68555, 0.74066, 1.34597, 0.77008, 0.80915, 0.80504, 0.91615, 0.73467, 1.09988, 0.98002, 0.82342, 0.83352, 1.01544, 0.61114, 0.90205, 0.82121, 0.59938, 0.7985, 1.11068, 0.77952, 1.25657, 1.26951, 0.66875, 0.74174, 0.83759, 0.78769, 0.85224, 1.74937, 1.18292, 0.82449, 0.71559, 0.75905, 1.40546, 0.84399, 0.7188, 0.81278, 1.15215, 0.79036, 0.80981, 0.85224, 0.62689, 0.36006, 0.58909, 0.90115, 0.94261, 0.54388, 0.7067, 0.79462, 0.86382, 1.1887, 0.55697, 0.60989, 0.78352, 0.65399, 0.91318, 0.79228, 0.73644, 0.31869, 0.76468, 0.28974, 0.64678, 0.22662, 0.51067, 0.74232, 0.27579]\n",
      "    Avg Accuracies: [0.8333, 0.7958, 0.6458, 0.7375, 0.7417, 0.6292, 0.7583, 0.8333, 0.8458, 0.8292, 0.8, 0.875, 0.7417, 0.8, 0.7833, 0.875, 0.7292, 0.875, 0.8083, 0.875, 0.775, 0.6583, 0.7542, 0.6583, 0.7208, 0.8792, 0.725, 0.7917, 0.7875, 0.7458, 0.725, 0.8, 0.8042, 0.6875, 0.6792, 0.7417, 0.7042, 0.8125, 0.7958, 0.7625, 0.8625, 0.8083, 0.5958, 0.85, 0.7167, 0.7375, 0.8375, 0.7917, 0.8417, 0.85, 0.7625, 0.775, 0.8417, 0.8042, 0.725, 0.8833, 0.7208, 0.7, 0.6167, 0.5792, 0.6542, 0.8583, 0.8333, 0.7292, 0.8083, 0.775, 0.6292, 0.775, 0.8083, 0.7708, 0.6292, 0.8625, 0.65, 0.6625, 0.7542, 0.8083, 0.8167, 0.6292, 0.8875, 0.8708, 0.7042, 0.8292, 0.7333, 0.8583, 0.7417, 0.8958, 0.6917, 0.7583, 0.8458, 0.9042, 0.8167, 0.8583, 0.7667, 0.7625, 0.7542, 0.8417, 0.8, 0.8625, 0.8167, 0.7417, 0.5917, 0.6083, 0.7917, 0.6208, 0.8583, 0.7833, 0.75, 0.7958, 0.7542, 0.7125, 0.7833, 0.6583, 0.75, 0.7833, 0.7417, 0.7917, 0.8292, 0.7542, 0.5792, 0.7917, 0.7583, 0.7292, 0.7958, 0.7375, 0.7583, 0.7375, 0.7208, 0.7083, 0.8125, 0.7417, 0.6917, 0.6708, 0.7417, 0.7875, 0.575, 0.4708, 0.7958, 0.7333, 0.8667, 0.825, 0.8167, 0.7625, 0.85, 0.7833, 0.7917, 0.725, 0.8375, 0.8417, 0.7708, 0.8542, 0.7792, 0.7375, 0.7042, 0.725, 0.7542, 0.7583, 0.7417, 0.7167, 0.7, 0.7542, 0.7333, 0.7625, 0.8292, 0.8167, 0.7083, 0.7833, 0.6542, 0.7958, 0.7583, 0.8125, 0.8667, 0.8125, 0.75, 0.8542, 0.7958, 0.8083, 0.8292, 0.7375, 0.675, 0.7042, 0.8125, 0.825, 0.8, 0.7625, 0.7208, 0.8292, 0.7833, 0.6458, 0.7583, 0.7708, 0.775, 0.7375, 0.7875, 0.6667, 0.6792, 0.7958, 0.7667, 0.725, 0.825, 0.7625, 0.7792, 0.8167, 0.7667, 0.65, 0.8, 0.6833, 0.625, 0.8125, 0.8042, 0.7792, 0.7417, 0.7333, 0.3667, 0.6333, 0.75, 0.8458, 0.8208, 0.5667, 0.7625, 0.85, 0.7833, 0.6833, 0.8333, 0.7625, 0.7458, 0.8042, 0.9125, 0.8208, 0.7083, 0.7458, 0.8625, 0.7958, 0.775, 0.7375, 0.6833, 0.8833, 0.8125, 0.7667, 0.8542, 0.7875, 0.7708, 0.8167, 0.9208, 0.8458, 0.9292, 0.8167, 0.9375, 0.8833, 0.8625, 0.9625]\n",
      "\n",
      "Epoch 3/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.48196, 0.38293, 0.64809, 0.63741, 0.49077, 0.60653, 0.66273, 0.38232, 0.34557, 0.33786, 0.29736, 0.29568, 0.48175, 0.46401, 0.42631, 0.31803, 0.68814, 0.28315, 0.42986, 0.30316, 0.58328, 0.71571, 0.51475, 0.66945, 0.57366, 0.2522, 0.52692, 0.42819, 0.38539, 0.62895, 0.4631, 0.49213, 0.43013, 0.5892, 0.69507, 0.62799, 0.70596, 0.38837, 0.42889, 0.62651, 0.25776, 0.3473, 0.82233, 0.27526, 0.57192, 0.63084, 0.34517, 0.3787, 0.41386, 0.31513, 0.41947, 0.45023, 0.34627, 0.38999, 0.66425, 0.26189, 0.59932, 0.61769, 0.72941, 0.82716, 0.54384, 0.35755, 0.39575, 0.58415, 0.3106, 0.46085, 0.78898, 0.39925, 0.39961, 0.41193, 0.70602, 0.29887, 0.71757, 0.65548, 0.40805, 0.3696, 0.31718, 0.88587, 0.25379, 0.34058, 0.54434, 0.37237, 0.61531, 0.26922, 0.47284, 0.28939, 0.73809, 0.45363, 0.3145, 0.24237, 0.32734, 0.28541, 0.52126, 0.46532, 0.54293, 0.34269, 0.41552, 0.27459, 0.3654, 0.53991, 0.72576, 0.93968, 0.44891, 0.71731, 0.30885, 0.3954, 0.54019, 0.53909, 0.42298, 0.64235, 0.56769, 0.67844, 0.60497, 0.4522, 0.47973, 0.50558, 0.40781, 0.57054, 0.9823, 0.45909, 0.50564, 0.57251, 0.41695, 0.51667, 0.50825, 0.60181, 0.58345, 0.7305, 0.46127, 0.51297, 0.63576, 0.64091, 0.48706, 0.45464, 0.818, 1.11819, 0.50097, 0.56388, 0.30145, 0.39376, 0.44791, 0.42866, 0.31135, 0.42883, 0.48343, 0.59808, 0.40895, 0.32713, 0.50017, 0.23611, 0.52366, 0.57339, 0.60061, 0.65181, 0.62357, 0.50196, 0.48577, 0.61577, 0.59849, 0.52364, 0.48737, 0.50036, 0.30195, 0.45976, 0.51327, 0.50841, 0.69585, 0.37053, 0.45433, 0.42663, 0.33122, 0.44625, 0.61729, 0.41484, 0.41625, 0.47309, 0.3541, 0.60182, 0.68031, 0.60647, 0.39479, 0.3552, 0.36673, 0.4614, 0.62608, 0.50295, 0.51467, 0.75801, 0.38947, 0.55062, 0.44287, 0.49432, 0.44091, 0.69624, 0.52253, 0.41408, 0.53917, 0.70469, 0.35342, 0.47564, 0.50128, 0.38504, 0.50143, 0.81774, 0.41711, 0.73371, 0.72688, 0.45132, 0.42971, 0.46308, 0.58568, 0.48524, 0.94056, 0.76619, 0.42808, 0.36213, 0.3797, 0.85861, 0.48552, 0.44227, 0.55609, 0.71893, 0.40844, 0.42552, 0.57096, 0.27701, 0.17773, 0.36979, 0.4969, 0.5945, 0.28993, 0.43079, 0.51076, 0.45096, 0.71246, 0.36631, 0.35184, 0.49862, 0.32361, 0.46052, 0.49918, 0.37334, 0.13107, 0.25864, 0.10459, 0.28947, 0.07066, 0.23102, 0.33573, 0.12248]\n",
      "    Avg Accuracies: [0.85, 0.8708, 0.8458, 0.7958, 0.8458, 0.8042, 0.825, 0.8958, 0.9083, 0.8958, 0.9417, 0.9167, 0.8875, 0.8417, 0.875, 0.925, 0.8042, 0.9083, 0.875, 0.9167, 0.7792, 0.7958, 0.8583, 0.7708, 0.8333, 0.9333, 0.85, 0.8625, 0.8792, 0.8042, 0.8333, 0.8167, 0.85, 0.8042, 0.7792, 0.7833, 0.7833, 0.8667, 0.8625, 0.8125, 0.9083, 0.875, 0.7458, 0.9375, 0.8375, 0.8125, 0.875, 0.8542, 0.8917, 0.9125, 0.8708, 0.8708, 0.9, 0.9083, 0.8, 0.9167, 0.825, 0.7917, 0.7583, 0.7333, 0.8, 0.9208, 0.8833, 0.8125, 0.9, 0.8583, 0.775, 0.8708, 0.8875, 0.8583, 0.8, 0.9, 0.8208, 0.775, 0.8708, 0.8792, 0.9333, 0.75, 0.925, 0.9042, 0.8375, 0.8875, 0.8333, 0.925, 0.8583, 0.9167, 0.7625, 0.8792, 0.9042, 0.9333, 0.9, 0.9, 0.7958, 0.8917, 0.8208, 0.8958, 0.8708, 0.925, 0.8792, 0.825, 0.825, 0.7292, 0.85, 0.7833, 0.9, 0.8917, 0.8292, 0.8458, 0.8583, 0.8458, 0.7917, 0.7708, 0.7875, 0.85, 0.8833, 0.8625, 0.875, 0.8333, 0.7042, 0.8833, 0.825, 0.8083, 0.8833, 0.8542, 0.8458, 0.8, 0.8292, 0.7458, 0.8542, 0.85, 0.8292, 0.8, 0.8167, 0.8708, 0.7583, 0.6625, 0.8417, 0.8667, 0.925, 0.8833, 0.8208, 0.8875, 0.9292, 0.8667, 0.8417, 0.7958, 0.8917, 0.9083, 0.8792, 0.9375, 0.8042, 0.8333, 0.7792, 0.7958, 0.8167, 0.8625, 0.8458, 0.8417, 0.8333, 0.8125, 0.8667, 0.8375, 0.9208, 0.8375, 0.8208, 0.8542, 0.775, 0.8708, 0.8833, 0.8917, 0.9042, 0.8875, 0.8083, 0.8792, 0.85, 0.8583, 0.8917, 0.8, 0.7833, 0.7958, 0.8917, 0.8917, 0.8708, 0.875, 0.7958, 0.8417, 0.825, 0.7833, 0.8792, 0.8292, 0.8792, 0.85, 0.8708, 0.7833, 0.8417, 0.8958, 0.8125, 0.7792, 0.8833, 0.8417, 0.8417, 0.8833, 0.8333, 0.7542, 0.8875, 0.8083, 0.7583, 0.8208, 0.8792, 0.8667, 0.7792, 0.85, 0.7542, 0.7708, 0.8833, 0.8958, 0.9, 0.7167, 0.8667, 0.8792, 0.8208, 0.8, 0.9125, 0.8917, 0.7875, 0.925, 0.9417, 0.875, 0.875, 0.8, 0.9292, 0.8542, 0.8542, 0.8542, 0.7833, 0.8917, 0.8917, 0.8542, 0.9083, 0.875, 0.8292, 0.8958, 0.9667, 0.9417, 0.9833, 0.9125, 0.9833, 0.9333, 0.9167, 0.9792]\n",
      "\n",
      "Epoch 4/9             \n",
      "    Avg Losses: [0.28891, 0.22886, 0.3559, 0.39023, 0.37431, 0.35275, 0.48511, 0.21426, 0.20488, 0.22675, 0.19763, 0.21251, 0.28091, 0.28781, 0.26523, 0.18045, 0.41467, 0.16987, 0.32037, 0.17809, 0.38815, 0.41576, 0.37449, 0.50219, 0.35067, 0.15366, 0.31396, 0.25742, 0.22803, 0.41936, 0.22588, 0.31221, 0.2781, 0.4487, 0.43524, 0.40831, 0.53501, 0.27912, 0.28236, 0.40846, 0.14398, 0.19602, 0.5025, 0.15856, 0.35133, 0.36871, 0.27215, 0.28247, 0.28401, 0.19666, 0.25415, 0.26821, 0.22572, 0.23833, 0.44897, 0.1706, 0.40138, 0.41233, 0.39788, 0.56952, 0.32189, 0.34489, 0.29231, 0.42231, 0.19222, 0.28384, 0.50832, 0.28283, 0.2123, 0.31109, 0.50026, 0.18521, 0.36325, 0.44203, 0.24668, 0.24076, 0.21205, 0.63285, 0.15116, 0.19759, 0.32279, 0.22464, 0.4399, 0.22261, 0.3801, 0.16058, 0.51012, 0.3606, 0.18335, 0.11659, 0.14364, 0.2885, 0.35765, 0.28533, 0.45711, 0.17376, 0.31657, 0.15993, 0.28201, 0.36495, 0.42996, 0.52213, 0.32008, 0.48602, 0.17758, 0.26284, 0.39039, 0.41634, 0.25962, 0.38385, 0.3671, 0.47567, 0.29817, 0.30014, 0.39614, 0.28799, 0.28318, 0.37699, 0.69169, 0.27075, 0.32267, 0.37107, 0.26674, 0.31559, 0.33103, 0.38293, 0.32691, 0.39419, 0.25239, 0.41048, 0.44502, 0.40158, 0.33931, 0.29996, 0.46534, 0.66281, 0.29514, 0.32455, 0.14047, 0.22306, 0.32852, 0.29045, 0.20378, 0.28115, 0.27948, 0.42489, 0.23599, 0.19227, 0.29525, 0.14941, 0.38839, 0.34543, 0.49706, 0.44576, 0.34685, 0.27158, 0.27295, 0.40581, 0.42918, 0.39445, 0.29299, 0.36259, 0.1974, 0.40968, 0.34214, 0.35563, 0.39533, 0.19804, 0.28549, 0.27163, 0.17832, 0.26995, 0.44641, 0.23026, 0.20763, 0.2799, 0.22709, 0.41037, 0.37302, 0.45191, 0.26457, 0.24938, 0.20663, 0.26095, 0.36947, 0.36359, 0.33983, 0.43218, 0.21164, 0.46288, 0.34929, 0.27776, 0.38236, 0.52896, 0.38834, 0.24886, 0.39913, 0.39963, 0.23723, 0.31508, 0.2684, 0.32909, 0.35508, 0.63284, 0.27517, 0.49175, 0.44114, 0.29236, 0.31188, 0.2981, 0.4531, 0.25021, 0.49076, 0.51957, 0.2364, 0.17064, 0.27775, 0.65783, 0.32195, 0.26164, 0.51905, 0.49771, 0.23781, 0.25961, 0.40497, 0.16743, 0.0629, 0.28033, 0.33499, 0.37259, 0.25426, 0.31233, 0.41837, 0.34832, 0.50924, 0.24214, 0.19551, 0.31726, 0.23083, 0.28226, 0.33196, 0.20754, 0.13901, 0.11818, 0.04536, 0.13365, 0.03929, 0.09566, 0.2536, 0.0965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9042, 0.9375, 0.8875, 0.8958, 0.8875, 0.8625, 0.8292, 0.9583, 0.9292, 0.9125, 0.9542, 0.9292, 0.925, 0.9, 0.9042, 0.9417, 0.8833, 0.9417, 0.9042, 0.9542, 0.875, 0.8583, 0.8958, 0.8417, 0.8958, 0.9542, 0.8958, 0.9167, 0.9167, 0.8833, 0.9375, 0.9, 0.9125, 0.8167, 0.8625, 0.8708, 0.8042, 0.9, 0.9083, 0.8708, 0.9625, 0.9333, 0.8208, 0.9458, 0.8792, 0.9042, 0.8958, 0.875, 0.8958, 0.95, 0.9083, 0.9292, 0.9458, 0.9417, 0.8417, 0.9458, 0.875, 0.8542, 0.875, 0.8125, 0.875, 0.8667, 0.8958, 0.8625, 0.95, 0.9083, 0.8333, 0.8875, 0.9208, 0.9083, 0.8333, 0.9292, 0.8833, 0.8708, 0.9208, 0.9333, 0.925, 0.8083, 0.9625, 0.95, 0.875, 0.9375, 0.8708, 0.9333, 0.9125, 0.9583, 0.8417, 0.8958, 0.9542, 0.9667, 0.9625, 0.8875, 0.8875, 0.9208, 0.875, 0.9458, 0.9042, 0.9458, 0.8875, 0.8833, 0.8542, 0.8208, 0.9125, 0.8625, 0.9542, 0.9292, 0.8875, 0.8792, 0.9042, 0.9042, 0.8667, 0.8375, 0.9375, 0.9, 0.8542, 0.9125, 0.9125, 0.9, 0.7917, 0.9083, 0.8917, 0.8667, 0.9042, 0.9167, 0.8875, 0.8833, 0.9042, 0.8917, 0.9208, 0.8833, 0.8708, 0.8542, 0.85, 0.9042, 0.825, 0.8083, 0.9375, 0.9333, 0.9667, 0.9292, 0.8792, 0.9208, 0.9458, 0.9083, 0.8833, 0.8667, 0.9417, 0.9417, 0.9, 0.9542, 0.8792, 0.8875, 0.85, 0.8542, 0.8958, 0.9208, 0.9167, 0.8708, 0.85, 0.8625, 0.9125, 0.8792, 0.9458, 0.875, 0.8875, 0.8792, 0.8875, 0.9292, 0.9167, 0.9167, 0.9458, 0.8958, 0.8625, 0.9417, 0.9625, 0.9125, 0.9542, 0.8708, 0.8458, 0.8375, 0.9333, 0.9, 0.9208, 0.9292, 0.9042, 0.8708, 0.8917, 0.8583, 0.9417, 0.8625, 0.8833, 0.9208, 0.8875, 0.8417, 0.8625, 0.9292, 0.8542, 0.8708, 0.9167, 0.8958, 0.9292, 0.8958, 0.8917, 0.7833, 0.9375, 0.8292, 0.8458, 0.9042, 0.9333, 0.9042, 0.8792, 0.925, 0.8667, 0.8125, 0.9458, 0.9542, 0.9083, 0.775, 0.9125, 0.9292, 0.85, 0.8708, 0.9333, 0.9083, 0.8708, 0.9583, 0.9833, 0.9125, 0.9042, 0.8583, 0.9167, 0.9042, 0.8875, 0.8958, 0.8333, 0.9333, 0.9375, 0.8958, 0.9333, 0.9167, 0.9083, 0.9375, 0.9667, 0.9667, 0.9917, 0.9708, 0.9917, 0.9792, 0.9208, 0.9792]\n",
      "\n",
      "Epoch 5/9             \n",
      "    Avg Losses: [0.16412, 0.1085, 0.19013, 0.28199, 0.27105, 0.20363, 0.30046, 0.17619, 0.11517, 0.16652, 0.15891, 0.14055, 0.13259, 0.16479, 0.15708, 0.13441, 0.28863, 0.08136, 0.20084, 0.1446, 0.23572, 0.29733, 0.23148, 0.35131, 0.1995, 0.08994, 0.18473, 0.18505, 0.14938, 0.28203, 0.20045, 0.25427, 0.17235, 0.30713, 0.30131, 0.33305, 0.38434, 0.20641, 0.20945, 0.26157, 0.09711, 0.14744, 0.32145, 0.1068, 0.23235, 0.19656, 0.19722, 0.30252, 0.21943, 0.11361, 0.1161, 0.17761, 0.10504, 0.21178, 0.27971, 0.20105, 0.27286, 0.28203, 0.27643, 0.40661, 0.21544, 0.16365, 0.21493, 0.30489, 0.14909, 0.15907, 0.32516, 0.1368, 0.14417, 0.25785, 0.43813, 0.14958, 0.21068, 0.27681, 0.17352, 0.13406, 0.13238, 0.39254, 0.11213, 0.12407, 0.21506, 0.12431, 0.25223, 0.19667, 0.27379, 0.10154, 0.32295, 0.2849, 0.12275, 0.08924, 0.11191, 0.15229, 0.22584, 0.24117, 0.32359, 0.09037, 0.18131, 0.135, 0.15849, 0.20723, 0.24466, 0.34418, 0.31216, 0.35446, 0.10929, 0.15397, 0.24203, 0.26822, 0.178, 0.27319, 0.29093, 0.27758, 0.23424, 0.19863, 0.22631, 0.14069, 0.25468, 0.25712, 0.53964, 0.2661, 0.15554, 0.30468, 0.27111, 0.2378, 0.29425, 0.28465, 0.18607, 0.21038, 0.26748, 0.35665, 0.34253, 0.26069, 0.18465, 0.1699, 0.21951, 0.38654, 0.20234, 0.25376, 0.08123, 0.12708, 0.2461, 0.13104, 0.1867, 0.22439, 0.23841, 0.2947, 0.21679, 0.09353, 0.22586, 0.08382, 0.23651, 0.20265, 0.27007, 0.31829, 0.25784, 0.16417, 0.22543, 0.28042, 0.32487, 0.17731, 0.16343, 0.29301, 0.10316, 0.32898, 0.19927, 0.24149, 0.26439, 0.1415, 0.22054, 0.23785, 0.15649, 0.18352, 0.29607, 0.21047, 0.11264, 0.15599, 0.18266, 0.28586, 0.20878, 0.23957, 0.20106, 0.14115, 0.15798, 0.12821, 0.21547, 0.26567, 0.25004, 0.26321, 0.1273, 0.30482, 0.29932, 0.15398, 0.21355, 0.30315, 0.21581, 0.16017, 0.29695, 0.28014, 0.12027, 0.21463, 0.19036, 0.1916, 0.25342, 0.44088, 0.17353, 0.28907, 0.31438, 0.19803, 0.16162, 0.16611, 0.28249, 0.16565, 0.31191, 0.37948, 0.1622, 0.08769, 0.22002, 0.55178, 0.18343, 0.17292, 0.35897, 0.37807, 0.12379, 0.18314, 0.26809, 0.08159, 0.0376, 0.1778, 0.19798, 0.19109, 0.16654, 0.15146, 0.32707, 0.2472, 0.33863, 0.23305, 0.0965, 0.18713, 0.1772, 0.18326, 0.21985, 0.12177, 0.13057, 0.06993, 0.01655, 0.07351, 0.01577, 0.0569, 0.12047, 0.06009]\n",
      "    Avg Accuracies: [0.95, 0.9708, 0.9458, 0.9, 0.9, 0.9417, 0.8958, 0.9583, 0.9708, 0.9417, 0.9625, 0.9583, 0.9667, 0.9458, 0.9708, 0.9583, 0.9083, 0.9833, 0.9625, 0.9542, 0.9208, 0.9083, 0.925, 0.8958, 0.9417, 0.9833, 0.9458, 0.95, 0.9542, 0.9167, 0.9458, 0.9083, 0.9542, 0.8875, 0.9, 0.8833, 0.8875, 0.9208, 0.9375, 0.9, 0.975, 0.9708, 0.9, 0.9667, 0.9292, 0.9542, 0.925, 0.8917, 0.9417, 0.975, 0.975, 0.9333, 0.9833, 0.9542, 0.9167, 0.9292, 0.9167, 0.9125, 0.9375, 0.85, 0.9333, 0.9625, 0.9292, 0.9083, 0.9542, 0.9667, 0.9042, 0.9583, 0.9542, 0.9042, 0.8458, 0.9458, 0.9458, 0.9208, 0.9458, 0.95, 0.95, 0.875, 0.9708, 0.9708, 0.9208, 0.9792, 0.9292, 0.9333, 0.9042, 0.9792, 0.8875, 0.9167, 0.9708, 0.975, 0.9625, 0.9542, 0.9375, 0.9333, 0.8833, 0.9833, 0.9583, 0.9417, 0.9417, 0.9417, 0.9125, 0.9042, 0.8792, 0.8833, 0.975, 0.9458, 0.9333, 0.925, 0.9542, 0.9083, 0.9208, 0.8792, 0.9167, 0.9458, 0.925, 0.9667, 0.9333, 0.9208, 0.8375, 0.9042, 0.9583, 0.9083, 0.9125, 0.9458, 0.9042, 0.9292, 0.9417, 0.9375, 0.875, 0.8625, 0.8958, 0.925, 0.925, 0.95, 0.95, 0.875, 0.95, 0.9333, 0.9833, 0.9542, 0.925, 0.9625, 0.9542, 0.9333, 0.925, 0.8917, 0.9208, 0.9708, 0.925, 0.9833, 0.925, 0.9417, 0.925, 0.8917, 0.9292, 0.9542, 0.9333, 0.9167, 0.8875, 0.9583, 0.95, 0.9125, 0.9708, 0.8708, 0.9458, 0.9333, 0.925, 0.9625, 0.9417, 0.9125, 0.95, 0.9583, 0.9083, 0.9333, 0.9792, 0.9333, 0.9542, 0.9125, 0.9458, 0.9208, 0.9208, 0.9583, 0.95, 0.9667, 0.9417, 0.8875, 0.9208, 0.9083, 0.9625, 0.9167, 0.9292, 0.9583, 0.925, 0.9292, 0.925, 0.9542, 0.8833, 0.9125, 0.9667, 0.9333, 0.9417, 0.9458, 0.9208, 0.8542, 0.9417, 0.9083, 0.9, 0.9417, 0.9667, 0.95, 0.925, 0.9375, 0.8958, 0.875, 0.9625, 0.9792, 0.9375, 0.8458, 0.9417, 0.9542, 0.875, 0.875, 0.9583, 0.9417, 0.9125, 0.9875, 0.9958, 0.9625, 0.9417, 0.9458, 0.9458, 0.9542, 0.8875, 0.9125, 0.8875, 0.9125, 0.9833, 0.9333, 0.9542, 0.9542, 0.9458, 0.9625, 0.9458, 0.9833, 1.0, 0.9875, 1.0, 0.9917, 0.9583, 0.9875]\n",
      "\n",
      "Epoch 6/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.1074, 0.06047, 0.12346, 0.16572, 0.19751, 0.15397, 0.19522, 0.0837, 0.06076, 0.10236, 0.11256, 0.08271, 0.13709, 0.10065, 0.08645, 0.10457, 0.20076, 0.06274, 0.15415, 0.12645, 0.17388, 0.20123, 0.11762, 0.34864, 0.13082, 0.03625, 0.15364, 0.1132, 0.0955, 0.20392, 0.13981, 0.16905, 0.11069, 0.25625, 0.19169, 0.25074, 0.27459, 0.12853, 0.13266, 0.16434, 0.05696, 0.07365, 0.2266, 0.064, 0.17944, 0.11122, 0.10853, 0.21967, 0.17725, 0.08947, 0.07911, 0.09606, 0.07128, 0.21202, 0.20377, 0.08675, 0.17988, 0.27651, 0.2601, 0.23553, 0.14984, 0.1217, 0.18287, 0.23356, 0.09189, 0.12574, 0.2568, 0.10465, 0.09447, 0.23183, 0.27649, 0.12257, 0.24177, 0.17097, 0.19736, 0.14328, 0.09079, 0.31043, 0.05974, 0.06421, 0.12343, 0.05246, 0.1385, 0.14781, 0.1659, 0.04048, 0.24354, 0.27874, 0.07164, 0.08183, 0.06819, 0.08019, 0.16821, 0.20635, 0.23753, 0.04492, 0.08764, 0.07426, 0.07873, 0.15216, 0.1528, 0.24838, 0.12397, 0.26659, 0.04785, 0.11172, 0.18045, 0.19225, 0.11157, 0.1721, 0.20463, 0.20355, 0.1177, 0.13017, 0.12556, 0.08764, 0.15913, 0.17252, 0.38469, 0.11963, 0.08187, 0.14958, 0.16542, 0.15974, 0.18998, 0.20793, 0.10989, 0.11745, 0.14983, 0.20232, 0.1979, 0.1641, 0.10662, 0.08054, 0.16169, 0.29234, 0.12013, 0.14832, 0.06094, 0.06975, 0.15442, 0.08289, 0.16513, 0.14342, 0.18965, 0.27068, 0.12267, 0.06244, 0.15166, 0.05841, 0.15512, 0.13631, 0.25458, 0.2197, 0.15214, 0.11098, 0.13443, 0.22731, 0.18316, 0.15543, 0.11723, 0.2058, 0.08124, 0.25725, 0.17625, 0.15873, 0.18283, 0.15082, 0.15641, 0.16194, 0.08463, 0.14162, 0.25208, 0.10878, 0.09396, 0.12305, 0.13023, 0.23452, 0.13409, 0.15505, 0.15705, 0.15615, 0.09161, 0.11882, 0.13419, 0.19404, 0.25759, 0.21007, 0.10701, 0.21995, 0.18035, 0.10051, 0.12413, 0.21084, 0.12421, 0.11848, 0.16598, 0.18613, 0.17133, 0.18281, 0.13389, 0.10676, 0.19518, 0.37715, 0.08691, 0.21421, 0.21866, 0.11602, 0.09748, 0.0917, 0.18684, 0.09449, 0.24829, 0.25863, 0.09323, 0.0558, 0.1411, 0.43652, 0.13102, 0.10726, 0.25302, 0.2475, 0.08158, 0.10755, 0.24293, 0.06518, 0.02503, 0.18471, 0.16272, 0.14776, 0.11814, 0.07114, 0.20684, 0.1613, 0.23578, 0.14109, 0.08129, 0.12732, 0.11255, 0.12106, 0.13751, 0.09883, 0.07116, 0.02467, 0.00885, 0.04479, 0.01696, 0.02835, 0.07226, 0.03629]\n",
      "    Avg Accuracies: [0.975, 1.0, 0.95, 0.9458, 0.9458, 0.9583, 0.9542, 0.9792, 0.9958, 0.9708, 0.975, 0.975, 0.9583, 0.9792, 0.9833, 0.9583, 0.9542, 0.9792, 0.9542, 0.9625, 0.9458, 0.95, 0.9708, 0.8792, 0.9542, 0.9958, 0.9458, 0.9667, 0.9792, 0.925, 0.9417, 0.9458, 0.9792, 0.9167, 0.9583, 0.9208, 0.9042, 0.9625, 0.9458, 0.95, 0.9833, 0.9833, 0.9333, 0.9792, 0.9417, 0.9708, 0.975, 0.9333, 0.9542, 0.975, 0.9833, 0.9792, 0.9792, 0.9208, 0.9458, 0.9708, 0.9583, 0.8958, 0.925, 0.9167, 0.95, 0.9625, 0.9542, 0.9167, 0.9792, 0.9792, 0.9125, 0.9708, 0.975, 0.9125, 0.9083, 0.9667, 0.9125, 0.9542, 0.9375, 0.9542, 0.9708, 0.925, 0.9958, 0.9875, 0.9667, 0.9875, 0.95, 0.95, 0.95, 1.0, 0.9375, 0.9042, 0.9875, 0.9875, 0.9833, 0.9833, 0.95, 0.925, 0.9083, 0.9917, 0.9917, 0.9833, 0.9833, 0.9625, 0.9417, 0.925, 0.9833, 0.9167, 0.9958, 0.9708, 0.9458, 0.925, 0.9583, 0.9583, 0.925, 0.9333, 0.9667, 0.9583, 0.9625, 0.975, 0.9458, 0.9667, 0.9083, 0.975, 0.9833, 0.9625, 0.9333, 0.9583, 0.9417, 0.925, 0.975, 0.9833, 0.9625, 0.9333, 0.95, 0.95, 0.9667, 0.9958, 0.9542, 0.9, 0.9667, 0.9583, 0.9875, 0.9875, 0.95, 0.9875, 0.9458, 0.9583, 0.9292, 0.9, 0.9583, 0.9833, 0.95, 0.9917, 0.9625, 0.975, 0.9125, 0.9333, 0.9542, 0.9667, 0.9542, 0.9292, 0.9542, 0.9542, 0.9708, 0.9333, 0.975, 0.9208, 0.9583, 0.9458, 0.9417, 0.9667, 0.9583, 0.9625, 0.9792, 0.9542, 0.9292, 0.9708, 0.9667, 0.9625, 0.9667, 0.9167, 0.9708, 0.9583, 0.9458, 0.9458, 0.9708, 0.9667, 0.9667, 0.9125, 0.9208, 0.925, 0.9792, 0.9292, 0.9458, 0.9625, 0.9708, 0.9417, 0.95, 0.9708, 0.9458, 0.9417, 0.95, 0.9458, 0.9625, 0.9667, 0.9542, 0.8625, 0.975, 0.9375, 0.9167, 0.9583, 0.975, 0.975, 0.95, 0.975, 0.9125, 0.9167, 0.9833, 0.9833, 0.95, 0.8292, 0.9542, 0.9708, 0.9208, 0.9375, 0.9708, 0.9667, 0.9375, 0.9792, 0.9958, 0.9458, 0.9542, 0.95, 0.9667, 0.9917, 0.9292, 0.9583, 0.9333, 0.9625, 0.975, 0.975, 0.9625, 0.9583, 0.9583, 0.9708, 0.975, 1.0, 1.0, 0.9958, 1.0, 1.0, 0.9792, 0.9917]\n",
      "\n",
      "Epoch 7/9             \n",
      "    Avg Losses: [0.05834, 0.05685, 0.08048, 0.0759, 0.14766, 0.09428, 0.11831, 0.10322, 0.03191, 0.07484, 0.07501, 0.07809, 0.09248, 0.08953, 0.08008, 0.0705, 0.14388, 0.03598, 0.15169, 0.10606, 0.12547, 0.15116, 0.09223, 0.37847, 0.07085, 0.02874, 0.06338, 0.07612, 0.05012, 0.13298, 0.06318, 0.12102, 0.08248, 0.17956, 0.15062, 0.21236, 0.15253, 0.09092, 0.08215, 0.11845, 0.0262, 0.0815, 0.15697, 0.03915, 0.11608, 0.06766, 0.06923, 0.11172, 0.13622, 0.11812, 0.05342, 0.08759, 0.05019, 0.13492, 0.15327, 0.04041, 0.12113, 0.13545, 0.15829, 0.1536, 0.14181, 0.10206, 0.13484, 0.16352, 0.05864, 0.11272, 0.16774, 0.03554, 0.05875, 0.17585, 0.19614, 0.11113, 0.14367, 0.10595, 0.0971, 0.11461, 0.0907, 0.20896, 0.04465, 0.03815, 0.07336, 0.03706, 0.0885, 0.08657, 0.1313, 0.02235, 0.14937, 0.22467, 0.04089, 0.09874, 0.04611, 0.04915, 0.12512, 0.1645, 0.17344, 0.02844, 0.07946, 0.03392, 0.05917, 0.11675, 0.07439, 0.16927, 0.1113, 0.19917, 0.03987, 0.05812, 0.16118, 0.11207, 0.10681, 0.14607, 0.13781, 0.10341, 0.09604, 0.1003, 0.09441, 0.05137, 0.10099, 0.15354, 0.28305, 0.1109, 0.04798, 0.11193, 0.13167, 0.08084, 0.12489, 0.10612, 0.06044, 0.06522, 0.13412, 0.18005, 0.15234, 0.16698, 0.07931, 0.0769, 0.09468, 0.16451, 0.11923, 0.08494, 0.05092, 0.05187, 0.10946, 0.05319, 0.15077, 0.1012, 0.12467, 0.20785, 0.06063, 0.05401, 0.16609, 0.02451, 0.08861, 0.08961, 0.18718, 0.13081, 0.10492, 0.11188, 0.08231, 0.16424, 0.13887, 0.10579, 0.0776, 0.17925, 0.04812, 0.11436, 0.14386, 0.08176, 0.10087, 0.10094, 0.07656, 0.1382, 0.04533, 0.07454, 0.17707, 0.07637, 0.04213, 0.1247, 0.09634, 0.19315, 0.09896, 0.0981, 0.10263, 0.10387, 0.07847, 0.07226, 0.07651, 0.14141, 0.12526, 0.13495, 0.0685, 0.14106, 0.10801, 0.07481, 0.09227, 0.13564, 0.04915, 0.07563, 0.14338, 0.12779, 0.09463, 0.13722, 0.08805, 0.0598, 0.14221, 0.22883, 0.05497, 0.1913, 0.15792, 0.07329, 0.06091, 0.08171, 0.13454, 0.03971, 0.15247, 0.13097, 0.0622, 0.02898, 0.10545, 0.26569, 0.08479, 0.07293, 0.21859, 0.19562, 0.04432, 0.11327, 0.12891, 0.06556, 0.01397, 0.08003, 0.1312, 0.10313, 0.08052, 0.05752, 0.14522, 0.12504, 0.15394, 0.11208, 0.04563, 0.08184, 0.06908, 0.11056, 0.15029, 0.05929, 0.03263, 0.01336, 0.0043, 0.01961, 0.00476, 0.02047, 0.04663, 0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9875, 0.9875, 0.975, 0.9875, 0.9458, 0.975, 0.9708, 0.9583, 1.0, 0.975, 0.9833, 0.9875, 0.975, 0.9792, 0.9792, 0.975, 0.9375, 0.9958, 0.95, 0.9583, 0.9542, 0.95, 0.9792, 0.8875, 0.9792, 0.9958, 0.9958, 0.9875, 0.9875, 0.9667, 0.9875, 0.9583, 0.9833, 0.9333, 0.9583, 0.9458, 0.9583, 0.9792, 0.9875, 0.9667, 1.0, 0.9792, 0.9667, 0.9917, 0.9708, 0.9792, 0.9833, 0.9667, 0.9667, 0.9667, 0.9875, 0.9708, 0.9917, 0.9542, 0.9417, 0.9917, 0.975, 0.9708, 0.9458, 0.9542, 0.9583, 0.9625, 0.9458, 0.95, 0.9958, 0.9583, 0.9583, 1.0, 0.9917, 0.925, 0.9375, 0.9625, 0.9625, 0.9792, 0.975, 0.9667, 0.9792, 0.9375, 0.9875, 0.9958, 0.9875, 0.9917, 0.9875, 0.9792, 0.9583, 1.0, 0.9375, 0.9208, 0.9958, 0.9667, 0.9833, 0.9875, 0.9625, 0.9583, 0.9458, 1.0, 0.9792, 1.0, 0.9833, 0.9625, 0.9833, 0.9625, 0.975, 0.925, 0.9958, 0.9917, 0.9542, 0.9833, 0.9625, 0.9583, 0.95, 0.975, 0.9667, 0.9792, 0.9833, 0.9917, 0.975, 0.9458, 0.9375, 0.9583, 0.9917, 0.975, 0.9667, 0.9792, 0.9708, 0.975, 0.9875, 0.9875, 0.9542, 0.95, 0.9625, 0.9542, 0.9833, 0.9875, 0.975, 0.9417, 0.9708, 0.975, 0.9833, 0.9917, 0.975, 0.9917, 0.9583, 0.9792, 0.9542, 0.925, 0.9917, 0.9833, 0.95, 1.0, 0.9708, 0.975, 0.9417, 0.9708, 0.9708, 0.9542, 0.9875, 0.95, 0.9583, 0.9708, 0.975, 0.9375, 0.9875, 0.975, 0.9458, 0.9833, 0.975, 0.975, 0.9833, 0.95, 0.9917, 0.9833, 0.9542, 0.9792, 0.9917, 0.9542, 0.9792, 0.9375, 0.9708, 0.9792, 0.9625, 0.9708, 0.9792, 0.9792, 0.9792, 0.95, 0.9708, 0.9625, 0.9833, 0.9542, 0.9667, 0.9792, 0.9833, 0.9583, 0.9958, 0.9708, 0.9542, 0.9583, 0.975, 0.9583, 0.975, 0.9833, 0.9542, 0.9292, 0.9917, 0.9375, 0.9417, 0.9917, 0.9917, 0.975, 0.975, 1.0, 0.95, 0.975, 0.9917, 0.9958, 0.975, 0.9208, 0.9708, 0.9833, 0.9167, 0.9375, 0.9958, 0.9667, 0.975, 0.9792, 1.0, 0.9792, 0.95, 0.9708, 0.975, 0.9875, 0.9542, 0.9625, 0.9708, 0.9708, 0.9917, 0.9792, 0.9875, 0.975, 0.9542, 0.9875, 0.9917, 1.0, 1.0, 1.0, 1.0, 0.9958, 0.9875, 0.9958]\n",
      "\n",
      "Epoch 8/9             \n",
      "    Avg Losses: [0.03995, 0.04689, 0.05498, 0.05937, 0.11932, 0.07282, 0.07717, 0.06631, 0.01709, 0.05675, 0.07413, 0.03702, 0.05234, 0.07359, 0.07445, 0.07456, 0.07749, 0.02935, 0.14579, 0.07868, 0.11498, 0.1019, 0.0497, 0.22173, 0.05037, 0.01312, 0.05585, 0.06108, 0.03363, 0.07982, 0.06463, 0.09214, 0.06313, 0.09482, 0.1171, 0.2347, 0.1442, 0.06783, 0.04711, 0.07496, 0.01241, 0.0572, 0.13112, 0.02, 0.09605, 0.05095, 0.04171, 0.06314, 0.11654, 0.10141, 0.02434, 0.03694, 0.02497, 0.08434, 0.09782, 0.0238, 0.07472, 0.09934, 0.10428, 0.1193, 0.07706, 0.06268, 0.07891, 0.12508, 0.03365, 0.0739, 0.1175, 0.03177, 0.02443, 0.11184, 0.12434, 0.08, 0.13529, 0.07029, 0.08337, 0.05866, 0.04461, 0.13439, 0.0217, 0.02401, 0.0524, 0.01627, 0.04943, 0.03875, 0.07016, 0.01777, 0.09249, 0.13959, 0.02448, 0.07452, 0.02218, 0.04027, 0.08074, 0.08782, 0.1042, 0.01736, 0.07005, 0.03164, 0.0486, 0.11468, 0.06726, 0.10285, 0.07198, 0.11468, 0.02153, 0.03925, 0.12231, 0.06217, 0.08267, 0.12665, 0.17608, 0.06378, 0.04079, 0.05339, 0.07034, 0.0229, 0.06104, 0.08616, 0.2355, 0.07399, 0.03414, 0.0675, 0.09499, 0.04141, 0.11153, 0.08179, 0.03861, 0.02942, 0.07129, 0.07979, 0.12188, 0.10273, 0.04103, 0.0528, 0.0487, 0.10589, 0.08765, 0.05744, 0.04894, 0.03623, 0.0719, 0.04568, 0.07608, 0.04514, 0.08194, 0.1537, 0.04938, 0.03439, 0.08959, 0.01384, 0.05492, 0.05735, 0.12206, 0.08174, 0.07466, 0.06092, 0.07232, 0.10831, 0.0719, 0.06428, 0.06475, 0.13289, 0.02065, 0.09896, 0.15506, 0.04405, 0.06941, 0.05307, 0.04179, 0.0842, 0.0742, 0.07673, 0.13735, 0.04493, 0.03594, 0.04661, 0.06763, 0.20949, 0.0689, 0.06095, 0.06033, 0.06969, 0.05409, 0.03921, 0.0478, 0.07128, 0.10576, 0.13289, 0.07974, 0.13513, 0.06684, 0.07896, 0.05705, 0.08272, 0.03045, 0.05022, 0.12714, 0.09618, 0.06279, 0.07425, 0.06648, 0.05197, 0.11526, 0.15349, 0.04996, 0.17026, 0.09499, 0.04128, 0.03364, 0.07905, 0.06935, 0.01918, 0.09104, 0.1027, 0.0399, 0.02168, 0.05443, 0.18998, 0.05931, 0.04588, 0.1977, 0.15837, 0.02159, 0.07728, 0.10893, 0.05143, 0.01049, 0.04827, 0.11693, 0.07694, 0.05161, 0.03519, 0.12933, 0.08425, 0.10531, 0.075, 0.03496, 0.02968, 0.03104, 0.0467, 0.11012, 0.04319, 0.01513, 0.00866, 0.00308, 0.00905, 0.00289, 0.02576, 0.03286, 0.01304]\n",
      "    Avg Accuracies: [0.9958, 0.9917, 0.9875, 0.9875, 0.95, 0.9792, 0.9875, 0.9833, 1.0, 0.9875, 0.9833, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.9875, 0.9917, 0.9458, 0.9708, 0.9625, 0.9792, 0.9958, 0.9292, 0.9917, 1.0, 0.9875, 0.9875, 0.9958, 0.9833, 0.9833, 0.9667, 0.9958, 0.9792, 0.9708, 0.9333, 0.9542, 0.9833, 0.9958, 0.9875, 1.0, 0.9875, 0.9667, 1.0, 0.975, 0.9875, 0.9958, 0.9917, 0.975, 0.975, 0.9958, 0.9958, 1.0, 0.975, 0.9708, 1.0, 0.9875, 0.9792, 0.9792, 0.975, 0.9792, 0.9917, 0.975, 0.9542, 0.9958, 0.9792, 0.9708, 0.9958, 1.0, 0.9625, 0.9583, 0.9792, 0.9583, 0.9917, 0.9792, 0.9875, 0.9833, 0.9583, 1.0, 1.0, 0.9875, 1.0, 0.9958, 0.9958, 0.9917, 1.0, 0.9833, 0.95, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.975, 0.975, 1.0, 0.975, 0.9958, 0.9875, 0.9625, 0.9833, 0.9708, 0.9792, 0.9708, 1.0, 0.9917, 0.9625, 0.9917, 0.9792, 0.9667, 0.9542, 0.9875, 0.9958, 0.9958, 0.9875, 1.0, 0.9958, 0.9792, 0.9375, 0.975, 0.9917, 0.9875, 0.975, 1.0, 0.9667, 0.9875, 0.9958, 1.0, 0.9833, 0.9833, 0.9625, 0.975, 0.9958, 0.9958, 0.9917, 0.9625, 0.9833, 0.9792, 0.9875, 0.9958, 0.9833, 0.9917, 0.9833, 1.0, 0.9708, 0.9417, 0.9958, 0.9958, 0.9625, 1.0, 0.9958, 0.9833, 0.975, 0.9833, 0.9833, 0.975, 0.9792, 0.9708, 0.9833, 0.9875, 0.9792, 0.9625, 1.0, 0.9667, 0.9458, 0.9958, 0.9875, 0.9958, 0.9958, 0.9833, 0.9875, 0.9792, 0.9625, 0.9875, 0.9917, 0.9958, 0.9708, 0.925, 0.9875, 0.9875, 0.9875, 0.9875, 0.9875, 0.9958, 0.9958, 0.9917, 0.9625, 0.9625, 0.9667, 0.9625, 0.9917, 0.9792, 0.9875, 0.975, 0.9958, 0.9917, 0.9583, 0.9833, 0.9792, 0.9875, 0.9792, 0.9917, 0.9625, 0.9708, 0.9958, 0.9417, 0.975, 0.9958, 1.0, 0.9833, 0.9917, 1.0, 0.9792, 0.9792, 0.9958, 0.9958, 0.9792, 0.9458, 0.9917, 0.9958, 0.9417, 0.9458, 1.0, 0.9708, 0.9583, 0.9917, 1.0, 0.9917, 0.9667, 0.9792, 0.9958, 0.9958, 0.9583, 0.9708, 0.9792, 0.9792, 0.9917, 0.9958, 1.0, 0.9958, 0.975, 0.9917, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9917, 0.9958]\n",
      "\n",
      "Epoch 9/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.031, 0.0667, 0.03066, 0.03853, 0.08108, 0.04407, 0.06208, 0.03372, 0.01364, 0.02693, 0.04314, 0.03273, 0.04891, 0.06261, 0.03742, 0.08304, 0.05574, 0.03059, 0.10272, 0.03162, 0.06426, 0.05777, 0.03432, 0.15986, 0.04476, 0.01067, 0.04388, 0.04683, 0.03168, 0.0578, 0.02028, 0.09421, 0.03294, 0.06395, 0.1063, 0.10196, 0.19524, 0.0377, 0.02042, 0.0596, 0.00923, 0.03828, 0.07761, 0.01412, 0.06926, 0.02896, 0.03351, 0.05543, 0.0568, 0.08458, 0.02304, 0.04574, 0.01196, 0.04394, 0.04412, 0.01501, 0.05284, 0.06106, 0.07912, 0.09912, 0.05127, 0.04609, 0.04659, 0.07581, 0.02377, 0.06683, 0.08279, 0.01572, 0.01738, 0.08198, 0.06707, 0.041, 0.0525, 0.05158, 0.05392, 0.04268, 0.0377, 0.16699, 0.01389, 0.01503, 0.04156, 0.01018, 0.04226, 0.02449, 0.04239, 0.00893, 0.05827, 0.1312, 0.01382, 0.03908, 0.02683, 0.01954, 0.05537, 0.06879, 0.07012, 0.01602, 0.07655, 0.01529, 0.02497, 0.1161, 0.03789, 0.06563, 0.04965, 0.10437, 0.01686, 0.02407, 0.0752, 0.04562, 0.02782, 0.0808, 0.12766, 0.04362, 0.02517, 0.05219, 0.02334, 0.01918, 0.03114, 0.06032, 0.23028, 0.03462, 0.02968, 0.04956, 0.06812, 0.03677, 0.11087, 0.0651, 0.03578, 0.01574, 0.05195, 0.07975, 0.08566, 0.08074, 0.03126, 0.02764, 0.02421, 0.05931, 0.05997, 0.0596, 0.01975, 0.02501, 0.04101, 0.02382, 0.05609, 0.02792, 0.07447, 0.07899, 0.05038, 0.0339, 0.05159, 0.00675, 0.03191, 0.04801, 0.09987, 0.06058, 0.06266, 0.09116, 0.05846, 0.07384, 0.04773, 0.05379, 0.05259, 0.11037, 0.00973, 0.09722, 0.07278, 0.02751, 0.03411, 0.02309, 0.03048, 0.05581, 0.13627, 0.04393, 0.09965, 0.02846, 0.01664, 0.03752, 0.06903, 0.13464, 0.05086, 0.03399, 0.04611, 0.03765, 0.03096, 0.01933, 0.04128, 0.03607, 0.06561, 0.06465, 0.04503, 0.08272, 0.05158, 0.07779, 0.02825, 0.05864, 0.01597, 0.02891, 0.07747, 0.04495, 0.05939, 0.03799, 0.04995, 0.05755, 0.07308, 0.12716, 0.03037, 0.13948, 0.04818, 0.02369, 0.03047, 0.05152, 0.0431, 0.01497, 0.05213, 0.06046, 0.02532, 0.02166, 0.05024, 0.12582, 0.03732, 0.03692, 0.12954, 0.08095, 0.01483, 0.08318, 0.10394, 0.01863, 0.00524, 0.03746, 0.1049, 0.05475, 0.03008, 0.02111, 0.10188, 0.04338, 0.09434, 0.0356, 0.0212, 0.01903, 0.03429, 0.03515, 0.10482, 0.0291, 0.0174, 0.00461, 0.00203, 0.00635, 0.00237, 0.01455, 0.02026, 0.00679]\n",
      "    Avg Accuracies: [1.0, 0.975, 0.9958, 1.0, 0.9708, 0.9917, 0.9917, 0.9917, 1.0, 0.9958, 0.9917, 0.9958, 0.9917, 0.9792, 0.9917, 0.975, 0.9833, 0.9958, 0.9625, 0.9958, 0.9833, 0.9917, 1.0, 0.9583, 0.9875, 1.0, 0.9875, 0.9917, 0.9958, 0.9875, 1.0, 0.9708, 1.0, 0.9958, 0.9583, 0.9708, 0.9333, 0.9917, 0.9958, 0.9917, 1.0, 0.9917, 0.9792, 1.0, 0.9833, 1.0, 0.9958, 0.9875, 0.9917, 0.9708, 1.0, 0.9917, 1.0, 0.9917, 0.9958, 1.0, 0.9917, 0.9875, 0.9833, 0.975, 0.9833, 0.9958, 0.9875, 0.9875, 1.0, 0.9833, 0.9875, 1.0, 1.0, 0.9708, 0.9833, 0.9875, 0.9917, 0.9875, 0.9917, 0.9917, 0.9917, 0.9542, 1.0, 1.0, 0.9875, 1.0, 0.9917, 1.0, 0.9958, 1.0, 0.9917, 0.9625, 1.0, 0.9875, 0.9917, 1.0, 0.9917, 0.9833, 0.9833, 1.0, 0.975, 1.0, 1.0, 0.9667, 0.9958, 0.9833, 0.9875, 0.9667, 0.9958, 0.9958, 0.9792, 0.9958, 1.0, 0.9833, 0.9583, 0.9958, 0.9958, 0.9875, 1.0, 1.0, 1.0, 0.9875, 0.925, 0.9958, 0.9958, 0.9875, 0.9792, 0.9958, 0.9667, 0.9833, 0.9958, 1.0, 0.9917, 0.975, 0.9833, 0.9833, 0.9958, 1.0, 1.0, 0.9875, 0.9875, 0.9833, 1.0, 1.0, 0.9958, 1.0, 0.9875, 0.9958, 0.975, 0.975, 0.9917, 0.9917, 0.9833, 1.0, 0.9958, 0.9875, 0.9708, 0.9917, 0.9833, 0.975, 0.9875, 0.9875, 0.9958, 0.9833, 0.9833, 0.9583, 1.0, 0.975, 0.9833, 1.0, 1.0, 1.0, 0.9958, 0.9875, 0.9542, 0.9958, 0.9667, 0.9958, 1.0, 0.9917, 0.9792, 0.95, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9875, 0.9917, 0.9917, 0.9792, 0.9958, 0.9875, 0.9875, 0.9792, 1.0, 0.9833, 1.0, 1.0, 0.975, 1.0, 0.9875, 0.9917, 0.9917, 0.9875, 0.9833, 0.9667, 1.0, 0.9583, 0.9958, 1.0, 0.9958, 0.9792, 0.9958, 1.0, 0.9958, 0.9917, 1.0, 0.9958, 0.9875, 0.9583, 0.9917, 0.9875, 0.9583, 0.9792, 1.0, 0.9792, 0.9667, 1.0, 1.0, 0.9958, 0.9583, 0.9917, 0.9958, 1.0, 0.9667, 1.0, 0.975, 1.0, 0.9958, 1.0, 0.9917, 0.9958, 0.9667, 0.9958, 0.9958, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr         = 3e-2\n",
    "n_epochs   = 10\n",
    "batch_size = 30\n",
    "\n",
    "teacher_dataloaders = [data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True) for dataset in teacher_datasets]\n",
    "teacher_optimizers  = [optim.Adam(model.parameters(), lr=lr) for model in teachers]\n",
    "criterion           = nn.CrossEntropyLoss()\n",
    "\n",
    "for model in teachers:\n",
    "    model.train()\n",
    "\n",
    "teachers_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    avg_losses      = []\n",
    "    avg_accuracies  = []\n",
    "\n",
    "    for i_model in range(n_teachers):\n",
    "        instance_count = 0\n",
    "        total_loss     = 0.\n",
    "        correct_count  = 0\n",
    "\n",
    "        model      = teachers[i_model]\n",
    "        dataloader = teacher_dataloaders[i_model]\n",
    "        optimizer  = teacher_optimizers[i_model]\n",
    "\n",
    "        n_batches = len(dataloader)\n",
    "        _prev_str_len = 0\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            _batch_str = \"Teacher {:d}/{:d}: ({:d}/{:d})\".format(i_model, n_teachers-1, i, n_batches-1)\n",
    "            print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "            _prev_str_len = len(_batch_str)\n",
    "\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs  = model(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            \n",
    "            correct_count += (preds == labels).sum().item()\n",
    "\n",
    "        avg_losses.append(total_loss / instance_count)\n",
    "        avg_accuracies.append(correct_count / instance_count)\n",
    "\n",
    "    _epoch_str = \"Epoch {:d}/{:d}\".format(i_epoch, n_epochs-1)\n",
    "    _epoch_str += ' ' * (_prev_str_len - len(_epoch_str))\n",
    "    print(_epoch_str)\n",
    "    print(\"    Avg Losses:\", [round(avg_loss, 5) for avg_loss in avg_losses])\n",
    "    print(\"    Avg Accuracies:\", [round(avg_acc, 4) for avg_acc in avg_accuracies])\n",
    "    print()\n",
    "\n",
    "    teachers_train_history['avg_losses'][i_epoch]     = avg_losses\n",
    "    teachers_train_history['avg_accuracies'][i_epoch] = avg_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:38:26.116908Z",
     "start_time": "2019-06-22T14:38:26.108973Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def aggregate_counts(img):\n",
    "    assert 3 <= img.dim() <= 4\n",
    "    if img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    else:\n",
    "        assert img.size(0) == 1\n",
    "\n",
    "    img = img.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in teachers:\n",
    "            model.eval()\n",
    "            preds_list.append(model(img).argmax(dim=1).view(1).cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(preds_list, dim=0)\n",
    "    \n",
    "    counts = torch.bincount(preds_tensor, minlength=10)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:38:28.113834Z",
     "start_time": "2019-06-22T14:38:26.119388Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/0 - Teacher 249/249\n",
      "\n",
      "Average Loss: 0.7430603544921875\n",
      "Average Accuracy: 0.814704\n",
      "\n",
      "Aggregate Accuracy: 0.9639999866485596\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "# Teacher Test\n",
    "if True:\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    preds_lists_list = []\n",
    "    labels_list      = []\n",
    "\n",
    "    n_batches = len(test_dataloader)\n",
    "    _prev_str_len = 0\n",
    "    for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels_list.append(labels)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for j, model in enumerate(teachers):\n",
    "                instance_count += imgs.size(0)\n",
    "\n",
    "                _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "                print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "                _prev_str_len = len(_progress_str)\n",
    "\n",
    "                outs  = model(imgs)\n",
    "                preds = outs.argmax(dim=1)\n",
    "                preds_list.append(preds.cpu())\n",
    "\n",
    "                total_loss += criterion(outs, labels).item()\n",
    "                correct_count += (preds == labels).sum().item()\n",
    "        preds_lists_list.append(preds_list)\n",
    "\n",
    "    preds_tensor = torch.cat([torch.stack(preds_list, dim=0) for preds_list in preds_lists_list], dim=1)\n",
    "    preds_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=preds_tensor.numpy()))\n",
    "\n",
    "    aggregate_preds = preds_counts.argmax(dim=0)\n",
    "    labels          = torch.cat(labels_list, dim=0)\n",
    "\n",
    "    aggregate_acc = (aggregate_preds == labels).float().mean().item()\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Average Loss:\", total_loss / instance_count)\n",
    "    print(\"Average Accuracy:\", correct_count / instance_count)\n",
    "    print()\n",
    "    print(\"Aggregate Accuracy:\", aggregate_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch 0/0 - Teacher 249/249\n",
    "\n",
    "Average Loss: 0.7504612662353516\n",
    "Average Accuracy: 0.814112\n",
    "\n",
    "Aggregate Accuracy: 0.9670000076293945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:38:50.651509Z",
     "start_time": "2019-06-22T14:38:28.116776Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/17 - Teacher 249/249\n",
      "tensor([[7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 5, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        ...,\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 4, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0]])\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "dataloader = data.DataLoader(student_dataset, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "batches_of_preds = []\n",
    "\n",
    "n_batches = len(dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, _) in enumerate(dataloader):\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    batch_of_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            batch_of_preds.append(preds.cpu())\n",
    "    \n",
    "    batches_of_preds.append(batch_of_preds)\n",
    "        \n",
    "label_preds = torch.cat(\n",
    "    [torch.stack([preds for preds in batch_of_preds], dim=0)\n",
    "     for batch_of_preds in batches_of_preds],\n",
    "    dim=1)\n",
    "\n",
    "print()\n",
    "print(label_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:38:50.719494Z",
     "start_time": "2019-06-22T14:38:50.653493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   0,  ...,   0,   2, 238],\n",
      "        [  0,   3, 249,  ...,   0,   0,   0],\n",
      "        [  0, 225,   0,  ...,   0,   2,   4],\n",
      "        ...,\n",
      "        [250,   0,   0,  ...,   0,  16,   0],\n",
      "        [  0,   7,   0,  ...,   0,   8,   2],\n",
      "        [  0,   0,   0,  ...,   0, 206,   0]])\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=label_preds.numpy()))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:41:04.927637Z",
     "start_time": "2019-06-22T14:41:04.899365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 6, 9, 0])\n",
      "\n",
      "Noisy Accuracy Against Predictions: 0.9725555777549744\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "\n",
    "noise_dist = dists.Laplace(loc=torch.zeros([], dtype=torch.float),\n",
    "                           scale=torch.full([], 1 / epsilon, dtype=torch.float))\n",
    "\n",
    "noisy_counts = label_counts.float() + noise_dist.sample([10, label_counts.size(1)])\n",
    "\n",
    "generated_labels = noisy_counts.argmax(dim=0)\n",
    "print(generated_labels)\n",
    "print()\n",
    "print(\"Noisy Accuracy Against Predictions:\", (generated_labels == label_counts.argmax(dim=0)).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:41:25.929692Z",
     "start_time": "2019-06-22T14:41:25.926220Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:41:27.070385Z",
     "start_time": "2019-06-22T14:41:27.042094Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(max_train_subset_size, n_new_labels_per_epoch, n_updates_per_epoch, lr, weight_decay, epsilon):\n",
    "    spec_dict = {\n",
    "        \"max_size\": max_train_subset_size,\n",
    "        \"n_new_labels\": n_new_labels_per_epoch,\n",
    "        \"n_updates\": n_updates_per_epoch,\n",
    "        \"lr\": lr,\n",
    "        \"wd\": weight_decay,\n",
    "        \"eps\": epsilon\n",
    "    }\n",
    "\n",
    "    student = MNISTClassifier().to(device)\n",
    "    \n",
    "    laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "    init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "    n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "    student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "    student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "    student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "    student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                                   batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "    student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    for i_epoch in range(n_total_epochs):\n",
    "        if i_epoch == 0:\n",
    "            new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "        else:\n",
    "            max_probs_list = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, _ in student_unlabeled_dataloader:\n",
    "                    imgs = imgs.to(device)\n",
    "\n",
    "                    outs  = student(imgs)\n",
    "                    probs = outs.softmax(dim=1)\n",
    "\n",
    "                    max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "            max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "\n",
    "            new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                                 max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "        for idx in new_label_indices:\n",
    "            student_labeled_dataset.indices.append(idx)\n",
    "            student_unlabeled_dataset.indices.remove(idx)\n",
    "            label_pred_counts = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28))\n",
    "            noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "            mnist_testset.targets[idx] = noisy_label\n",
    "\n",
    "        student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "\n",
    "        for i_update in range(n_updates_per_epoch):\n",
    "            imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs  = student(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "            student_optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "    student.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    for imgs, labels in test_dataloader:\n",
    "        instance_count += imgs.size(0)\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs  = student(imgs)\n",
    "\n",
    "        total_loss += criterion(outs, labels).item()\n",
    "\n",
    "        preds = outs.argmax(dim=1)\n",
    "\n",
    "        correct_count += (preds == labels).sum().item()\n",
    "\n",
    "    print(spec_dict)\n",
    "    print(\"    Average Loss:\", total_loss / instance_count)\n",
    "    print(\"    Average Accuracy:\", correct_count / instance_count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-22T14:44:27.953Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.015296291589737\n",
      "    Average Accuracy: 0.704\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2261069943904876\n",
      "    Average Accuracy: 0.722\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0697530851364137\n",
      "    Average Accuracy: 0.76\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6763886561393738\n",
      "    Average Accuracy: 0.8\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2667924003601074\n",
      "    Average Accuracy: 0.715\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5068216601610183\n",
      "    Average Accuracy: 0.746\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0086140575408935\n",
      "    Average Accuracy: 0.744\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1966932644844055\n",
      "    Average Accuracy: 0.742\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.5044769134521485\n",
      "    Average Accuracy: 0.657\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1489041194915772\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4138138420581818\n",
      "    Average Accuracy: 0.737\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0171754080057145\n",
      "    Average Accuracy: 0.811\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7384055188894272\n",
      "    Average Accuracy: 0.811\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.51355371761322\n",
      "    Average Accuracy: 0.682\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.9287724148631096\n",
      "    Average Accuracy: 0.771\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5315443930625916\n",
      "    Average Accuracy: 0.558\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.834123566865921\n",
      "    Average Accuracy: 0.766\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8914840240478515\n",
      "    Average Accuracy: 0.756\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7072281731367112\n",
      "    Average Accuracy: 0.77\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9032845191955566\n",
      "    Average Accuracy: 0.749\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.3893793699741364\n",
      "    Average Accuracy: 0.808\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8880495252609253\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5042085375785827\n",
      "    Average Accuracy: 0.69\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.070411647796631\n",
      "    Average Accuracy: 0.617\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7840498871803284\n",
      "    Average Accuracy: 0.771\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2557212972640992\n",
      "    Average Accuracy: 0.722\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.219761826276779\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.3792901058197022\n",
      "    Average Accuracy: 0.637\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2277094845175742\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6192728449702263\n",
      "    Average Accuracy: 0.752\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7767430605888367\n",
      "    Average Accuracy: 0.806\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9051151208281517\n",
      "    Average Accuracy: 0.77\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.120322793006897\n",
      "    Average Accuracy: 0.714\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7599764549732209\n",
      "    Average Accuracy: 0.846\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7989425575733184\n",
      "    Average Accuracy: 0.844\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9435012738853693\n",
      "    Average Accuracy: 0.842\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8727575578689575\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1190993342399598\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0182386243641377\n",
      "    Average Accuracy: 0.815\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8027935571670533\n",
      "    Average Accuracy: 0.818\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0254743152856827\n",
      "    Average Accuracy: 0.81\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0815103952884675\n",
      "    Average Accuracy: 0.858\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8896537908315658\n",
      "    Average Accuracy: 0.824\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0487456014156342\n",
      "    Average Accuracy: 0.824\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9085236895382405\n",
      "    Average Accuracy: 0.888\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7170870597362519\n",
      "    Average Accuracy: 0.797\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8669781754016876\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.29668583881855\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7999036383628845\n",
      "    Average Accuracy: 0.798\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8207391225099564\n",
      "    Average Accuracy: 0.817\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 15, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9252756263613701\n",
      "    Average Accuracy: 0.81\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7185291236639023\n",
      "    Average Accuracy: 0.832\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1706596674919127\n",
      "    Average Accuracy: 0.786\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0094034887552261\n",
      "    Average Accuracy: 0.853\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9413001240491867\n",
      "    Average Accuracy: 0.749\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.712588849902153\n",
      "    Average Accuracy: 0.839\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 25, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0195666980743407\n",
      "    Average Accuracy: 0.849\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8391722503900528\n",
      "    Average Accuracy: 0.8\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1345086097717285\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 4, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1452719852328301\n",
      "    Average Accuracy: 0.844\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6104736804962159\n",
      "    Average Accuracy: 0.867\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9386390643715858\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.014727367401123\n",
      "    Average Accuracy: 0.859\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8415995667278766\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8991554935574532\n",
      "    Average Accuracy: 0.832\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 15, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8008348705768585\n",
      "    Average Accuracy: 0.869\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.5628045307397842\n",
      "    Average Accuracy: 0.863\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6064711617529392\n",
      "    Average Accuracy: 0.873\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2049650159478187\n",
      "    Average Accuracy: 0.831\n",
      "\n",
      "{'max_size': 200, 'n_new_labels': 3, 'n_updates': 25, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1119895285367967\n",
      "    Average Accuracy: 0.81\n",
      "\n",
      "70/89\r"
     ]
    }
   ],
   "source": [
    "grid_spec = {\n",
    "        \"max_train_subset_size\":  [100, 150, 200],\n",
    "        \"n_new_labels_per_epoch\": [3, 4],\n",
    "        \"n_updates_per_epoch\":    [10, 15, 20, 25, 30],\n",
    "        \"lr\":                     [5e-3, 1e-2, 2e-2],\n",
    "        \"weight_decay\":           [0],\n",
    "        \"epsilon\":                [0.05]\n",
    "}\n",
    "\n",
    "spec_iter = itertools.product(grid_spec[\"max_train_subset_size\"],\n",
    "                              grid_spec[\"n_new_labels_per_epoch\"],\n",
    "                              grid_spec[\"n_updates_per_epoch\"],\n",
    "                              grid_spec[\"lr\"],\n",
    "                              grid_spec[\"weight_decay\"],\n",
    "                              grid_spec[\"epsilon\"])\n",
    "\n",
    "n_specs = np.prod([len(options) for options in grid_spec.values()])\n",
    "\n",
    "for i, spec in enumerate(spec_iter):\n",
    "    print(\"{:d}/{:d}\".format(i, n_specs-1), end='\\r')\n",
    "    train(*spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T20:07:43.488310Z",
     "start_time": "2019-06-21T20:07:43.478862Z"
    }
   },
   "outputs": [],
   "source": [
    "student = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T20:09:39.219545Z",
     "start_time": "2019-06-21T20:07:44.123930Z"
    },
    "code_folding": [
     26
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49 - Number of Labeled Data: 2\n",
      "    Update 0 - Loss = 2.338653, Accuracy = 0.0\n",
      "    Update 1 - Loss = 1.552873, Accuracy = 1.0\n",
      "    Update 2 - Loss = 1.101398, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.746303, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.487096, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.314154, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.207640, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.149181, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.104536, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.076262, Accuracy = 1.0\n",
      "Epoch 1/49 - Number of Labeled Data: 4\n",
      "    Update 0 - Loss = 1.301574, Accuracy = 0.5\n",
      "    Update 1 - Loss = 1.089545, Accuracy = 0.5\n",
      "    Update 2 - Loss = 0.858703, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.648914, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.468678, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.327084, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.225381, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.156469, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.112128, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.083712, Accuracy = 1.0\n",
      "Epoch 2/49 - Number of Labeled Data: 6\n",
      "    Update 0 - Loss = 0.751547, Accuracy = 0.8333\n",
      "    Update 1 - Loss = 0.645515, Accuracy = 0.8333\n",
      "    Update 2 - Loss = 0.515573, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.391072, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.289907, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.213941, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.156881, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.115802, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.087956, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.071464, Accuracy = 1.0\n",
      "Epoch 3/49 - Number of Labeled Data: 8\n",
      "    Update 0 - Loss = 0.668311, Accuracy = 0.75\n",
      "    Update 1 - Loss = 0.622445, Accuracy = 0.75\n",
      "    Update 2 - Loss = 0.551728, Accuracy = 0.875\n",
      "    Update 3 - Loss = 0.469295, Accuracy = 0.875\n",
      "    Update 4 - Loss = 0.390690, Accuracy = 0.875\n",
      "    Update 5 - Loss = 0.322158, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.265127, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.219062, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.181474, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.152132, Accuracy = 1.0\n",
      "Epoch 4/49 - Number of Labeled Data: 10\n",
      "    Update 0 - Loss = 0.586566, Accuracy = 0.8\n",
      "    Update 1 - Loss = 0.529241, Accuracy = 0.8\n",
      "    Update 2 - Loss = 0.456313, Accuracy = 0.9\n",
      "    Update 3 - Loss = 0.382450, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.316271, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.260182, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.213226, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.175962, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.147718, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.127378, Accuracy = 1.0\n",
      "Epoch 5/49 - Number of Labeled Data: 12\n",
      "    Update 0 - Loss = 0.458334, Accuracy = 0.8333\n",
      "    Update 1 - Loss = 0.420796, Accuracy = 0.8333\n",
      "    Update 2 - Loss = 0.369148, Accuracy = 0.9167\n",
      "    Update 3 - Loss = 0.310781, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.253805, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.206136, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.170198, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.146172, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.131332, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.123139, Accuracy = 1.0\n",
      "Epoch 6/49 - Number of Labeled Data: 14\n",
      "    Update 0 - Loss = 0.418052, Accuracy = 0.8571\n",
      "    Update 1 - Loss = 0.398700, Accuracy = 0.9286\n",
      "    Update 2 - Loss = 0.366196, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.329394, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.294383, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.263397, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.236805, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.215746, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.199137, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.186543, Accuracy = 1.0\n",
      "Epoch 7/49 - Number of Labeled Data: 16\n",
      "    Update 0 - Loss = 0.436736, Accuracy = 0.875\n",
      "    Update 1 - Loss = 0.420644, Accuracy = 0.875\n",
      "    Update 2 - Loss = 0.400323, Accuracy = 0.9375\n",
      "    Update 3 - Loss = 0.376968, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.351830, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.327060, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.303411, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.281601, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.261874, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.245140, Accuracy = 1.0\n",
      "Epoch 8/49 - Number of Labeled Data: 18\n",
      "    Update 0 - Loss = 0.455925, Accuracy = 0.8889\n",
      "    Update 1 - Loss = 0.430368, Accuracy = 0.9444\n",
      "    Update 2 - Loss = 0.399211, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.368176, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.340356, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.317996, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.300735, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.289072, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.281144, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.274216, Accuracy = 1.0\n",
      "Epoch 9/49 - Number of Labeled Data: 20\n",
      "    Update 0 - Loss = 0.441736, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.424111, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.401988, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.381697, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.369162, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.356252, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.348294, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.340688, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.331175, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.322125, Accuracy = 1.0\n",
      "Epoch 10/49 - Number of Labeled Data: 22\n",
      "    Update 0 - Loss = 0.488921, Accuracy = 0.9091\n",
      "    Update 1 - Loss = 0.472878, Accuracy = 0.9091\n",
      "    Update 2 - Loss = 0.450004, Accuracy = 0.9545\n",
      "    Update 3 - Loss = 0.425284, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.403690, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.385991, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.373282, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.363604, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.355450, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.348104, Accuracy = 1.0\n",
      "Epoch 11/49 - Number of Labeled Data: 24\n",
      "    Update 0 - Loss = 0.479140, Accuracy = 0.9583\n",
      "    Update 1 - Loss = 0.462911, Accuracy = 0.9583\n",
      "    Update 2 - Loss = 0.441985, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.424456, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.410386, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.396338, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.384231, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.375768, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.369885, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.364186, Accuracy = 1.0\n",
      "Epoch 12/49 - Number of Labeled Data: 26\n",
      "    Update 0 - Loss = 0.512712, Accuracy = 0.9231\n",
      "    Update 1 - Loss = 0.487639, Accuracy = 0.9615\n",
      "    Update 2 - Loss = 0.460109, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.437321, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.416238, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.398096, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.386629, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.378347, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.370338, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.362570, Accuracy = 1.0\n",
      "Epoch 13/49 - Number of Labeled Data: 28\n",
      "    Update 0 - Loss = 0.500946, Accuracy = 0.9643\n",
      "    Update 1 - Loss = 0.482058, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.460535, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.443020, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.430686, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.419550, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.408998, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.401122, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.396313, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.389760, Accuracy = 1.0\n",
      "Epoch 14/49 - Number of Labeled Data: 30\n",
      "    Update 0 - Loss = 0.508707, Accuracy = 0.9333\n",
      "    Update 1 - Loss = 0.486278, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.463054, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.447167, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.433575, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.421409, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.412697, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.404620, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.397054, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.390307, Accuracy = 1.0\n",
      "Epoch 15/49 - Number of Labeled Data: 32\n",
      "    Update 0 - Loss = 0.485326, Accuracy = 0.9688\n",
      "    Update 1 - Loss = 0.467323, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.450585, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.437996, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.429806, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.423795, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.417704, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.411607, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.405885, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 9 - Loss = 0.400655, Accuracy = 1.0\n",
      "Epoch 16/49 - Number of Labeled Data: 34\n",
      "    Update 0 - Loss = 0.489888, Accuracy = 0.9706\n",
      "    Update 1 - Loss = 0.473369, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.457185, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.446634, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.438530, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.433696, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.427910, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.420705, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.414927, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.408941, Accuracy = 1.0\n",
      "Epoch 17/49 - Number of Labeled Data: 36\n",
      "    Update 0 - Loss = 0.490056, Accuracy = 0.9444\n",
      "    Update 1 - Loss = 0.474666, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.459653, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.450884, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.442996, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.437017, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.429970, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.425239, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.418654, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.415015, Accuracy = 1.0\n",
      "Epoch 18/49 - Number of Labeled Data: 38\n",
      "    Update 0 - Loss = 0.505228, Accuracy = 0.9474\n",
      "    Update 1 - Loss = 0.491857, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.475935, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.463892, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.457329, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.448007, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.440516, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.434975, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.429201, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.422763, Accuracy = 1.0\n",
      "Epoch 19/49 - Number of Labeled Data: 40\n",
      "    Update 0 - Loss = 0.506681, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.482751, Accuracy = 0.975\n",
      "    Update 2 - Loss = 0.466942, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.458900, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.452580, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.448441, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.438875, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.432008, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.426556, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.423574, Accuracy = 1.0\n",
      "Epoch 20/49 - Number of Labeled Data: 42\n",
      "    Update 0 - Loss = 0.499563, Accuracy = 0.9524\n",
      "    Update 1 - Loss = 0.481904, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.472550, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.465387, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.456955, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.448441, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.441377, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.437327, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.433125, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.427298, Accuracy = 1.0\n",
      "Epoch 21/49 - Number of Labeled Data: 44\n",
      "    Update 0 - Loss = 0.499284, Accuracy = 0.9545\n",
      "    Update 1 - Loss = 0.480362, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.465372, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.461316, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.456961, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.448358, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.443604, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.435394, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.432738, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.429057, Accuracy = 1.0\n",
      "Epoch 22/49 - Number of Labeled Data: 46\n",
      "    Update 0 - Loss = 0.494952, Accuracy = 0.9565\n",
      "    Update 1 - Loss = 0.480039, Accuracy = 0.9783\n",
      "    Update 2 - Loss = 0.471304, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.462470, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.458013, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.449707, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.444174, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.440526, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.438940, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.435422, Accuracy = 1.0\n",
      "Epoch 23/49 - Number of Labeled Data: 48\n",
      "    Update 0 - Loss = 0.499791, Accuracy = 0.9792\n",
      "    Update 1 - Loss = 0.486282, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.481903, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.476958, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.464197, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.459527, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.458733, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.448693, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.442250, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.440049, Accuracy = 1.0\n",
      "Epoch 24/49 - Number of Labeled Data: 50\n",
      "    Update 0 - Loss = 0.498750, Accuracy = 0.98\n",
      "    Update 1 - Loss = 0.483580, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.472825, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.469342, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.463824, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.462702, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.453879, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.446316, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.444953, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.437401, Accuracy = 1.0\n",
      "Epoch 25/49 - Number of Labeled Data: 52\n",
      "    Update 0 - Loss = 0.497697, Accuracy = 0.9615\n",
      "    Update 1 - Loss = 0.491166, Accuracy = 0.9808\n",
      "    Update 2 - Loss = 0.477437, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.471831, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.466225, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.460012, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.452999, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.448114, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.440312, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.436531, Accuracy = 1.0\n",
      "Epoch 26/49 - Number of Labeled Data: 54\n",
      "    Update 0 - Loss = 0.491973, Accuracy = 0.963\n",
      "    Update 1 - Loss = 0.475639, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.465989, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.461879, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.457717, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.446972, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.446151, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.437337, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.437578, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.427733, Accuracy = 1.0\n",
      "Epoch 27/49 - Number of Labeled Data: 56\n",
      "    Update 0 - Loss = 0.482105, Accuracy = 0.9643\n",
      "    Update 1 - Loss = 0.471431, Accuracy = 0.9821\n",
      "    Update 2 - Loss = 0.465432, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.460496, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.454722, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.447531, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.441859, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.437803, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.434211, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.429635, Accuracy = 1.0\n",
      "Epoch 28/49 - Number of Labeled Data: 58\n",
      "    Update 0 - Loss = 0.486170, Accuracy = 0.9655\n",
      "    Update 1 - Loss = 0.475413, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.463468, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.459519, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.454614, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.451589, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.442317, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.440774, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.439104, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.438253, Accuracy = 1.0\n",
      "Epoch 29/49 - Number of Labeled Data: 60\n",
      "    Update 0 - Loss = 0.480686, Accuracy = 0.9833\n",
      "    Update 1 - Loss = 0.464333, Accuracy = 0.9833\n",
      "    Update 2 - Loss = 0.458279, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.447966, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.440862, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.437867, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.432739, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.428168, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.426448, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.420129, Accuracy = 1.0\n",
      "Epoch 30/49 - Number of Labeled Data: 62\n",
      "    Update 0 - Loss = 0.471012, Accuracy = 0.9677\n",
      "    Update 1 - Loss = 0.457223, Accuracy = 0.9839\n",
      "    Update 2 - Loss = 0.451319, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.451021, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.445298, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.437802, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.438884, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.443521, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.431728, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.427598, Accuracy = 1.0\n",
      "Epoch 31/49 - Number of Labeled Data: 64\n",
      "    Update 0 - Loss = 0.480080, Accuracy = 0.9688\n",
      "    Update 1 - Loss = 0.464329, Accuracy = 0.9844\n",
      "    Update 2 - Loss = 0.462033, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.455981, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.450079, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.448617, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.444309, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.439373, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 8 - Loss = 0.430307, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.431741, Accuracy = 1.0\n",
      "Epoch 32/49 - Number of Labeled Data: 66\n",
      "    Update 0 - Loss = 0.467694, Accuracy = 0.9848\n",
      "    Update 1 - Loss = 0.454931, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.447458, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.446503, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.444823, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.439646, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.432144, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.430708, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.430268, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.422539, Accuracy = 1.0\n",
      "Epoch 33/49 - Number of Labeled Data: 68\n",
      "    Update 0 - Loss = 0.467577, Accuracy = 0.9706\n",
      "    Update 1 - Loss = 0.458398, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.450021, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.446302, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.448077, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.441004, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.433090, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.432628, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.428591, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.423551, Accuracy = 1.0\n",
      "Epoch 34/49 - Number of Labeled Data: 70\n",
      "    Update 0 - Loss = 0.474099, Accuracy = 0.9714\n",
      "    Update 1 - Loss = 0.470250, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.461452, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.457803, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.451093, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.442738, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.441627, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.436710, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.433232, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.427640, Accuracy = 1.0\n",
      "Epoch 35/49 - Number of Labeled Data: 72\n",
      "    Update 0 - Loss = 0.469238, Accuracy = 0.9861\n",
      "    Update 1 - Loss = 0.458283, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.449260, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.444701, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.438894, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.434663, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.433740, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.429036, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.423107, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.420805, Accuracy = 1.0\n",
      "Epoch 36/49 - Number of Labeled Data: 74\n",
      "    Update 0 - Loss = 0.474300, Accuracy = 0.973\n",
      "    Update 1 - Loss = 0.465917, Accuracy = 0.973\n",
      "    Update 2 - Loss = 0.460590, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.458899, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.454459, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.453547, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.449600, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.444148, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.443310, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.444167, Accuracy = 1.0\n",
      "Epoch 37/49 - Number of Labeled Data: 76\n",
      "    Update 0 - Loss = 0.480176, Accuracy = 0.9737\n",
      "    Update 1 - Loss = 0.471443, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.462381, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.453934, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.456936, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.450137, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.446740, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.440629, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.438516, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.434156, Accuracy = 1.0\n",
      "Epoch 38/49 - Number of Labeled Data: 78\n",
      "    Update 0 - Loss = 0.467837, Accuracy = 0.9872\n",
      "    Update 1 - Loss = 0.460429, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.447903, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.442530, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.442709, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.439105, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.432328, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.428435, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.426125, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.420963, Accuracy = 1.0\n",
      "Epoch 39/49 - Number of Labeled Data: 80\n",
      "    Update 0 - Loss = 0.464644, Accuracy = 0.975\n",
      "    Update 1 - Loss = 0.454629, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.445242, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.434866, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.434041, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.429802, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.427317, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.423241, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.417035, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.415198, Accuracy = 1.0\n",
      "Epoch 40/49 - Number of Labeled Data: 82\n",
      "    Update 0 - Loss = 0.445787, Accuracy = 0.9878\n",
      "    Update 1 - Loss = 0.440406, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.434707, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.425276, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.423377, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.418460, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.414456, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.414581, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.413177, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.411775, Accuracy = 1.0\n",
      "Epoch 41/49 - Number of Labeled Data: 84\n",
      "    Update 0 - Loss = 0.443066, Accuracy = 0.9762\n",
      "    Update 1 - Loss = 0.435897, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.432566, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.431906, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.426519, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.425054, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.422423, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.420248, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.415143, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.418005, Accuracy = 1.0\n",
      "Epoch 42/49 - Number of Labeled Data: 86\n",
      "    Update 0 - Loss = 0.453955, Accuracy = 0.9767\n",
      "    Update 1 - Loss = 0.447228, Accuracy = 0.9884\n",
      "    Update 2 - Loss = 0.436670, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.433288, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.432260, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.429424, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.431094, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.422991, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.424441, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.429740, Accuracy = 1.0\n",
      "Epoch 43/49 - Number of Labeled Data: 88\n",
      "    Update 0 - Loss = 0.456109, Accuracy = 0.9773\n",
      "    Update 1 - Loss = 0.450015, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.454926, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.444495, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.442552, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.438091, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.432888, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.427339, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.428675, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.431322, Accuracy = 1.0\n",
      "Epoch 44/49 - Number of Labeled Data: 90\n",
      "    Update 0 - Loss = 0.459660, Accuracy = 0.9778\n",
      "    Update 1 - Loss = 0.451121, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.436302, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.434270, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.434960, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.428689, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.421642, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.420498, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.411194, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.409940, Accuracy = 1.0\n",
      "Epoch 45/49 - Number of Labeled Data: 92\n",
      "    Update 0 - Loss = 0.441576, Accuracy = 0.9891\n",
      "    Update 1 - Loss = 0.432512, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.429236, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.420568, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.419474, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.416713, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.415486, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.407844, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.407989, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.401421, Accuracy = 1.0\n",
      "Epoch 46/49 - Number of Labeled Data: 94\n",
      "    Update 0 - Loss = 0.437346, Accuracy = 0.9787\n",
      "    Update 1 - Loss = 0.428207, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.420733, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.421940, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.417407, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.412608, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.409139, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.405714, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.404821, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.402311, Accuracy = 1.0\n",
      "Epoch 47/49 - Number of Labeled Data: 96\n",
      "    Update 0 - Loss = 0.432337, Accuracy = 0.9792\n",
      "    Update 1 - Loss = 0.420220, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.419700, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.418672, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.413444, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.414798, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.411152, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 7 - Loss = 0.405405, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.407001, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.405819, Accuracy = 1.0\n",
      "Epoch 48/49 - Number of Labeled Data: 98\n",
      "    Update 0 - Loss = 0.436305, Accuracy = 0.9796\n",
      "    Update 1 - Loss = 0.421083, Accuracy = 0.9898\n",
      "    Update 2 - Loss = 0.427107, Accuracy = 0.9898\n",
      "    Update 3 - Loss = 0.422049, Accuracy = 0.9898\n",
      "    Update 4 - Loss = 0.415886, Accuracy = 0.9898\n",
      "    Update 5 - Loss = 0.416208, Accuracy = 0.9898\n",
      "    Update 6 - Loss = 0.416877, Accuracy = 0.9898\n",
      "    Update 7 - Loss = 0.414058, Accuracy = 0.9898\n",
      "    Update 8 - Loss = 0.407894, Accuracy = 0.9898\n",
      "    Update 9 - Loss = 0.408899, Accuracy = 0.9898\n",
      "Epoch 49/49 - Number of Labeled Data: 100\n",
      "    Update 0 - Loss = 0.436317, Accuracy = 0.97\n",
      "    Update 1 - Loss = 0.426153, Accuracy = 0.99\n",
      "    Update 2 - Loss = 0.429137, Accuracy = 0.99\n",
      "    Update 3 - Loss = 0.424593, Accuracy = 0.99\n",
      "    Update 4 - Loss = 0.423200, Accuracy = 0.99\n",
      "    Update 5 - Loss = 0.423244, Accuracy = 0.99\n",
      "    Update 6 - Loss = 0.420733, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.418795, Accuracy = 0.99\n",
      "    Update 8 - Loss = 0.423231, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.417039, Accuracy = 0.99\n"
     ]
    }
   ],
   "source": [
    "max_train_subset_size  = 100\n",
    "n_new_labels_per_epoch = 2\n",
    "n_updates_per_epoch    = 10\n",
    "lr                     = 5e-3\n",
    "weight_decay           = 1e-3\n",
    "epsilon                = 0.05\n",
    "\n",
    "laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                               batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "student.train()\n",
    "\n",
    "teacher_preds = []\n",
    "noisy_labels  = []\n",
    "student_train_history = {'n_labels': {}, 'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_total_epochs):\n",
    "    if i_epoch == 0:\n",
    "        new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "    else:\n",
    "        max_probs_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in student_unlabeled_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "\n",
    "                outs  = student(imgs)\n",
    "                probs = outs.softmax(dim=1)\n",
    "\n",
    "                max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "        max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "        \n",
    "        new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                             max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "    for idx in new_label_indices:\n",
    "        student_labeled_dataset.indices.append(idx)\n",
    "        student_unlabeled_dataset.indices.remove(idx)\n",
    "        label_pred_counts = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28))\n",
    "        noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "        mnist_testset.targets[idx] = noisy_label\n",
    "        teacher_preds.append(label_pred_counts)\n",
    "        noisy_labels.append(noisy_label)\n",
    "        \n",
    "    student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "    \n",
    "    print(\"Epoch {:d}/{:d} - Number of Labeled Data: {:d}\".format(i_epoch, n_total_epochs-1, len(student_labeled_dataset)))\n",
    "\n",
    "    student_train_history['n_labels'][i_epoch] = init_subset_size + (i_epoch * n_new_labels_per_epoch)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i_update in range(n_updates_per_epoch):\n",
    "        imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = student(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(\"    Update {:d} - Loss = {:.6f}, Accuracy = {:.4}\".format(i_update, loss.item(), accuracy))\n",
    "\n",
    "    student_train_history['avg_losses'][i_epoch]     = losses\n",
    "    student_train_history['avg_accuracies'][i_epoch] = accuracies\n",
    "\n",
    "teacher_preds = torch.stack(teacher_preds, dim=1)\n",
    "noisy_labels  = torch.tensor(noisy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T20:13:13.711482Z",
     "start_time": "2019-06-21T20:13:13.385611Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/33\n",
      "Average Loss: 1.386195161819458\n",
      "Average Accuracy: 0.606\n"
     ]
    }
   ],
   "source": [
    "student.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs   = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = student(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T19:55:35.278845Z",
     "start_time": "2019-06-21T19:55:30.181978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon: 5.30258509299405\n"
     ]
    }
   ],
   "source": [
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds, noisy_labels, epsilon)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Labels Using Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T13:04:10.946546Z",
     "start_time": "2019-06-22T13:03:49.746547Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/17 - Teacher 249/249\n",
      "tensor([[7, 0, 1,  ..., 6, 9, 0],\n",
      "        [7, 0, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        ...,\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 0, 1,  ..., 6, 9, 0]])\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "dataloader = data.DataLoader(student_dataset, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "batches_of_preds = []\n",
    "\n",
    "n_batches = len(dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, _) in enumerate(dataloader):\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    batch_of_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            batch_of_preds.append(preds.cpu())\n",
    "    \n",
    "    batches_of_preds.append(batch_of_preds)\n",
    "        \n",
    "label_preds = torch.cat(\n",
    "    [torch.stack([preds for preds in batch_of_preds], dim=0)\n",
    "     for batch_of_preds in batches_of_preds],\n",
    "    dim=1)\n",
    "\n",
    "print()\n",
    "print(label_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T16:40:06.332084Z",
     "start_time": "2019-06-20T16:40:06.325637Z"
    }
   },
   "source": [
    "### Get Label Counts for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T13:04:11.005107Z",
     "start_time": "2019-06-22T13:04:10.948032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   4,   0,  ...,   0,   1, 232],\n",
      "        [  0,   5, 248,  ...,   0,   0,   0],\n",
      "        [  0, 213,   1,  ...,   0,   1,   7],\n",
      "        ...,\n",
      "        [248,   0,   0,  ...,   0,  26,   0],\n",
      "        [  0,   7,   0,  ...,   0,   8,   0],\n",
      "        [  0,   0,   0,  ...,   0, 192,   0]])\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=label_preds.numpy()))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Labels from Noisy Counts with a Certain $\\epsilon$ Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:37:11.761761Z",
     "start_time": "2019-06-21T13:37:11.745428Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 6, 9, 0])\n",
      "\n",
      "Noisy Accuracy Against Predictions: 0.9427777528762817\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "\n",
    "noise_dist = dists.Laplace(loc=torch.zeros([], dtype=torch.float),\n",
    "                           scale=torch.full([], 1 / epsilon, dtype=torch.float))\n",
    "\n",
    "noisy_counts = label_counts.float() + noise_dist.sample([10, label_counts.size(1)])\n",
    "\n",
    "generated_labels = noisy_counts.argmax(dim=0)\n",
    "print(generated_labels)\n",
    "print()\n",
    "print(\"Noisy Accuracy Against Predictions:\", (generated_labels == label_counts.argmax(dim=0)).float().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PATE Analysis to Check Information Leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:41:50.200151Z",
     "start_time": "2019-06-21T13:41:07.951830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.30258509299405, 5.302585092994046)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pate.perform_analysis(label_preds[:, :100], generated_labels[:100], epsilon, delta=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the Generated Labels to the DP Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset.targets[dp_dataset.indices] = generated_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the DP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "lr       = 3e-3\n",
    "n_epochs = 10\n",
    "\n",
    "dp_optimizer = optim.Adam(dp_model.parameters(), lr=lr)\n",
    "criterion    = nn.CrossEntropyLoss()\n",
    "\n",
    "dp_model.train()\n",
    "\n",
    "dp_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    n_batches = len(dp_dataloader)\n",
    "    _prev_str_len = 0\n",
    "    for i, (imgs, labels) in enumerate(dp_dataloader):\n",
    "        _batch_str = \"Epoch {:d}/{:d}: ({:d}/{:d})\".format(i_epoch, n_epochs-1, i, n_batches-1)\n",
    "        print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "        _prev_str_len = len(_batch_str)\n",
    "\n",
    "        instance_count += imgs.size(0)\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = dp_model(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        dp_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        dp_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        correct_count += (preds == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / instance_count\n",
    "    avg_accuracy = correct_count / instance_count\n",
    "\n",
    "    print()\n",
    "    print(\"    Avg Loss: {:.6f}\".format(avg_loss))\n",
    "    print(\"    Avg Accuracy: {:.4f}\".format(avg_accuracy))\n",
    "    print()\n",
    "\n",
    "    dp_train_history['avg_losses'][i_epoch]     = avg_loss\n",
    "    dp_train_history['avg_accuracies'][i_epoch] = avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Result Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "dp_model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "# test_dataloader     = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "n_batches = len(dataloader)\n",
    "for i, (imgs, labels) in enumerate(data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs = imgs.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = model(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "    1. Split the training dataset into `n + 1` smaller datasets where `n` is the number of teacher models\n",
    "    2. Define a Dataset class and a DataLoader that can give batches of data for all `n` teacher datasets\n",
    "2. Define Model(s)\n",
    "    1. A simple ConvNet for both the main model and all teacher models\n",
    "    2. If too slow: custom `nn.Module` that can process `n` batches at once for all `n` teachers\n",
    "3. Train Teachers\n",
    "4. Label Unlabeled Training Dataset in a Differentially Private Manner\n",
    "    1. Generate raw labels\n",
    "    2. PATE analysis to find a proper `epsilon` value\n",
    "    3. Add proper noise to the label counts\n",
    "    4. Take the labels with most counts\n",
    "5. Train the Main Model On the Training Dataset with Generated Labels\n",
    "6. Test on the Test Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
