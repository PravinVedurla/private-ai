{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Project:\n",
    "\n",
    "For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:03:48.403642Z",
     "start_time": "2019-06-25T17:03:45.373036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:03:48.571324Z",
     "start_time": "2019-06-25T17:03:48.406122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 60000\n",
      "Test Set Size: 10000\n",
      "\n",
      "Min Data Value: tensor(0, dtype=torch.uint8)\n",
      "Max Data Value: tensor(255, dtype=torch.uint8)\n",
      "\n",
      "Train Label Counts: {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test Label Counts: {0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset  = datasets.MNIST(root='../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset.true_targets = mnist_testset.targets.clone() # data points that are considered \"unlabeled\" will be re-labeled by teachers later\n",
    "\n",
    "print(\"Training Set Size:\", len(mnist_trainset))\n",
    "print(\"Test Set Size:\", len(mnist_testset))\n",
    "print()\n",
    "print(\"Min Data Value:\", torch.min(mnist_trainset.data.min(), mnist_testset.data.min()))\n",
    "print(\"Max Data Value:\", torch.max(mnist_trainset.data.max(), mnist_testset.data.max()))\n",
    "print()\n",
    "print(\"Train Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_trainset.targets, return_counts=True))})\n",
    "print(\"Test Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_testset.targets, return_counts=True))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:03:48.592163Z",
     "start_time": "2019-06-25T17:03:48.573276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each teacher dataset: 240\n",
      "Size of the dataset available to the student: 9000\n",
      "Size of the test dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "n_teachers = 250\n",
    "\n",
    "_teacher_dataset_len = len(mnist_trainset) // n_teachers\n",
    "\n",
    "teacher_datasets = [data.Subset(mnist_trainset, list(range(i*_teacher_dataset_len, (i+1)*_teacher_dataset_len))) for i in range(n_teachers)]\n",
    "student_dataset  = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9))))\n",
    "test_dataset     = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9), len(mnist_testset))))\n",
    "\n",
    "print(\"Size of each teacher dataset:\", _teacher_dataset_len)\n",
    "print(\"Size of the dataset available to the student:\", len(student_dataset))\n",
    "print(\"Size of the test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:03:48.608986Z",
     "start_time": "2019-06-25T17:03:48.594602Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        # 1x28x28\n",
    "        self.bn0        = nn.BatchNorm2d(1)\n",
    "        self.conv0      = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.bn1        = nn.BatchNorm2d(5)\n",
    "        self.maxpool0   = nn.MaxPool2d(2)\n",
    "        # 5x14x14\n",
    "        self.conv1      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn2        = nn.BatchNorm2d(5)\n",
    "        self.maxpool1   = nn.MaxPool2d(2)\n",
    "        # 5x 7x 7\n",
    "        self.conv2      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn3        = nn.BatchNorm2d(5)\n",
    "        self.maxpool2   = nn.MaxPool2d(2, padding=1)\n",
    "        # 5x 4x 4 = 80\n",
    "        self.fc         = nn.Linear(80, 10)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(self.bn0(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.fc(x.view(-1, 80))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Teacher & DF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:03:52.345939Z",
     "start_time": "2019-06-25T17:03:48.610474Z"
    }
   },
   "outputs": [],
   "source": [
    "teachers      = [MNISTClassifier().to(device) for _ in range(n_teachers)]\n",
    "student       = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Teachers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:10:23.430065Z",
     "start_time": "2019-06-25T17:03:52.348916Z"
    },
    "code_folding": [
     12
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9             \n",
      "    Avg Losses: [2.21073, 2.23918, 2.28086, 2.15874, 2.23866, 2.31621, 2.30713, 2.18633, 2.17418, 2.16536, 2.21159, 2.13759, 2.29504, 2.13437, 2.26481, 2.26822, 2.36746, 1.982, 2.2323, 2.13046, 2.18558, 2.3023, 2.18393, 2.23326, 2.22305, 2.19719, 2.31659, 2.25757, 2.18945, 2.30273, 2.24863, 2.29796, 2.19766, 2.19736, 2.23516, 2.10273, 2.25671, 2.16019, 2.15332, 2.15617, 2.16629, 2.16903, 2.29986, 2.15375, 2.35322, 2.26402, 2.16145, 2.11861, 1.9837, 2.22307, 2.18739, 2.1666, 2.20664, 2.20077, 2.16129, 2.13993, 2.22303, 2.21677, 2.25294, 2.318, 2.30551, 2.11383, 2.02318, 2.24366, 2.12847, 2.18998, 2.38609, 2.24913, 2.11516, 2.1852, 2.28901, 2.16478, 2.27972, 2.20896, 2.18185, 2.15838, 2.26615, 2.29928, 1.90267, 2.15768, 2.23865, 2.09571, 2.17137, 2.01474, 2.18474, 2.08203, 2.26916, 2.14139, 2.13376, 2.00431, 2.27429, 2.25236, 2.2412, 2.15806, 2.06265, 2.15356, 2.22228, 2.06031, 2.17198, 2.18582, 2.32406, 2.32279, 2.16512, 2.31682, 2.1459, 2.20135, 2.27286, 2.17005, 2.24154, 2.33773, 2.09488, 2.32376, 2.29292, 2.13337, 2.168, 2.31548, 2.10926, 2.1934, 2.36461, 2.26305, 2.09429, 2.28596, 2.17563, 2.25982, 2.3113, 2.20922, 2.22492, 2.2454, 2.21729, 2.0837, 2.29063, 2.25299, 2.18992, 2.16562, 2.30043, 2.34616, 2.26113, 2.27231, 2.16817, 2.31263, 2.33401, 2.21849, 2.1174, 2.11123, 2.20396, 2.25619, 2.01475, 2.05484, 2.22974, 2.09647, 2.29722, 2.36117, 2.28311, 2.20881, 2.26532, 2.33023, 2.186, 2.31897, 2.23161, 2.18338, 2.10811, 2.29595, 2.16346, 2.25251, 2.2622, 2.17528, 2.3172, 2.13499, 2.23191, 2.23288, 1.9902, 2.2193, 2.10471, 2.25035, 2.24638, 2.11847, 2.11505, 2.22427, 2.30591, 2.21544, 2.17284, 2.21771, 2.1784, 2.30839, 2.2152, 2.10152, 2.18159, 2.31007, 2.21134, 2.10331, 2.26013, 2.27187, 2.08699, 2.29745, 2.22577, 2.25388, 2.13596, 2.23598, 2.11999, 2.24028, 2.13461, 2.11814, 2.13933, 2.21759, 2.20369, 2.33002, 2.3528, 2.17646, 2.17335, 2.25637, 2.02236, 2.22642, 2.36992, 2.27649, 2.25047, 2.25065, 2.27415, 2.32967, 2.21808, 2.24284, 2.14604, 2.29484, 2.23476, 2.2296, 2.0718, 2.20586, 2.07811, 2.17823, 2.17631, 2.17855, 2.09659, 2.25036, 2.19659, 2.28594, 2.27595, 2.23097, 2.03611, 2.11549, 2.17534, 2.2058, 2.12737, 2.22151, 2.07211, 2.28076, 1.97503, 2.21552, 1.90485, 2.16851, 2.28436, 2.01619]\n",
      "    Avg Accuracies: [0.1917, 0.2208, 0.1833, 0.2458, 0.2542, 0.1583, 0.1917, 0.3167, 0.2333, 0.2083, 0.2292, 0.3167, 0.1458, 0.275, 0.2292, 0.1792, 0.1292, 0.3625, 0.1833, 0.2208, 0.2125, 0.2083, 0.1875, 0.1917, 0.25, 0.2708, 0.1708, 0.1833, 0.2333, 0.1583, 0.1958, 0.2208, 0.2875, 0.2208, 0.1875, 0.2625, 0.2042, 0.2292, 0.275, 0.2333, 0.2625, 0.2458, 0.1333, 0.275, 0.1583, 0.1958, 0.3167, 0.2583, 0.3708, 0.2583, 0.2042, 0.2292, 0.2042, 0.2583, 0.2417, 0.225, 0.1958, 0.2292, 0.1667, 0.1542, 0.1708, 0.3042, 0.3333, 0.25, 0.2667, 0.2167, 0.125, 0.2, 0.2458, 0.2708, 0.1375, 0.2125, 0.1417, 0.2292, 0.225, 0.2333, 0.2542, 0.1792, 0.35, 0.2458, 0.2542, 0.3292, 0.2417, 0.2792, 0.2208, 0.3, 0.1333, 0.2417, 0.2417, 0.3125, 0.1375, 0.2375, 0.225, 0.2417, 0.2708, 0.2708, 0.2833, 0.3708, 0.2417, 0.2125, 0.1458, 0.1458, 0.2333, 0.1833, 0.3333, 0.2292, 0.1917, 0.2875, 0.2333, 0.2125, 0.2333, 0.1667, 0.2375, 0.2167, 0.2542, 0.1458, 0.3542, 0.2083, 0.1333, 0.2292, 0.275, 0.1208, 0.2125, 0.2083, 0.2125, 0.2708, 0.1792, 0.1958, 0.2292, 0.275, 0.1292, 0.2167, 0.2083, 0.2042, 0.1875, 0.1292, 0.2042, 0.1708, 0.2458, 0.2167, 0.2042, 0.2333, 0.2708, 0.2667, 0.2, 0.1708, 0.2542, 0.3083, 0.1958, 0.2875, 0.1833, 0.1458, 0.1667, 0.2458, 0.1875, 0.1208, 0.1958, 0.175, 0.1958, 0.1917, 0.3042, 0.2083, 0.2417, 0.2292, 0.2292, 0.2792, 0.1208, 0.2458, 0.2, 0.225, 0.2542, 0.1625, 0.2875, 0.2292, 0.2167, 0.2792, 0.2458, 0.1917, 0.1833, 0.2042, 0.25, 0.2333, 0.2042, 0.1625, 0.2333, 0.2583, 0.2333, 0.1292, 0.2333, 0.3, 0.2208, 0.2458, 0.2958, 0.2792, 0.2083, 0.1792, 0.2417, 0.1917, 0.275, 0.2, 0.275, 0.2583, 0.2083, 0.2083, 0.2375, 0.2167, 0.1708, 0.25, 0.2542, 0.2083, 0.325, 0.2458, 0.1542, 0.1792, 0.2792, 0.1583, 0.1958, 0.1583, 0.1792, 0.2208, 0.2833, 0.2333, 0.1583, 0.2083, 0.3125, 0.1625, 0.2625, 0.2792, 0.1625, 0.2625, 0.3, 0.1958, 0.2417, 0.2333, 0.1792, 0.2667, 0.2917, 0.2833, 0.2208, 0.1625, 0.275, 0.1875, 0.2833, 0.1375, 0.3833, 0.2375, 0.375, 0.2083, 0.2125, 0.4208]\n",
      "\n",
      "Epoch 1/9             \n",
      "    Avg Losses: [1.42381, 1.39537, 1.74487, 1.53985, 1.55253, 1.90142, 1.62009, 1.4135, 1.30981, 1.38843, 1.39188, 1.24709, 1.86741, 1.33969, 1.33815, 1.3306, 1.84276, 0.95245, 1.50066, 1.12283, 1.53449, 1.89858, 1.44705, 1.65217, 1.69226, 1.19985, 1.83251, 1.62285, 1.36112, 1.75379, 1.60446, 1.61523, 1.31669, 1.62977, 1.77638, 1.47225, 1.79817, 1.33695, 1.43391, 1.46353, 1.24035, 1.35297, 1.95186, 1.29823, 1.95154, 1.67819, 1.28619, 1.34109, 1.00772, 1.47126, 1.53107, 1.47704, 1.4076, 1.44501, 1.53864, 1.19278, 1.57052, 1.58738, 1.74866, 1.90252, 1.76198, 1.25126, 0.97451, 1.6813, 1.32292, 1.42093, 1.98004, 1.57496, 1.40484, 1.46477, 1.99371, 1.40583, 1.98369, 1.61364, 1.48053, 1.37721, 1.69897, 1.82911, 0.89683, 1.29328, 1.677, 1.21664, 1.66508, 1.06224, 1.48296, 1.14285, 1.77176, 1.5192, 1.2997, 0.97415, 1.58493, 1.57691, 1.5984, 1.42763, 1.31415, 1.30406, 1.28475, 1.02804, 1.39818, 1.60773, 2.01165, 1.98219, 1.45242, 1.91757, 1.1857, 1.58552, 1.68537, 1.42052, 1.60991, 1.6828, 1.38486, 1.90846, 1.51598, 1.37557, 1.53038, 1.73341, 1.20852, 1.49144, 2.04071, 1.58566, 1.33482, 1.86689, 1.42537, 1.6486, 1.61695, 1.55609, 1.67671, 1.76015, 1.44691, 1.31895, 1.7989, 1.76222, 1.55916, 1.43701, 1.8509, 2.10753, 1.44544, 1.75486, 1.3932, 1.51323, 1.61157, 1.45711, 1.19002, 1.31292, 1.51954, 1.72311, 1.14192, 1.23265, 1.65739, 1.17559, 1.53354, 1.79744, 1.68659, 1.6411, 1.76463, 1.91536, 1.58411, 1.71895, 1.64447, 1.37587, 1.43552, 1.55132, 1.30771, 1.43608, 1.48642, 1.50677, 1.78681, 1.30656, 1.59476, 1.4626, 0.94181, 1.57376, 1.38978, 1.44049, 1.55957, 1.43553, 1.14401, 1.64256, 1.89102, 1.6014, 1.41941, 1.42416, 1.29406, 1.71719, 1.59306, 1.30824, 1.39046, 1.98514, 1.37188, 1.38513, 1.60011, 1.69304, 1.27431, 1.70502, 1.72458, 1.61647, 1.40712, 1.64285, 1.29312, 1.69142, 1.45707, 1.25022, 1.36998, 1.65383, 1.41502, 1.89952, 1.86792, 1.38564, 1.43751, 1.57334, 1.26326, 1.64884, 2.19365, 1.82912, 1.47181, 1.47616, 1.49857, 1.95911, 1.60749, 1.52544, 1.44046, 1.75859, 1.48846, 1.5461, 1.33984, 1.42182, 1.01291, 1.31295, 1.54863, 1.51149, 1.26342, 1.4558, 1.5351, 1.69838, 1.81812, 1.30321, 1.19927, 1.47293, 1.43928, 1.66977, 1.34175, 1.52437, 1.02248, 1.69081, 0.92605, 1.42398, 0.70244, 1.35278, 1.61002, 0.88342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.5667, 0.6292, 0.4625, 0.6042, 0.5083, 0.3833, 0.4833, 0.5375, 0.6708, 0.6333, 0.5708, 0.6292, 0.4917, 0.6375, 0.7042, 0.6333, 0.4708, 0.7708, 0.5583, 0.7542, 0.5, 0.3833, 0.5417, 0.4417, 0.5, 0.7458, 0.375, 0.4208, 0.6583, 0.4542, 0.5583, 0.5, 0.6792, 0.4875, 0.3792, 0.5375, 0.4833, 0.6292, 0.6083, 0.5458, 0.675, 0.625, 0.4042, 0.6292, 0.3167, 0.5583, 0.6125, 0.6125, 0.7375, 0.6125, 0.5417, 0.5417, 0.6542, 0.6, 0.5792, 0.7667, 0.5417, 0.5042, 0.4083, 0.4125, 0.4583, 0.6542, 0.7042, 0.5125, 0.6083, 0.525, 0.3542, 0.6208, 0.5292, 0.5875, 0.325, 0.6375, 0.2875, 0.4833, 0.5458, 0.6083, 0.5917, 0.4, 0.7417, 0.6958, 0.4833, 0.6792, 0.475, 0.6792, 0.5875, 0.6917, 0.475, 0.5542, 0.6167, 0.7833, 0.6125, 0.5208, 0.5583, 0.5708, 0.6333, 0.6792, 0.6292, 0.725, 0.5958, 0.5208, 0.3375, 0.3917, 0.5833, 0.3958, 0.7, 0.5167, 0.5042, 0.5625, 0.5042, 0.5625, 0.5875, 0.4042, 0.5667, 0.6, 0.575, 0.4917, 0.7375, 0.525, 0.325, 0.5333, 0.6167, 0.4708, 0.5625, 0.4833, 0.5542, 0.525, 0.5208, 0.4667, 0.6167, 0.6208, 0.475, 0.4292, 0.4792, 0.5667, 0.4208, 0.2667, 0.575, 0.3958, 0.6875, 0.5542, 0.6542, 0.5375, 0.7042, 0.6042, 0.5792, 0.5375, 0.7167, 0.6292, 0.4292, 0.6792, 0.5, 0.5333, 0.4708, 0.475, 0.4167, 0.4167, 0.5583, 0.475, 0.5, 0.5875, 0.5375, 0.5708, 0.6458, 0.6583, 0.5458, 0.5292, 0.3667, 0.6, 0.5208, 0.5667, 0.775, 0.5333, 0.6333, 0.5667, 0.525, 0.5458, 0.6917, 0.5125, 0.4083, 0.4667, 0.6, 0.6042, 0.6875, 0.4542, 0.4792, 0.6625, 0.6375, 0.4083, 0.6, 0.5583, 0.6, 0.5292, 0.6208, 0.425, 0.4708, 0.575, 0.5875, 0.5625, 0.6083, 0.4833, 0.5417, 0.6833, 0.5875, 0.4667, 0.5958, 0.3625, 0.4542, 0.6458, 0.6208, 0.5375, 0.625, 0.5292, 0.1833, 0.3708, 0.5375, 0.6292, 0.575, 0.3708, 0.525, 0.5958, 0.5958, 0.4583, 0.6458, 0.5167, 0.5583, 0.6542, 0.7875, 0.6083, 0.5417, 0.5375, 0.725, 0.6375, 0.5667, 0.4792, 0.4042, 0.7167, 0.6167, 0.5292, 0.6667, 0.4875, 0.625, 0.6167, 0.7542, 0.5625, 0.75, 0.5625, 0.8708, 0.6833, 0.6, 0.7958]\n",
      "\n",
      "Epoch 2/9             \n",
      "    Avg Losses: [0.66599, 0.68, 1.12474, 0.94035, 0.87837, 1.19405, 0.95927, 0.68643, 0.60857, 0.6313, 0.68368, 0.53423, 1.05277, 0.73045, 0.72797, 0.57532, 1.11161, 0.43986, 0.73435, 0.49876, 0.86732, 1.18369, 0.89181, 1.06066, 0.99738, 0.48883, 1.09057, 0.80912, 0.67014, 1.06789, 0.84542, 0.8452, 0.69559, 0.92172, 1.10591, 0.88686, 1.10064, 0.68435, 0.69726, 0.90724, 0.49256, 0.58526, 1.35001, 0.60153, 1.20756, 0.94735, 0.5831, 0.64751, 0.57989, 0.64268, 0.79085, 0.83259, 0.62535, 0.74641, 0.95486, 0.4387, 0.94367, 1.00357, 1.14919, 1.29178, 1.03752, 0.66914, 0.58902, 0.9811, 0.64928, 0.82458, 1.34556, 0.76407, 0.68749, 0.77847, 1.34026, 0.59694, 1.39065, 1.05931, 0.77265, 0.65953, 0.75683, 1.25791, 0.40736, 0.59923, 0.98679, 0.60373, 1.02912, 0.47348, 0.8163, 0.53822, 1.03332, 0.85762, 0.62372, 0.41193, 0.71429, 0.65669, 0.87922, 0.81352, 0.80651, 0.58685, 0.68455, 0.42693, 0.66215, 0.91345, 1.41744, 1.52111, 0.76166, 1.18957, 0.53504, 0.8023, 0.91048, 0.75111, 0.81586, 1.0115, 0.81306, 1.21674, 0.87108, 0.76159, 0.87342, 0.94199, 0.61365, 0.91401, 1.51914, 0.84702, 0.79193, 1.06661, 0.72766, 0.91778, 0.84166, 0.94221, 1.04842, 1.04955, 0.75506, 0.80042, 1.08596, 1.11449, 0.8611, 0.77262, 1.31092, 1.6177, 0.74286, 1.07584, 0.60249, 0.75645, 0.76992, 0.86336, 0.53998, 0.7142, 0.81085, 0.98294, 0.62944, 0.5848, 0.96158, 0.53288, 0.84607, 1.105, 0.96856, 1.00391, 1.03573, 1.09328, 0.90557, 1.1071, 0.98892, 0.73693, 0.83677, 0.85364, 0.58533, 0.71735, 0.85879, 0.80836, 1.18544, 0.67979, 0.87907, 0.79398, 0.49305, 0.77364, 0.87896, 0.64375, 0.78308, 0.77796, 0.60326, 0.97946, 1.2149, 0.871, 0.7001, 0.70706, 0.62539, 0.87781, 0.94258, 0.68553, 0.74049, 1.34597, 0.77008, 0.8091, 0.80504, 0.91615, 0.73466, 1.09988, 0.98002, 0.82342, 0.83352, 1.01544, 0.61114, 0.90205, 0.82121, 0.59938, 0.7985, 1.11068, 0.78088, 1.25657, 1.26951, 0.66867, 0.74174, 0.83759, 0.78769, 0.85224, 1.74938, 1.18304, 0.82449, 0.70356, 0.75905, 1.40086, 0.84399, 0.7188, 0.81278, 1.15215, 0.79036, 0.80981, 0.85224, 0.62689, 0.36006, 0.58909, 0.90115, 0.94261, 0.54388, 0.7067, 0.79463, 0.86382, 1.18871, 0.55697, 0.60989, 0.78352, 0.65399, 0.91318, 0.79228, 0.73552, 0.31869, 0.76447, 0.28683, 0.64678, 0.22662, 0.51067, 0.74232, 0.27578]\n",
      "    Avg Accuracies: [0.8333, 0.7833, 0.6458, 0.7375, 0.7417, 0.6292, 0.7583, 0.8333, 0.8542, 0.8292, 0.8, 0.875, 0.7417, 0.8, 0.7833, 0.875, 0.7292, 0.875, 0.8083, 0.875, 0.775, 0.6583, 0.7542, 0.6583, 0.7208, 0.8792, 0.725, 0.7917, 0.7875, 0.7458, 0.725, 0.8, 0.8042, 0.6875, 0.6833, 0.7417, 0.7042, 0.8125, 0.7958, 0.7625, 0.8625, 0.8167, 0.6083, 0.85, 0.7167, 0.7375, 0.8375, 0.7917, 0.8333, 0.85, 0.7625, 0.775, 0.8417, 0.8042, 0.725, 0.8833, 0.7208, 0.7, 0.6167, 0.5792, 0.6542, 0.8375, 0.8333, 0.7292, 0.8083, 0.775, 0.6292, 0.775, 0.8083, 0.7708, 0.6292, 0.8625, 0.65, 0.6625, 0.7542, 0.8083, 0.8167, 0.6292, 0.8875, 0.8708, 0.7042, 0.8292, 0.7333, 0.8583, 0.7417, 0.8958, 0.6917, 0.7583, 0.8458, 0.9042, 0.8167, 0.8583, 0.7667, 0.7625, 0.7542, 0.8417, 0.8, 0.8625, 0.8167, 0.7417, 0.5875, 0.6125, 0.7875, 0.6208, 0.8583, 0.7833, 0.75, 0.7958, 0.7542, 0.7125, 0.7833, 0.6583, 0.75, 0.7792, 0.7417, 0.7917, 0.8292, 0.7542, 0.5792, 0.7917, 0.7583, 0.7292, 0.7958, 0.7375, 0.7583, 0.7333, 0.7208, 0.7083, 0.8125, 0.7417, 0.6917, 0.6708, 0.7417, 0.7875, 0.575, 0.4708, 0.7958, 0.7333, 0.8667, 0.825, 0.8167, 0.7625, 0.85, 0.7833, 0.7917, 0.725, 0.8375, 0.8417, 0.7708, 0.8542, 0.7792, 0.7375, 0.7042, 0.725, 0.7542, 0.7583, 0.7417, 0.7167, 0.6917, 0.7542, 0.7333, 0.7583, 0.8292, 0.8167, 0.7083, 0.7833, 0.6542, 0.7958, 0.7583, 0.8125, 0.8667, 0.8125, 0.75, 0.8542, 0.7958, 0.8083, 0.8292, 0.7375, 0.675, 0.7042, 0.8125, 0.825, 0.8, 0.7625, 0.7208, 0.8292, 0.7875, 0.6458, 0.7583, 0.7708, 0.775, 0.7375, 0.7875, 0.6667, 0.6792, 0.7958, 0.7667, 0.725, 0.825, 0.7625, 0.7792, 0.8167, 0.7667, 0.65, 0.8, 0.6833, 0.625, 0.8125, 0.8042, 0.7792, 0.7417, 0.7333, 0.3667, 0.6333, 0.75, 0.85, 0.8208, 0.5708, 0.7625, 0.85, 0.7833, 0.6833, 0.8333, 0.7625, 0.7458, 0.8042, 0.9125, 0.8208, 0.7083, 0.7458, 0.8625, 0.7958, 0.775, 0.7375, 0.6833, 0.8833, 0.8125, 0.7667, 0.8542, 0.7875, 0.7708, 0.8167, 0.9208, 0.8458, 0.9333, 0.8167, 0.9375, 0.8833, 0.8625, 0.9625]\n",
      "\n",
      "Epoch 3/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.48196, 0.39495, 0.64809, 0.63741, 0.49076, 0.60653, 0.66273, 0.3823, 0.34925, 0.33786, 0.29736, 0.29504, 0.48175, 0.46401, 0.42631, 0.31803, 0.68814, 0.28315, 0.42986, 0.30316, 0.58328, 0.71571, 0.51409, 0.66945, 0.57366, 0.25209, 0.52692, 0.42819, 0.38539, 0.62895, 0.4631, 0.4921, 0.43013, 0.5892, 0.69549, 0.62799, 0.70596, 0.38762, 0.43073, 0.6265, 0.25464, 0.34913, 0.82218, 0.27526, 0.57192, 0.63084, 0.34517, 0.3787, 0.4145, 0.31513, 0.41947, 0.45023, 0.34627, 0.39547, 0.66425, 0.26189, 0.59932, 0.61769, 0.72941, 0.82716, 0.54384, 0.36854, 0.39575, 0.58415, 0.3106, 0.4627, 0.78898, 0.39925, 0.39961, 0.41193, 0.70602, 0.29887, 0.71757, 0.65548, 0.40805, 0.3696, 0.31718, 0.88586, 0.25379, 0.34058, 0.54434, 0.37237, 0.61531, 0.26884, 0.47284, 0.28939, 0.73809, 0.45363, 0.31637, 0.24237, 0.32735, 0.28513, 0.52126, 0.46653, 0.54293, 0.34268, 0.41552, 0.27387, 0.3654, 0.53991, 0.7238, 0.93889, 0.44812, 0.71859, 0.30867, 0.3954, 0.53558, 0.53909, 0.42298, 0.64224, 0.56769, 0.67844, 0.60497, 0.45203, 0.47973, 0.50558, 0.40781, 0.57054, 0.9823, 0.45685, 0.50564, 0.57251, 0.41695, 0.51667, 0.50825, 0.60691, 0.58345, 0.7305, 0.46127, 0.51297, 0.63577, 0.64091, 0.48706, 0.45464, 0.818, 1.12682, 0.50097, 0.56388, 0.30145, 0.39376, 0.4479, 0.42866, 0.31135, 0.42883, 0.48217, 0.59808, 0.40895, 0.32713, 0.50017, 0.23611, 0.52368, 0.57339, 0.60061, 0.65181, 0.62357, 0.50196, 0.48511, 0.61577, 0.59275, 0.52364, 0.48737, 0.50019, 0.30195, 0.45976, 0.51327, 0.50841, 0.69884, 0.37053, 0.45373, 0.42669, 0.33122, 0.44625, 0.60105, 0.41484, 0.41625, 0.47309, 0.3541, 0.60182, 0.68031, 0.60647, 0.39479, 0.3552, 0.36673, 0.4614, 0.62608, 0.50413, 0.51306, 0.75801, 0.38947, 0.55, 0.44288, 0.49432, 0.44232, 0.69624, 0.52238, 0.41408, 0.53916, 0.70469, 0.35342, 0.47564, 0.50128, 0.38504, 0.50143, 0.81774, 0.41797, 0.73371, 0.72688, 0.45252, 0.42971, 0.46308, 0.58568, 0.48524, 0.93896, 0.76593, 0.42808, 0.35031, 0.37974, 0.84168, 0.48552, 0.44227, 0.55609, 0.71893, 0.40844, 0.42552, 0.57096, 0.27701, 0.17773, 0.3699, 0.4969, 0.5945, 0.28993, 0.43079, 0.51329, 0.45096, 0.70995, 0.36631, 0.35184, 0.49862, 0.32361, 0.46052, 0.49918, 0.3721, 0.13107, 0.25769, 0.10537, 0.28947, 0.07066, 0.23102, 0.33573, 0.12247]\n",
      "    Avg Accuracies: [0.85, 0.8667, 0.8458, 0.7958, 0.8458, 0.8042, 0.825, 0.8958, 0.9, 0.8958, 0.9417, 0.9208, 0.8875, 0.8417, 0.875, 0.925, 0.8042, 0.9083, 0.875, 0.9167, 0.7792, 0.7958, 0.8583, 0.7708, 0.8333, 0.9333, 0.85, 0.8625, 0.8792, 0.8042, 0.8333, 0.8167, 0.85, 0.8042, 0.7833, 0.7833, 0.7833, 0.8667, 0.8542, 0.8125, 0.9125, 0.8792, 0.725, 0.9375, 0.8375, 0.8125, 0.875, 0.8542, 0.8917, 0.9125, 0.8708, 0.8708, 0.9, 0.8958, 0.8, 0.9167, 0.825, 0.7917, 0.7583, 0.7333, 0.8, 0.9125, 0.8833, 0.8125, 0.9, 0.8542, 0.775, 0.8708, 0.8875, 0.8583, 0.8, 0.9, 0.8208, 0.775, 0.8708, 0.8792, 0.9333, 0.75, 0.925, 0.9042, 0.8375, 0.8875, 0.8333, 0.925, 0.8583, 0.9167, 0.7625, 0.8792, 0.9042, 0.9333, 0.9, 0.9, 0.7958, 0.8917, 0.8208, 0.8958, 0.8708, 0.925, 0.8792, 0.825, 0.8292, 0.7417, 0.85, 0.7833, 0.9042, 0.8917, 0.8417, 0.8458, 0.8583, 0.8458, 0.7917, 0.7708, 0.7875, 0.85, 0.8833, 0.8625, 0.875, 0.8333, 0.7042, 0.8833, 0.825, 0.8083, 0.8833, 0.8542, 0.8458, 0.7958, 0.8292, 0.7458, 0.8542, 0.85, 0.825, 0.8, 0.8167, 0.8708, 0.7583, 0.6583, 0.8417, 0.8667, 0.925, 0.8833, 0.8208, 0.8875, 0.9292, 0.8667, 0.8417, 0.7958, 0.8917, 0.9083, 0.8792, 0.9375, 0.8042, 0.8333, 0.7792, 0.7958, 0.8167, 0.8625, 0.8417, 0.8417, 0.8417, 0.8125, 0.8667, 0.8375, 0.9208, 0.8375, 0.8208, 0.8542, 0.7667, 0.8708, 0.8833, 0.8917, 0.9042, 0.8875, 0.8083, 0.8792, 0.85, 0.8583, 0.8917, 0.8, 0.7833, 0.7958, 0.8917, 0.8917, 0.8708, 0.875, 0.7958, 0.8417, 0.825, 0.7833, 0.8792, 0.8292, 0.8792, 0.85, 0.8708, 0.7833, 0.8375, 0.8958, 0.8125, 0.7792, 0.8833, 0.8417, 0.8417, 0.8833, 0.8333, 0.7542, 0.8875, 0.8083, 0.7583, 0.8208, 0.8792, 0.8667, 0.7792, 0.85, 0.7583, 0.7708, 0.8833, 0.8833, 0.9, 0.725, 0.8667, 0.8792, 0.8208, 0.8, 0.9125, 0.8917, 0.7875, 0.925, 0.9417, 0.875, 0.875, 0.8, 0.9292, 0.8542, 0.8583, 0.8542, 0.7792, 0.8917, 0.8917, 0.8542, 0.9083, 0.875, 0.8292, 0.8958, 0.9667, 0.9417, 0.9833, 0.9125, 0.9833, 0.9333, 0.9167, 0.9792]\n",
      "\n",
      "Epoch 4/9             \n",
      "    Avg Losses: [0.28891, 0.22555, 0.3559, 0.39023, 0.37368, 0.35275, 0.48511, 0.21394, 0.20961, 0.22675, 0.19763, 0.20655, 0.28091, 0.28781, 0.26523, 0.18045, 0.41467, 0.16987, 0.32037, 0.17809, 0.38816, 0.41576, 0.37297, 0.50219, 0.35067, 0.1523, 0.31396, 0.25742, 0.22803, 0.41936, 0.22588, 0.30999, 0.2781, 0.44865, 0.4218, 0.40831, 0.53516, 0.28574, 0.28776, 0.40846, 0.13591, 0.2014, 0.50212, 0.15856, 0.35133, 0.36871, 0.27215, 0.28247, 0.29031, 0.19666, 0.25415, 0.26818, 0.22573, 0.24178, 0.44897, 0.1706, 0.40138, 0.41233, 0.39788, 0.56953, 0.32189, 0.3434, 0.29231, 0.42231, 0.19222, 0.28587, 0.50844, 0.28283, 0.2123, 0.31109, 0.50026, 0.18521, 0.36325, 0.44203, 0.24668, 0.24076, 0.21205, 0.63305, 0.15116, 0.19759, 0.32279, 0.22464, 0.4399, 0.22224, 0.37989, 0.16058, 0.51007, 0.3606, 0.1845, 0.11659, 0.14371, 0.28281, 0.35765, 0.28448, 0.45711, 0.17376, 0.31657, 0.16081, 0.28201, 0.36495, 0.42961, 0.52433, 0.31863, 0.48849, 0.17811, 0.26284, 0.38606, 0.41634, 0.25962, 0.38303, 0.3671, 0.47567, 0.29817, 0.29739, 0.39614, 0.28799, 0.28318, 0.37699, 0.69169, 0.27331, 0.32267, 0.37107, 0.26674, 0.31559, 0.33103, 0.38329, 0.32691, 0.39419, 0.25239, 0.41048, 0.4449, 0.40158, 0.33931, 0.29996, 0.46534, 0.67171, 0.29514, 0.32455, 0.14048, 0.22306, 0.3285, 0.29045, 0.20378, 0.28117, 0.2821, 0.42489, 0.23599, 0.19227, 0.29525, 0.14941, 0.38838, 0.34504, 0.49706, 0.44576, 0.34686, 0.27158, 0.27404, 0.40581, 0.40901, 0.39445, 0.29299, 0.35475, 0.1974, 0.40968, 0.34214, 0.35563, 0.40866, 0.19804, 0.28286, 0.27062, 0.17832, 0.26995, 0.44733, 0.23026, 0.20783, 0.2799, 0.22709, 0.41039, 0.37302, 0.45196, 0.26457, 0.24938, 0.20663, 0.26095, 0.36947, 0.37192, 0.34524, 0.43218, 0.21164, 0.46073, 0.34954, 0.27753, 0.37089, 0.52896, 0.38742, 0.24886, 0.39912, 0.39963, 0.23723, 0.31508, 0.2684, 0.32909, 0.35508, 0.63284, 0.27884, 0.49175, 0.44114, 0.29253, 0.31188, 0.2981, 0.4531, 0.25021, 0.48449, 0.51862, 0.2364, 0.16753, 0.28073, 0.64502, 0.32195, 0.26164, 0.51905, 0.49771, 0.23781, 0.25961, 0.40497, 0.16743, 0.06296, 0.2803, 0.33499, 0.37259, 0.25426, 0.31233, 0.41567, 0.34832, 0.50837, 0.24215, 0.19551, 0.31726, 0.23083, 0.28224, 0.33196, 0.21588, 0.13901, 0.11884, 0.04488, 0.13365, 0.03929, 0.09566, 0.2536, 0.09641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9042, 0.9375, 0.8875, 0.8958, 0.8875, 0.8625, 0.8292, 0.9583, 0.9292, 0.9125, 0.9542, 0.9292, 0.925, 0.9, 0.9042, 0.9417, 0.8833, 0.9417, 0.9042, 0.9542, 0.875, 0.8583, 0.8958, 0.8417, 0.8958, 0.95, 0.8958, 0.9167, 0.9167, 0.8833, 0.9375, 0.9, 0.9125, 0.8167, 0.8708, 0.8708, 0.8042, 0.9, 0.9042, 0.8708, 0.975, 0.9333, 0.8208, 0.9458, 0.8792, 0.9042, 0.8958, 0.875, 0.9042, 0.95, 0.9083, 0.9292, 0.9458, 0.9375, 0.8417, 0.9458, 0.875, 0.8542, 0.875, 0.8125, 0.875, 0.8708, 0.8958, 0.8625, 0.95, 0.9042, 0.8333, 0.8875, 0.9208, 0.9083, 0.8333, 0.9292, 0.8833, 0.8708, 0.9208, 0.9333, 0.925, 0.8083, 0.9625, 0.95, 0.875, 0.9375, 0.8708, 0.9292, 0.9125, 0.9583, 0.8417, 0.8958, 0.9542, 0.9667, 0.9625, 0.8917, 0.8875, 0.925, 0.875, 0.9458, 0.9042, 0.9458, 0.8875, 0.8833, 0.8542, 0.8208, 0.9042, 0.85, 0.9458, 0.9292, 0.8917, 0.8792, 0.9042, 0.9, 0.8667, 0.8375, 0.9375, 0.9042, 0.8542, 0.9125, 0.9125, 0.9, 0.7917, 0.9167, 0.8917, 0.8667, 0.9042, 0.9167, 0.8875, 0.8917, 0.9042, 0.8917, 0.9208, 0.8833, 0.8667, 0.8542, 0.85, 0.9042, 0.825, 0.8042, 0.9375, 0.9333, 0.9625, 0.9292, 0.8792, 0.9208, 0.9458, 0.9083, 0.8958, 0.8667, 0.9417, 0.9417, 0.9, 0.9542, 0.8792, 0.8875, 0.85, 0.8542, 0.8958, 0.9208, 0.9167, 0.8708, 0.8542, 0.8625, 0.9125, 0.8917, 0.9458, 0.875, 0.8875, 0.8792, 0.8708, 0.9292, 0.9125, 0.9208, 0.9458, 0.8958, 0.8667, 0.9417, 0.9625, 0.9125, 0.9542, 0.8708, 0.8458, 0.8375, 0.9333, 0.9, 0.9208, 0.9292, 0.9042, 0.8667, 0.8833, 0.8583, 0.9417, 0.8625, 0.8833, 0.9208, 0.8875, 0.8417, 0.8625, 0.9292, 0.8542, 0.8708, 0.9167, 0.8958, 0.9292, 0.8958, 0.8917, 0.7833, 0.925, 0.8292, 0.8458, 0.9083, 0.9333, 0.9042, 0.8792, 0.925, 0.8667, 0.8208, 0.9458, 0.9542, 0.9083, 0.7708, 0.9125, 0.9292, 0.85, 0.8708, 0.9333, 0.9083, 0.8708, 0.9583, 0.9833, 0.9125, 0.9042, 0.8583, 0.9167, 0.9042, 0.8875, 0.8958, 0.8292, 0.9333, 0.9375, 0.8958, 0.9333, 0.9167, 0.9083, 0.9417, 0.9667, 0.9708, 0.9917, 0.9708, 0.9917, 0.9792, 0.9208, 0.9792]\n",
      "\n",
      "Epoch 5/9             \n",
      "    Avg Losses: [0.16412, 0.11238, 0.19013, 0.28199, 0.26994, 0.20363, 0.30046, 0.17323, 0.10403, 0.16652, 0.15891, 0.14783, 0.13259, 0.16479, 0.15708, 0.13441, 0.28863, 0.08127, 0.20084, 0.1446, 0.23572, 0.29733, 0.22705, 0.35131, 0.19949, 0.08771, 0.18473, 0.18505, 0.14938, 0.28203, 0.20045, 0.25392, 0.17235, 0.30682, 0.31666, 0.33305, 0.38522, 0.19929, 0.20844, 0.26157, 0.09852, 0.13559, 0.32763, 0.1068, 0.23235, 0.19656, 0.19719, 0.30252, 0.23025, 0.11361, 0.1161, 0.17755, 0.1052, 0.21269, 0.27971, 0.20105, 0.27286, 0.28203, 0.27643, 0.40654, 0.21544, 0.15731, 0.21493, 0.30489, 0.14909, 0.1629, 0.32443, 0.13681, 0.14417, 0.25785, 0.43813, 0.14958, 0.21068, 0.27681, 0.17352, 0.13406, 0.13238, 0.3912, 0.1121, 0.12403, 0.21507, 0.12431, 0.25223, 0.19411, 0.2732, 0.10154, 0.32238, 0.2849, 0.12288, 0.08924, 0.11155, 0.15056, 0.22584, 0.24145, 0.32359, 0.09037, 0.18131, 0.13795, 0.15849, 0.20724, 0.22976, 0.36041, 0.30095, 0.35064, 0.11195, 0.15397, 0.23866, 0.26822, 0.17847, 0.26737, 0.29093, 0.27758, 0.23424, 0.19734, 0.22631, 0.14069, 0.25468, 0.25712, 0.53964, 0.26222, 0.15554, 0.30468, 0.27111, 0.2378, 0.29425, 0.27353, 0.18607, 0.21038, 0.26748, 0.35638, 0.343, 0.26069, 0.18465, 0.1699, 0.21951, 0.39204, 0.20234, 0.25376, 0.08119, 0.12708, 0.24597, 0.13104, 0.1867, 0.22287, 0.24612, 0.2947, 0.21679, 0.09353, 0.22586, 0.08382, 0.23549, 0.20161, 0.27007, 0.31829, 0.25873, 0.16417, 0.22098, 0.28042, 0.31053, 0.17731, 0.16343, 0.28116, 0.10317, 0.32898, 0.19927, 0.24149, 0.28534, 0.1415, 0.21378, 0.23926, 0.15649, 0.18352, 0.29226, 0.21047, 0.11096, 0.15599, 0.18266, 0.28777, 0.20878, 0.23981, 0.20106, 0.14115, 0.15798, 0.12821, 0.21549, 0.24987, 0.2519, 0.26321, 0.12731, 0.30216, 0.2997, 0.15281, 0.21586, 0.30315, 0.2081, 0.16017, 0.29679, 0.28014, 0.12027, 0.21463, 0.19036, 0.1916, 0.25342, 0.44088, 0.16983, 0.28907, 0.31438, 0.19306, 0.16162, 0.16611, 0.28249, 0.16565, 0.30243, 0.38542, 0.1622, 0.08517, 0.22146, 0.56265, 0.18342, 0.17292, 0.35897, 0.37807, 0.12379, 0.18304, 0.26809, 0.08159, 0.03747, 0.17643, 0.19798, 0.19109, 0.16654, 0.15146, 0.33422, 0.2472, 0.32884, 0.23296, 0.0965, 0.18713, 0.1772, 0.18328, 0.21985, 0.10765, 0.13057, 0.06952, 0.01591, 0.07351, 0.01577, 0.0569, 0.12047, 0.06003]\n",
      "    Avg Accuracies: [0.95, 0.975, 0.9458, 0.9, 0.9, 0.9417, 0.8958, 0.9583, 0.975, 0.9417, 0.9625, 0.95, 0.9667, 0.9458, 0.9708, 0.9583, 0.9083, 0.9833, 0.9625, 0.9542, 0.9208, 0.9083, 0.925, 0.8958, 0.9417, 0.9875, 0.9458, 0.95, 0.9542, 0.9167, 0.9458, 0.9083, 0.9542, 0.8917, 0.9, 0.8833, 0.8875, 0.9417, 0.9458, 0.9, 0.975, 0.9625, 0.8875, 0.9667, 0.9292, 0.9542, 0.925, 0.8917, 0.9333, 0.975, 0.975, 0.9333, 0.9833, 0.9292, 0.9167, 0.9292, 0.9167, 0.9125, 0.9375, 0.85, 0.9333, 0.9625, 0.9292, 0.9083, 0.9542, 0.9667, 0.9042, 0.9583, 0.9542, 0.9042, 0.8458, 0.9458, 0.9458, 0.9208, 0.9458, 0.95, 0.95, 0.8708, 0.975, 0.9708, 0.9208, 0.9792, 0.9292, 0.9292, 0.9042, 0.9792, 0.8875, 0.9167, 0.9625, 0.975, 0.9625, 0.9625, 0.9375, 0.9458, 0.8833, 0.9833, 0.9583, 0.9542, 0.9417, 0.9417, 0.9208, 0.8875, 0.8917, 0.8792, 0.975, 0.9458, 0.9333, 0.925, 0.9542, 0.9125, 0.9208, 0.8792, 0.9167, 0.9458, 0.925, 0.9667, 0.9333, 0.9208, 0.8375, 0.9042, 0.9583, 0.9083, 0.9125, 0.9458, 0.9042, 0.9375, 0.9417, 0.9375, 0.875, 0.8625, 0.9, 0.925, 0.925, 0.95, 0.95, 0.875, 0.95, 0.9333, 0.9833, 0.9542, 0.9292, 0.9625, 0.9542, 0.9375, 0.925, 0.8917, 0.9208, 0.9708, 0.925, 0.9833, 0.9292, 0.9417, 0.925, 0.8917, 0.9333, 0.9542, 0.9292, 0.9167, 0.8875, 0.9583, 0.95, 0.9125, 0.9708, 0.8708, 0.9458, 0.9333, 0.9083, 0.9625, 0.95, 0.9208, 0.95, 0.9583, 0.925, 0.9333, 0.975, 0.9333, 0.9542, 0.9083, 0.9458, 0.9208, 0.9208, 0.9583, 0.95, 0.9667, 0.9417, 0.9125, 0.925, 0.9083, 0.9625, 0.9125, 0.9292, 0.9583, 0.9292, 0.9292, 0.925, 0.9542, 0.8875, 0.9125, 0.9667, 0.9333, 0.9417, 0.9458, 0.9208, 0.8542, 0.9417, 0.9083, 0.9, 0.95, 0.9667, 0.95, 0.925, 0.9375, 0.9, 0.8708, 0.9625, 0.9792, 0.9375, 0.8542, 0.9417, 0.9542, 0.875, 0.875, 0.9583, 0.9417, 0.9125, 0.9875, 0.9958, 0.9625, 0.9417, 0.9458, 0.9458, 0.9542, 0.8958, 0.9125, 0.9042, 0.9125, 0.9833, 0.9333, 0.9542, 0.9542, 0.9458, 0.975, 0.9458, 0.9833, 1.0, 0.9875, 1.0, 0.9917, 0.9583, 0.9875]\n",
      "\n",
      "Epoch 6/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.1074, 0.06861, 0.12346, 0.16572, 0.2016, 0.15397, 0.19522, 0.09769, 0.07793, 0.10249, 0.11256, 0.08473, 0.13709, 0.10065, 0.08645, 0.10457, 0.20076, 0.06277, 0.15415, 0.12645, 0.17388, 0.20123, 0.1143, 0.34864, 0.13082, 0.03396, 0.15364, 0.1132, 0.0955, 0.20392, 0.13981, 0.16824, 0.11068, 0.25701, 0.1951, 0.25079, 0.27671, 0.12609, 0.13564, 0.16434, 0.05833, 0.07401, 0.23937, 0.064, 0.17943, 0.11122, 0.10858, 0.21967, 0.18916, 0.08947, 0.07911, 0.09582, 0.07157, 0.20472, 0.20377, 0.08675, 0.17988, 0.27651, 0.2601, 0.23554, 0.14984, 0.1118, 0.18287, 0.23356, 0.09189, 0.12019, 0.25232, 0.10465, 0.09447, 0.23183, 0.27649, 0.12257, 0.24177, 0.17097, 0.19736, 0.14328, 0.09079, 0.30777, 0.05961, 0.06416, 0.12345, 0.05246, 0.1385, 0.14273, 0.16574, 0.04048, 0.24411, 0.27874, 0.07252, 0.08183, 0.06831, 0.08073, 0.16821, 0.20314, 0.23753, 0.04492, 0.08764, 0.0755, 0.07873, 0.15205, 0.1415, 0.23516, 0.12427, 0.30495, 0.05272, 0.11172, 0.16894, 0.19225, 0.11059, 0.17298, 0.20463, 0.20355, 0.1177, 0.12384, 0.12556, 0.08764, 0.15913, 0.17252, 0.38469, 0.12876, 0.08188, 0.14958, 0.16542, 0.15974, 0.18997, 0.20262, 0.10989, 0.11745, 0.14983, 0.20247, 0.19686, 0.1641, 0.10662, 0.08054, 0.16169, 0.28573, 0.12013, 0.14832, 0.05907, 0.06975, 0.15466, 0.08289, 0.16513, 0.14271, 0.18108, 0.27068, 0.12267, 0.06244, 0.15166, 0.05841, 0.15492, 0.13757, 0.25459, 0.2197, 0.15643, 0.11098, 0.14184, 0.22731, 0.16102, 0.15543, 0.11723, 0.2201, 0.0812, 0.25725, 0.17625, 0.15874, 0.19803, 0.15082, 0.15767, 0.15991, 0.08463, 0.14162, 0.24196, 0.10878, 0.09365, 0.12305, 0.13023, 0.23146, 0.13409, 0.15463, 0.15705, 0.15615, 0.09161, 0.11882, 0.13409, 0.16305, 0.24064, 0.21007, 0.10702, 0.22818, 0.1827, 0.1014, 0.12026, 0.21084, 0.13025, 0.11848, 0.16575, 0.18613, 0.17133, 0.18281, 0.13389, 0.10676, 0.19518, 0.37715, 0.09146, 0.21421, 0.21866, 0.11791, 0.09749, 0.0917, 0.18684, 0.09449, 0.25536, 0.26886, 0.09323, 0.0619, 0.14155, 0.4561, 0.131, 0.10726, 0.25302, 0.2475, 0.08158, 0.10625, 0.24293, 0.06518, 0.025, 0.19171, 0.16272, 0.14776, 0.11814, 0.07114, 0.20081, 0.1613, 0.21645, 0.14126, 0.08129, 0.12732, 0.11255, 0.12111, 0.13751, 0.09082, 0.07116, 0.03604, 0.00867, 0.04479, 0.01696, 0.02835, 0.07226, 0.03663]\n",
      "    Avg Accuracies: [0.975, 0.9833, 0.95, 0.9458, 0.9417, 0.9583, 0.9542, 0.975, 0.9833, 0.9708, 0.975, 0.9792, 0.9583, 0.9792, 0.9833, 0.9583, 0.9542, 0.9792, 0.9542, 0.9625, 0.9458, 0.95, 0.9708, 0.8792, 0.9542, 0.9958, 0.9458, 0.9667, 0.9792, 0.925, 0.9417, 0.9458, 0.9792, 0.9167, 0.95, 0.9208, 0.9, 0.9625, 0.9625, 0.95, 0.9833, 0.9792, 0.9333, 0.9792, 0.9417, 0.9708, 0.975, 0.9333, 0.9458, 0.975, 0.9833, 0.9792, 0.9792, 0.9208, 0.9458, 0.9708, 0.9583, 0.8958, 0.925, 0.9167, 0.95, 0.975, 0.9542, 0.9167, 0.9792, 0.9792, 0.9167, 0.9708, 0.975, 0.9125, 0.9083, 0.9667, 0.9125, 0.9542, 0.9375, 0.9542, 0.9708, 0.9208, 0.9958, 0.9875, 0.9667, 0.9875, 0.95, 0.95, 0.9542, 1.0, 0.9375, 0.9042, 0.9917, 0.9875, 0.9875, 0.9875, 0.95, 0.9333, 0.9083, 0.9917, 0.9917, 0.9833, 0.9833, 0.9625, 0.9583, 0.9417, 0.975, 0.8875, 0.9958, 0.9708, 0.9542, 0.925, 0.9583, 0.9625, 0.925, 0.9333, 0.9667, 0.9625, 0.9625, 0.975, 0.9458, 0.9667, 0.9083, 0.9625, 0.9833, 0.9625, 0.9333, 0.9583, 0.9417, 0.9417, 0.975, 0.9833, 0.9625, 0.9333, 0.9542, 0.95, 0.9667, 0.9958, 0.9542, 0.8958, 0.9667, 0.9583, 0.9917, 0.9875, 0.9583, 0.9875, 0.9458, 0.9583, 0.9417, 0.9, 0.9583, 0.9833, 0.95, 0.9917, 0.9583, 0.975, 0.9125, 0.9333, 0.95, 0.9667, 0.9667, 0.9292, 0.9625, 0.9542, 0.9708, 0.9333, 0.975, 0.9208, 0.9583, 0.9458, 0.9333, 0.9667, 0.9583, 0.9625, 0.9792, 0.9542, 0.9333, 0.9708, 0.975, 0.9625, 0.9667, 0.9208, 0.9708, 0.9542, 0.9458, 0.9458, 0.9708, 0.9667, 0.9667, 0.9417, 0.925, 0.925, 0.9792, 0.9083, 0.9417, 0.9625, 0.9625, 0.9417, 0.9542, 0.9708, 0.9458, 0.9417, 0.95, 0.9458, 0.9625, 0.9667, 0.9542, 0.8625, 0.975, 0.9375, 0.9167, 0.9583, 0.975, 0.975, 0.95, 0.975, 0.9208, 0.9083, 0.9833, 0.9875, 0.95, 0.8333, 0.9542, 0.9708, 0.9208, 0.9375, 0.9708, 0.9667, 0.9375, 0.9792, 0.9958, 0.9333, 0.9542, 0.95, 0.9667, 0.9917, 0.9292, 0.9583, 0.9417, 0.9625, 0.975, 0.975, 0.9625, 0.9583, 0.9583, 0.975, 0.975, 0.9875, 1.0, 0.9958, 1.0, 1.0, 0.9792, 0.9917]\n",
      "\n",
      "Epoch 7/9             \n",
      "    Avg Losses: [0.05834, 0.07073, 0.08048, 0.0759, 0.14879, 0.09428, 0.11831, 0.10729, 0.03594, 0.07427, 0.07501, 0.07781, 0.09248, 0.08953, 0.08008, 0.07049, 0.14388, 0.03623, 0.15169, 0.10606, 0.12547, 0.15153, 0.08385, 0.37848, 0.07085, 0.02877, 0.06338, 0.07612, 0.05012, 0.13298, 0.06318, 0.12489, 0.0824, 0.18062, 0.16569, 0.21259, 0.16624, 0.08065, 0.07743, 0.11845, 0.03364, 0.07532, 0.16234, 0.03915, 0.11609, 0.06766, 0.06957, 0.11172, 0.15318, 0.11812, 0.05342, 0.0876, 0.05018, 0.13129, 0.15327, 0.04041, 0.12113, 0.13545, 0.15829, 0.15355, 0.14181, 0.06859, 0.13484, 0.16352, 0.05865, 0.09934, 0.16624, 0.03554, 0.05875, 0.17585, 0.19614, 0.11113, 0.14367, 0.10595, 0.0971, 0.11461, 0.0907, 0.21013, 0.04447, 0.03814, 0.07343, 0.03706, 0.0885, 0.08157, 0.126, 0.02235, 0.14639, 0.22467, 0.04491, 0.09874, 0.0464, 0.04949, 0.12512, 0.16099, 0.17344, 0.02844, 0.07946, 0.0332, 0.05917, 0.11527, 0.08557, 0.16673, 0.11929, 0.20535, 0.03914, 0.05812, 0.13613, 0.11206, 0.10728, 0.12995, 0.13778, 0.10341, 0.09604, 0.09913, 0.09441, 0.05137, 0.10099, 0.15354, 0.28305, 0.09652, 0.04798, 0.11193, 0.13167, 0.08084, 0.12489, 0.08379, 0.06044, 0.06527, 0.13416, 0.1793, 0.1438, 0.16698, 0.07931, 0.0769, 0.09468, 0.15313, 0.11923, 0.08494, 0.04757, 0.05187, 0.10964, 0.05319, 0.15078, 0.1079, 0.1088, 0.20785, 0.0606, 0.05401, 0.16609, 0.02451, 0.09247, 0.08881, 0.18718, 0.13081, 0.09895, 0.11189, 0.08062, 0.16424, 0.09883, 0.10579, 0.0776, 0.23005, 0.04815, 0.11436, 0.14386, 0.08176, 0.10371, 0.10095, 0.07967, 0.13586, 0.04533, 0.07456, 0.15885, 0.07637, 0.0433, 0.1247, 0.09634, 0.19201, 0.09896, 0.10055, 0.10263, 0.10387, 0.07847, 0.07226, 0.07676, 0.12522, 0.13027, 0.13495, 0.0689, 0.14054, 0.11586, 0.07399, 0.08898, 0.13564, 0.04973, 0.07563, 0.14502, 0.12779, 0.09455, 0.13723, 0.08805, 0.0598, 0.14221, 0.22883, 0.05096, 0.1913, 0.15792, 0.07945, 0.06091, 0.08171, 0.13454, 0.03971, 0.15647, 0.13633, 0.0622, 0.02619, 0.10795, 0.25093, 0.08477, 0.07293, 0.21859, 0.19562, 0.04432, 0.11077, 0.12891, 0.06556, 0.01394, 0.0931, 0.1312, 0.10313, 0.08052, 0.05752, 0.13542, 0.12504, 0.13479, 0.1129, 0.04563, 0.08184, 0.06908, 0.11088, 0.15029, 0.07433, 0.03264, 0.01987, 0.00483, 0.01961, 0.00476, 0.02047, 0.04663, 0.01253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9875, 0.9833, 0.975, 0.9875, 0.9417, 0.975, 0.9708, 0.9583, 0.9958, 0.975, 0.9833, 0.9708, 0.975, 0.9792, 0.9792, 0.975, 0.9375, 0.9958, 0.95, 0.9583, 0.9542, 0.95, 0.9917, 0.8875, 0.9792, 0.9958, 0.9958, 0.9875, 0.9875, 0.9667, 0.9875, 0.9625, 0.9833, 0.9333, 0.95, 0.9417, 0.95, 0.975, 0.9833, 0.9667, 0.9917, 0.9833, 0.9667, 0.9917, 0.9708, 0.9792, 0.9833, 0.9667, 0.9583, 0.9667, 0.9875, 0.9708, 0.9875, 0.9542, 0.9417, 0.9917, 0.975, 0.9708, 0.9458, 0.9542, 0.9583, 0.9917, 0.9458, 0.95, 0.9958, 0.9667, 0.9625, 1.0, 0.9917, 0.925, 0.9375, 0.9625, 0.9625, 0.9792, 0.975, 0.9667, 0.9792, 0.9417, 0.9875, 0.9958, 0.9833, 0.9917, 0.9875, 0.9792, 0.9708, 1.0, 0.95, 0.9208, 0.9917, 0.9667, 0.9792, 0.9917, 0.9625, 0.95, 0.9458, 1.0, 0.9792, 1.0, 0.9833, 0.9625, 0.975, 0.9667, 0.9667, 0.9375, 0.9917, 0.9917, 0.975, 0.9833, 0.9667, 0.9667, 0.95, 0.975, 0.9667, 0.975, 0.9833, 0.9917, 0.975, 0.9458, 0.9375, 0.9667, 0.9917, 0.975, 0.9667, 0.9792, 0.9708, 0.9958, 0.9875, 0.9875, 0.9542, 0.9417, 0.9667, 0.9542, 0.9833, 0.9875, 0.975, 0.9375, 0.9708, 0.975, 0.9875, 0.9917, 0.9708, 0.9917, 0.9583, 0.9708, 0.9708, 0.925, 0.9917, 0.9833, 0.95, 1.0, 0.9792, 0.9708, 0.9417, 0.9708, 0.9792, 0.9542, 0.9833, 0.95, 0.9792, 0.9708, 0.975, 0.925, 0.9875, 0.975, 0.9458, 0.9833, 0.9708, 0.975, 0.9792, 0.9417, 0.9917, 0.9833, 0.9542, 0.9792, 0.9917, 0.9542, 0.9792, 0.9458, 0.9708, 0.9792, 0.9625, 0.9708, 0.9792, 0.9792, 0.9792, 0.9542, 0.9625, 0.9625, 0.9833, 0.9667, 0.975, 0.9708, 0.9833, 0.9583, 0.9917, 0.9708, 0.95, 0.9583, 0.975, 0.9583, 0.975, 0.9833, 0.9542, 0.9292, 0.9917, 0.9375, 0.9417, 0.9833, 0.9917, 0.975, 0.975, 1.0, 0.95, 0.9625, 0.9917, 1.0, 0.9667, 0.9125, 0.9708, 0.9833, 0.9167, 0.9375, 0.9958, 0.9708, 0.975, 0.9792, 1.0, 0.975, 0.95, 0.9708, 0.975, 0.9875, 0.9542, 0.9625, 0.9708, 0.9708, 0.9917, 0.9792, 0.9875, 0.975, 0.9542, 0.975, 0.9917, 1.0, 1.0, 1.0, 1.0, 0.9958, 0.9875, 0.9958]\n",
      "\n",
      "Epoch 8/9             \n",
      "    Avg Losses: [0.03995, 0.06138, 0.05498, 0.05937, 0.11328, 0.07282, 0.07717, 0.07598, 0.0328, 0.05466, 0.07413, 0.0571, 0.05234, 0.07359, 0.07445, 0.0746, 0.07749, 0.02962, 0.14579, 0.07868, 0.11498, 0.10302, 0.04089, 0.22174, 0.05037, 0.01323, 0.05585, 0.06108, 0.03363, 0.07983, 0.06463, 0.09292, 0.06347, 0.10364, 0.15478, 0.23457, 0.1454, 0.06555, 0.04011, 0.07495, 0.0158, 0.05045, 0.14531, 0.02, 0.09626, 0.05094, 0.0419, 0.06314, 0.12398, 0.10141, 0.02434, 0.0374, 0.02496, 0.10853, 0.09782, 0.0238, 0.07472, 0.09934, 0.10428, 0.12052, 0.07706, 0.05696, 0.07891, 0.12508, 0.03373, 0.0553, 0.10905, 0.03177, 0.02443, 0.11184, 0.12434, 0.08, 0.13529, 0.07029, 0.08337, 0.05866, 0.04461, 0.13906, 0.02156, 0.0236, 0.05312, 0.01627, 0.04943, 0.03856, 0.07297, 0.01777, 0.08884, 0.13959, 0.03528, 0.07452, 0.02281, 0.04139, 0.08074, 0.08508, 0.1042, 0.01736, 0.07006, 0.03327, 0.0486, 0.11163, 0.06645, 0.1228, 0.068, 0.13056, 0.02166, 0.03928, 0.09307, 0.06295, 0.07548, 0.10061, 0.17663, 0.06378, 0.04079, 0.05077, 0.07034, 0.0229, 0.06104, 0.08616, 0.2355, 0.05719, 0.03414, 0.0675, 0.09499, 0.04141, 0.11153, 0.05886, 0.03861, 0.0294, 0.07094, 0.07978, 0.10695, 0.10273, 0.04103, 0.05286, 0.0487, 0.08915, 0.08765, 0.05744, 0.04652, 0.03623, 0.07377, 0.04568, 0.07608, 0.05198, 0.07533, 0.1537, 0.04903, 0.03436, 0.08959, 0.01384, 0.05877, 0.05402, 0.1222, 0.08174, 0.06904, 0.06084, 0.05833, 0.10831, 0.04885, 0.06428, 0.06475, 0.15385, 0.02049, 0.09896, 0.15506, 0.04405, 0.08106, 0.05307, 0.04126, 0.09051, 0.0742, 0.07674, 0.12817, 0.04493, 0.0399, 0.04661, 0.06763, 0.2018, 0.0689, 0.06395, 0.06032, 0.06969, 0.05409, 0.03921, 0.04776, 0.06659, 0.09299, 0.13289, 0.08031, 0.135, 0.06883, 0.07387, 0.05587, 0.08272, 0.02413, 0.05022, 0.12936, 0.09615, 0.06301, 0.07428, 0.06649, 0.05197, 0.11526, 0.15349, 0.04409, 0.17026, 0.09499, 0.04611, 0.03372, 0.07905, 0.06935, 0.01918, 0.09003, 0.10747, 0.0399, 0.01547, 0.05196, 0.21334, 0.05923, 0.04589, 0.19771, 0.15837, 0.02159, 0.07528, 0.10893, 0.05143, 0.00993, 0.06735, 0.11693, 0.07694, 0.05161, 0.03519, 0.11815, 0.08425, 0.10332, 0.0721, 0.03496, 0.02968, 0.03104, 0.04755, 0.11012, 0.0408, 0.01513, 0.01007, 0.00325, 0.00905, 0.00289, 0.02576, 0.03286, 0.01255]\n",
      "    Avg Accuracies: [0.9958, 0.9875, 0.9875, 0.9875, 0.9583, 0.9792, 0.9875, 0.9833, 0.9958, 0.9917, 0.9833, 0.9833, 0.9833, 0.9917, 0.9917, 0.9792, 0.9875, 0.9917, 0.9458, 0.9708, 0.9625, 0.9792, 1.0, 0.9292, 0.9917, 1.0, 0.9875, 0.9875, 0.9958, 0.9833, 0.9833, 0.9708, 0.9958, 0.975, 0.9375, 0.9292, 0.9667, 0.9792, 1.0, 0.9875, 1.0, 0.9917, 0.9625, 1.0, 0.975, 0.9875, 0.9958, 0.9917, 0.9625, 0.975, 0.9958, 0.9958, 1.0, 0.9625, 0.9708, 1.0, 0.9875, 0.9792, 0.9792, 0.975, 0.9792, 0.9833, 0.975, 0.9542, 0.9958, 0.9875, 0.9667, 0.9958, 1.0, 0.9625, 0.9583, 0.9792, 0.9583, 0.9917, 0.9792, 0.9875, 0.9833, 0.95, 1.0, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9833, 1.0, 0.975, 0.95, 0.9958, 0.9833, 0.9958, 0.9875, 0.9792, 0.9792, 0.975, 1.0, 0.975, 0.9917, 0.9875, 0.9667, 0.9833, 0.9708, 0.9875, 0.9708, 1.0, 0.9917, 0.9833, 0.9917, 0.9833, 0.975, 0.9542, 0.9875, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 0.9792, 0.9375, 0.9875, 0.9917, 0.9875, 0.975, 1.0, 0.9667, 1.0, 0.9958, 1.0, 0.9833, 0.9833, 0.975, 0.975, 0.9958, 0.9958, 0.9917, 0.9833, 0.9833, 0.9792, 0.9917, 0.9958, 0.9792, 0.9917, 0.9833, 0.9917, 0.9625, 0.9417, 0.9958, 0.9958, 0.9625, 1.0, 0.9958, 0.9792, 0.975, 0.9833, 0.9792, 0.975, 0.9833, 0.9708, 1.0, 0.9875, 0.9792, 0.9542, 1.0, 0.9667, 0.9458, 0.9958, 0.9792, 0.9958, 0.9958, 0.9792, 0.9875, 0.9792, 0.9583, 0.9875, 0.9917, 0.9958, 0.9708, 0.9292, 0.9875, 0.9875, 0.9875, 0.9875, 0.9875, 0.9958, 0.9958, 0.9833, 0.975, 0.9625, 0.9667, 0.9625, 0.9875, 0.9833, 0.9917, 0.975, 1.0, 0.9917, 0.9583, 0.9833, 0.9792, 0.9875, 0.9792, 0.9917, 0.9625, 0.9708, 0.9958, 0.9417, 0.975, 0.9958, 1.0, 0.9833, 0.9917, 1.0, 0.975, 0.9667, 0.9958, 1.0, 0.9875, 0.9417, 0.9917, 0.9958, 0.9417, 0.9458, 1.0, 0.975, 0.9583, 0.9917, 1.0, 0.9833, 0.9667, 0.9792, 0.9958, 0.9958, 0.9667, 0.9708, 0.975, 0.9875, 0.9917, 0.9958, 1.0, 0.9958, 0.975, 0.9917, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9917, 0.9958]\n",
      "\n",
      "Epoch 9/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.031, 0.04517, 0.03066, 0.03853, 0.07917, 0.04407, 0.06208, 0.04161, 0.02878, 0.03631, 0.04314, 0.05493, 0.04891, 0.06261, 0.03742, 0.08305, 0.05574, 0.03096, 0.10272, 0.03162, 0.06426, 0.05753, 0.034, 0.15973, 0.04476, 0.01089, 0.04388, 0.04683, 0.03168, 0.05778, 0.02028, 0.09152, 0.03384, 0.07283, 0.17371, 0.10615, 0.16491, 0.03162, 0.01737, 0.0596, 0.01094, 0.04787, 0.08315, 0.01412, 0.06868, 0.02896, 0.03201, 0.05543, 0.06618, 0.08458, 0.02304, 0.04318, 0.01237, 0.07127, 0.04412, 0.01501, 0.05284, 0.06106, 0.07912, 0.10177, 0.05127, 0.05591, 0.04659, 0.07581, 0.02393, 0.03881, 0.06762, 0.01572, 0.01738, 0.08198, 0.06707, 0.041, 0.0525, 0.05158, 0.05392, 0.04268, 0.0377, 0.17164, 0.01386, 0.01488, 0.04279, 0.01018, 0.04226, 0.02558, 0.03742, 0.00893, 0.05678, 0.1312, 0.02546, 0.03908, 0.03055, 0.02347, 0.05537, 0.0586, 0.07012, 0.01602, 0.07654, 0.0159, 0.02497, 0.11268, 0.03171, 0.09127, 0.04479, 0.10482, 0.01504, 0.02406, 0.06633, 0.04686, 0.024, 0.07013, 0.12874, 0.04362, 0.02517, 0.04849, 0.02334, 0.01919, 0.03114, 0.06032, 0.23028, 0.05631, 0.02968, 0.04956, 0.06809, 0.03677, 0.11087, 0.03967, 0.03578, 0.01589, 0.05348, 0.07313, 0.07633, 0.08074, 0.03126, 0.02764, 0.02421, 0.05108, 0.05997, 0.0596, 0.01848, 0.02501, 0.04052, 0.02382, 0.05609, 0.03103, 0.06396, 0.07899, 0.05093, 0.03367, 0.05159, 0.00675, 0.03366, 0.04174, 0.09989, 0.06058, 0.061, 0.09375, 0.02733, 0.07384, 0.03385, 0.05379, 0.05258, 0.15105, 0.00975, 0.09722, 0.07278, 0.02751, 0.03874, 0.02309, 0.0298, 0.04656, 0.13627, 0.04432, 0.08107, 0.02847, 0.01842, 0.03752, 0.06903, 0.12881, 0.05086, 0.03411, 0.04611, 0.03765, 0.03096, 0.01933, 0.04217, 0.03988, 0.05568, 0.06465, 0.04674, 0.07711, 0.06134, 0.06254, 0.0272, 0.05864, 0.01308, 0.02891, 0.08042, 0.04495, 0.06022, 0.03798, 0.04995, 0.05755, 0.07308, 0.12716, 0.02783, 0.13948, 0.04818, 0.0283, 0.03052, 0.05152, 0.0431, 0.01497, 0.06522, 0.06901, 0.02532, 0.01004, 0.04632, 0.13132, 0.03727, 0.0369, 0.12954, 0.08095, 0.01483, 0.09324, 0.10393, 0.01863, 0.00498, 0.0487, 0.1049, 0.05475, 0.03007, 0.02111, 0.07793, 0.04338, 0.08268, 0.03546, 0.0212, 0.01903, 0.03429, 0.03664, 0.10482, 0.02517, 0.0174, 0.00523, 0.00205, 0.00635, 0.00237, 0.01455, 0.02026, 0.00675]\n",
      "    Avg Accuracies: [1.0, 0.9833, 0.9958, 1.0, 0.9792, 0.9917, 0.9917, 0.9917, 0.9917, 0.9875, 0.9917, 0.9833, 0.9917, 0.9792, 0.9917, 0.975, 0.9833, 0.9958, 0.9625, 0.9958, 0.9833, 0.9875, 0.9958, 0.9583, 0.9875, 1.0, 0.9875, 0.9917, 0.9958, 0.9875, 1.0, 0.9667, 1.0, 0.9792, 0.9542, 0.9667, 0.9417, 0.9958, 1.0, 0.9917, 1.0, 0.9792, 0.9833, 1.0, 0.9792, 1.0, 0.9958, 0.9875, 0.9875, 0.9708, 1.0, 0.9958, 1.0, 0.9833, 0.9958, 1.0, 0.9917, 0.9875, 0.9833, 0.975, 0.9833, 0.9833, 0.9875, 0.9875, 1.0, 0.9958, 0.9958, 1.0, 1.0, 0.9708, 0.9833, 0.9875, 0.9917, 0.9875, 0.9917, 0.9917, 0.9917, 0.95, 1.0, 1.0, 0.9875, 1.0, 0.9917, 1.0, 1.0, 1.0, 0.9958, 0.9625, 0.9958, 0.9875, 0.9917, 1.0, 0.9917, 0.9958, 0.9833, 1.0, 0.975, 1.0, 1.0, 0.9625, 0.9958, 0.975, 0.9917, 0.975, 0.9958, 0.9958, 0.975, 0.9958, 1.0, 0.9792, 0.9583, 0.9958, 0.9958, 0.9917, 1.0, 1.0, 1.0, 0.9875, 0.925, 0.9875, 0.9958, 0.9875, 0.9792, 0.9958, 0.9667, 0.9917, 0.9958, 1.0, 0.9875, 0.9792, 0.9958, 0.9833, 0.9958, 1.0, 1.0, 0.9958, 0.9875, 0.9833, 1.0, 1.0, 0.9958, 1.0, 0.9875, 1.0, 0.9708, 0.975, 0.9917, 0.9917, 0.9833, 1.0, 0.9958, 0.9958, 0.975, 0.9917, 0.9875, 0.9667, 0.9958, 0.9875, 0.9958, 0.9833, 0.9833, 0.9667, 1.0, 0.975, 0.9833, 1.0, 0.9958, 1.0, 1.0, 0.9958, 0.9542, 0.9958, 0.9833, 0.9958, 0.9958, 0.9917, 0.9792, 0.9583, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9875, 0.9958, 0.9958, 0.9792, 0.9917, 0.9833, 0.9875, 0.9833, 1.0, 0.9833, 1.0, 1.0, 0.975, 1.0, 0.9875, 0.9917, 0.9917, 0.9875, 0.9833, 0.9667, 1.0, 0.9583, 0.9958, 1.0, 0.9958, 0.9792, 0.9958, 1.0, 0.9875, 0.9875, 1.0, 1.0, 0.9833, 0.9583, 0.9917, 0.9875, 0.9583, 0.9792, 1.0, 0.9625, 0.9667, 1.0, 1.0, 0.9958, 0.9583, 0.9917, 0.9958, 1.0, 0.9792, 1.0, 0.9833, 1.0, 0.9958, 1.0, 0.9917, 0.9958, 0.9667, 1.0, 0.9958, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr         = 3e-2\n",
    "n_epochs   = 10\n",
    "batch_size = 30\n",
    "\n",
    "teacher_dataloaders = [data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True) for dataset in teacher_datasets]\n",
    "teacher_optimizers  = [optim.Adam(model.parameters(), lr=lr) for model in teachers]\n",
    "criterion           = nn.CrossEntropyLoss()\n",
    "\n",
    "for model in teachers:\n",
    "    model.train()\n",
    "\n",
    "teachers_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    avg_losses      = []\n",
    "    avg_accuracies  = []\n",
    "\n",
    "    for i_model in range(n_teachers):\n",
    "        instance_count = 0\n",
    "        total_loss     = 0.\n",
    "        correct_count  = 0\n",
    "\n",
    "        model      = teachers[i_model]\n",
    "        dataloader = teacher_dataloaders[i_model]\n",
    "        optimizer  = teacher_optimizers[i_model]\n",
    "\n",
    "        n_batches = len(dataloader)\n",
    "        _prev_str_len = 0\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            _batch_str = \"Teacher {:d}/{:d}: ({:d}/{:d})\".format(i_model, n_teachers-1, i, n_batches-1)\n",
    "            print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "            _prev_str_len = len(_batch_str)\n",
    "\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs  = model(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            \n",
    "            correct_count += (preds == labels).sum().item()\n",
    "\n",
    "        avg_losses.append(total_loss / instance_count)\n",
    "        avg_accuracies.append(correct_count / instance_count)\n",
    "\n",
    "    _epoch_str = \"Epoch {:d}/{:d}\".format(i_epoch, n_epochs-1)\n",
    "    _epoch_str += ' ' * (_prev_str_len - len(_epoch_str))\n",
    "    print(_epoch_str)\n",
    "    print(\"    Avg Losses:\", [round(avg_loss, 5) for avg_loss in avg_losses])\n",
    "    print(\"    Avg Accuracies:\", [round(avg_acc, 4) for avg_acc in avg_accuracies])\n",
    "    print()\n",
    "\n",
    "    teachers_train_history['avg_losses'][i_epoch]     = avg_losses\n",
    "    teachers_train_history['avg_accuracies'][i_epoch] = avg_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Evaluation (Average and Aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:10:25.498877Z",
     "start_time": "2019-06-25T17:10:23.432583Z"
    },
    "code_folding": [
     15
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/0 - Teacher 249/249\n",
      "\n",
      "Average Loss: 0.7392376829833984\n",
      "Average Accuracy: 0.815656\n",
      "\n",
      "Aggregate Accuracy: 0.9629999995231628\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "preds_lists_list = []\n",
    "labels_list      = []\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "\n",
    "    imgs   = imgs.to(device)\n",
    "    labels_list.append(labels)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            preds_list.append(preds.cpu())\n",
    "\n",
    "            total_loss += criterion(outs, labels).item()\n",
    "            correct_count += (preds == labels).sum().item()\n",
    "    preds_lists_list.append(preds_list)\n",
    "\n",
    "preds_tensor = torch.cat([torch.stack(preds_list, dim=0) for preds_list in preds_lists_list], dim=1)\n",
    "preds_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=preds_tensor.numpy()))\n",
    "\n",
    "aggregate_preds = preds_counts.argmax(dim=0)\n",
    "labels          = torch.cat(labels_list, dim=0)\n",
    "\n",
    "aggregate_acc = (aggregate_preds == labels).float().mean().item()\n",
    "\n",
    "print('\\n')\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)\n",
    "print()\n",
    "print(\"Aggregate Accuracy:\", aggregate_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:10:25.511307Z",
     "start_time": "2019-06-25T17:10:25.501854Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def aggregate_counts(img, return_label_preds=False):\n",
    "    assert 3 <= img.dim() <= 4\n",
    "    if img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    else:\n",
    "        assert img.size(0) == 1\n",
    "\n",
    "    img = img.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in teachers:\n",
    "            model.eval()\n",
    "            preds_list.append(model(img).argmax(dim=1).view(1).cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(preds_list, dim=0)\n",
    "    \n",
    "    counts = torch.bincount(preds_tensor, minlength=10)\n",
    "    \n",
    "    if return_label_preds:\n",
    "        return counts, preds_tensor\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:11:59.652186Z",
     "start_time": "2019-06-25T17:10:25.513758Z"
    },
    "code_folding": [
     28
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19 - Number of Labeled Data: 5\n",
      "    Update 0 - Loss = 2.516278, Accuracy = 0.0\n",
      "    Update 1 - Loss = 1.813576, Accuracy = 0.2\n",
      "    Update 2 - Loss = 1.451643, Accuracy = 1.0\n",
      "    Update 3 - Loss = 1.171823, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.919899, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.684254, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.458117, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.295014, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.171470, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.095434, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.055843, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.034436, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.020803, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.012203, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.007342, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004648, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003143, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002238, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001647, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001253, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.000992, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.000808, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.000676, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.000574, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000493, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000428, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000373, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000327, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000287, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000254, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000226, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000202, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000181, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000163, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000147, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000133, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000122, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000112, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000103, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000096, Accuracy = 1.0\n",
      "Epoch 1/19 - Number of Labeled Data: 10\n",
      "    Update 0 - Loss = 7.142651, Accuracy = 0.5\n",
      "    Update 1 - Loss = 5.819632, Accuracy = 0.5\n",
      "    Update 2 - Loss = 4.560114, Accuracy = 0.5\n",
      "    Update 3 - Loss = 3.351016, Accuracy = 0.5\n",
      "    Update 4 - Loss = 2.202660, Accuracy = 0.5\n",
      "    Update 5 - Loss = 1.267522, Accuracy = 0.5\n",
      "    Update 6 - Loss = 0.930922, Accuracy = 0.8\n",
      "    Update 7 - Loss = 1.058129, Accuracy = 0.5\n",
      "    Update 8 - Loss = 1.004701, Accuracy = 0.7\n",
      "    Update 9 - Loss = 0.883789, Accuracy = 0.7\n",
      "    Update 10 - Loss = 0.809728, Accuracy = 0.9\n",
      "    Update 11 - Loss = 0.738038, Accuracy = 0.9\n",
      "    Update 12 - Loss = 0.643516, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.528491, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.435607, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.375358, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.331123, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.284801, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.239592, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.200765, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.167680, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.137045, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.110239, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.090079, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.075308, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.062942, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.052699, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.045027, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.038682, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.033212, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.028384, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.024089, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.020370, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.017286, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.014812, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.012812, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.011156, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.009768, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.008648, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.007734, Accuracy = 1.0\n",
      "Epoch 2/19 - Number of Labeled Data: 15\n",
      "    Update 0 - Loss = 1.470720, Accuracy = 0.6667\n",
      "    Update 1 - Loss = 1.263093, Accuracy = 0.7333\n",
      "    Update 2 - Loss = 1.082498, Accuracy = 0.7333\n",
      "    Update 3 - Loss = 0.843414, Accuracy = 0.7333\n",
      "    Update 4 - Loss = 0.595139, Accuracy = 0.8667\n",
      "    Update 5 - Loss = 0.404721, Accuracy = 0.8667\n",
      "    Update 6 - Loss = 0.260972, Accuracy = 0.8667\n",
      "    Update 7 - Loss = 0.155984, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.102032, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.089961, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.097272, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.106304, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.104268, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.089615, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.069035, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.051060, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.039243, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.031327, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.025903, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.021593, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.018204, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.015415, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.013229, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.011622, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.010445, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.009513, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.008771, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.008143, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.007593, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.007104, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.006663, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.006257, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.005878, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.005526, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.005195, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.004882, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.004590, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.004316, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.004055, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.003808, Accuracy = 1.0\n",
      "Epoch 3/19 - Number of Labeled Data: 20\n",
      "    Update 0 - Loss = 0.503072, Accuracy = 0.75\n",
      "    Update 1 - Loss = 0.395477, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.288453, Accuracy = 0.95\n",
      "    Update 3 - Loss = 0.211366, Accuracy = 0.95\n",
      "    Update 4 - Loss = 0.152595, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.116055, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.086693, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.065866, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.053127, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.045775, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.039846, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.034585, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.029327, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.023848, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.019055, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.015646, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.013361, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.011791, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.010722, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.009906, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.009230, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.008661, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.008138, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.007608, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.007083, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.006542, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.006014, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.005521, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.005072, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004673, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004318, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.004003, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003729, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003499, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.003307, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.003144, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.003001, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002872, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002751, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002640, Accuracy = 1.0\n",
      "Epoch 4/19 - Number of Labeled Data: 25\n",
      "    Update 0 - Loss = 0.578370, Accuracy = 0.8\n",
      "    Update 1 - Loss = 0.422768, Accuracy = 0.84\n",
      "    Update 2 - Loss = 0.270169, Accuracy = 0.92\n",
      "    Update 3 - Loss = 0.161630, Accuracy = 0.92\n",
      "    Update 4 - Loss = 0.098833, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.079270, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 6 - Loss = 0.077698, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.061360, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.043584, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.033311, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.029581, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.029295, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.026632, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.023628, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.021323, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.018907, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.016757, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.015043, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.013442, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.011802, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.010276, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.008963, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.007841, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.006883, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.006069, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.005384, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.004865, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.004483, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.004122, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.003810, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.003560, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003357, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003179, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003025, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002880, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002747, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002623, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002506, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002395, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002289, Accuracy = 1.0\n",
      "Epoch 5/19 - Number of Labeled Data: 30\n",
      "    Update 0 - Loss = 0.352625, Accuracy = 0.8333\n",
      "    Update 1 - Loss = 0.157014, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.073230, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.081644, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.093557, Accuracy = 0.9667\n",
      "    Update 5 - Loss = 0.071000, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.047754, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.041033, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.034321, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.026316, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.020929, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.017674, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.015500, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.013690, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.012115, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.010832, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.009846, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.009210, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.008793, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.008465, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.008099, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.007632, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.007064, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.006445, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.005869, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.005359, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.004916, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.004542, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.004219, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.003945, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.003703, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003491, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003300, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003125, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002966, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002819, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002682, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002557, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002442, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002337, Accuracy = 1.0\n",
      "Epoch 6/19 - Number of Labeled Data: 35\n",
      "    Update 0 - Loss = 0.310532, Accuracy = 0.8857\n",
      "    Update 1 - Loss = 0.216789, Accuracy = 0.9143\n",
      "    Update 2 - Loss = 0.135088, Accuracy = 0.9429\n",
      "    Update 3 - Loss = 0.073494, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.037228, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.033929, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.040097, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.044543, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.042120, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.033994, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.025716, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.019667, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.015790, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.013512, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.011917, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.010529, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.009409, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.008448, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.007614, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.006848, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.006194, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.005660, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.005235, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.004931, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.004713, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.004556, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.004410, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.004260, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.004087, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.003897, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.003696, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003498, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003311, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003139, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002987, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002848, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002724, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002613, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002515, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002422, Accuracy = 1.0\n",
      "Epoch 7/19 - Number of Labeled Data: 40\n",
      "    Update 0 - Loss = 0.542208, Accuracy = 0.875\n",
      "    Update 1 - Loss = 0.420972, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.316771, Accuracy = 0.95\n",
      "    Update 3 - Loss = 0.233501, Accuracy = 0.975\n",
      "    Update 4 - Loss = 0.165785, Accuracy = 0.975\n",
      "    Update 5 - Loss = 0.103264, Accuracy = 0.975\n",
      "    Update 6 - Loss = 0.050502, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.049628, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.084264, Accuracy = 0.975\n",
      "    Update 9 - Loss = 0.057231, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.028955, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.021052, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.020397, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.019657, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.017274, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.014981, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.013365, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.012149, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.010984, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.009766, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.008622, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.007606, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.006667, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.005877, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.005289, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.004839, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.004469, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.004144, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.003825, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.003521, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.003238, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.002978, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.002741, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.002531, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002348, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002188, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002048, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001926, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001817, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001722, Accuracy = 1.0\n",
      "Epoch 8/19 - Number of Labeled Data: 45\n",
      "    Update 0 - Loss = 0.207733, Accuracy = 0.8889\n",
      "    Update 1 - Loss = 0.118085, Accuracy = 0.9333\n",
      "    Update 2 - Loss = 0.060667, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.030399, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.020919, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.021650, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.022519, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.019100, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.016028, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.014299, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.013205, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.012267, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.011274, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 13 - Loss = 0.010081, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.008916, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.007898, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.007060, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.006424, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.005910, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.005481, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.005076, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.004708, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.004364, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.004089, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.003843, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.003618, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.003394, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.003178, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002973, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002787, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.002615, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.002458, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.002317, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.002197, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002086, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001979, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001880, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001789, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001705, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001628, Accuracy = 1.0\n",
      "Epoch 9/19 - Number of Labeled Data: 50\n",
      "    Update 0 - Loss = 0.182155, Accuracy = 0.92\n",
      "    Update 1 - Loss = 0.091332, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.045034, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.027190, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.020627, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.023820, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.026525, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.023118, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.017006, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.012212, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.009378, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.008307, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.008385, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.008911, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.009054, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.008283, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.006863, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.005397, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.004246, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003498, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003056, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002792, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002603, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002459, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002311, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002150, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001989, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001833, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001701, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001583, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001473, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001383, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001304, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001236, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001179, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001133, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001093, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001058, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001027, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000997, Accuracy = 1.0\n",
      "Epoch 10/19 - Number of Labeled Data: 55\n",
      "    Update 0 - Loss = 0.280900, Accuracy = 0.9273\n",
      "    Update 1 - Loss = 0.215509, Accuracy = 0.9636\n",
      "    Update 2 - Loss = 0.159651, Accuracy = 0.9818\n",
      "    Update 3 - Loss = 0.112549, Accuracy = 0.9818\n",
      "    Update 4 - Loss = 0.064995, Accuracy = 0.9818\n",
      "    Update 5 - Loss = 0.026130, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.020520, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.032043, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.040585, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.033739, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.026495, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.024252, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.018925, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.012198, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.007851, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005529, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004381, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003858, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003651, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003610, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003605, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003574, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003496, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.003353, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.003172, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002973, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002757, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002556, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002380, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002226, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.002089, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001969, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001863, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001768, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001681, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001601, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001527, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001457, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001392, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001331, Accuracy = 1.0\n",
      "Epoch 11/19 - Number of Labeled Data: 60\n",
      "    Update 0 - Loss = 0.159170, Accuracy = 0.9167\n",
      "    Update 1 - Loss = 0.105554, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.053403, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.027092, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.017178, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.016827, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.020010, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.022177, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.020530, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.016418, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.012715, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.010526, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.009331, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.008137, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.006785, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005501, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004578, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003992, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003658, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003462, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003351, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003253, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003128, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002968, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002778, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002571, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002361, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002163, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001983, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001828, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001695, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001582, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001489, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001411, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001344, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001286, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001235, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001190, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001150, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001114, Accuracy = 1.0\n",
      "Epoch 12/19 - Number of Labeled Data: 65\n",
      "    Update 0 - Loss = 0.170153, Accuracy = 0.9385\n",
      "    Update 1 - Loss = 0.120486, Accuracy = 0.9846\n",
      "    Update 2 - Loss = 0.083390, Accuracy = 0.9846\n",
      "    Update 3 - Loss = 0.053275, Accuracy = 0.9846\n",
      "    Update 4 - Loss = 0.029813, Accuracy = 0.9846\n",
      "    Update 5 - Loss = 0.020809, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.017728, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.015439, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.013617, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.013784, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.014869, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.013944, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.011088, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.008381, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.006604, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005524, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004717, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.004024, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003453, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003019, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 20 - Loss = 0.002718, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002507, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002357, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002251, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002177, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002125, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002082, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002045, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002007, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001959, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001898, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001826, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001746, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001662, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001578, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001498, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001420, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001347, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001279, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001217, Accuracy = 1.0\n",
      "Epoch 13/19 - Number of Labeled Data: 70\n",
      "    Update 0 - Loss = 0.111025, Accuracy = 0.9571\n",
      "    Update 1 - Loss = 0.058010, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.018385, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.006587, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.004643, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.005594, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.007420, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.008738, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.008876, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.007942, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.006640, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005522, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004848, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004535, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004369, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004273, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004169, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.004005, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003729, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003379, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003028, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002719, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002465, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002259, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002087, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001940, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001809, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001692, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001589, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001497, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001416, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001344, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001281, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001227, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001179, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001137, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001099, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001063, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001031, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001002, Accuracy = 1.0\n",
      "Epoch 14/19 - Number of Labeled Data: 75\n",
      "    Update 0 - Loss = 0.075495, Accuracy = 0.9867\n",
      "    Update 1 - Loss = 0.042251, Accuracy = 0.9867\n",
      "    Update 2 - Loss = 0.019301, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.010069, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.007939, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.007956, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.007171, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.005977, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.005097, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.004592, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004414, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004408, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004483, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004527, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004440, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004210, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003856, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003444, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003031, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002660, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002342, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002080, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001869, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001704, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001574, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001469, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001381, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001308, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001246, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001188, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001133, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001083, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001036, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000990, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000945, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000903, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000864, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000827, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000793, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000762, Accuracy = 1.0\n",
      "Epoch 15/19 - Number of Labeled Data: 80\n",
      "    Update 0 - Loss = 0.093311, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.045038, Accuracy = 0.9875\n",
      "    Update 2 - Loss = 0.020887, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.008976, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.004552, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.005199, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.006592, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.007590, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.007942, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.007046, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.005410, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004231, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003680, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003476, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003424, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003385, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003264, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003031, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002704, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002333, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001971, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001663, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001425, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001240, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001101, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000999, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000924, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000867, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000823, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000790, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000764, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000742, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000724, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000709, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000695, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000682, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000669, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000657, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000646, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000634, Accuracy = 1.0\n",
      "Epoch 16/19 - Number of Labeled Data: 85\n",
      "    Update 0 - Loss = 0.078610, Accuracy = 0.9765\n",
      "    Update 1 - Loss = 0.037611, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.016455, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.013109, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.020020, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.016926, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.008699, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.004977, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.003824, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.003798, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004379, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005059, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.005294, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004834, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004024, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003295, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002774, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002426, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002191, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002023, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001897, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001797, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001716, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001637, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001558, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001475, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001387, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 27 - Loss = 0.001297, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001211, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001129, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001055, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000988, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000930, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000879, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000836, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000799, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000768, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000740, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000716, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000694, Accuracy = 1.0\n",
      "Epoch 17/19 - Number of Labeled Data: 90\n",
      "    Update 0 - Loss = 0.095339, Accuracy = 0.9556\n",
      "    Update 1 - Loss = 0.055714, Accuracy = 0.9778\n",
      "    Update 2 - Loss = 0.021279, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.008717, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.007046, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.010180, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.013835, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.013420, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.010012, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.007027, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.005274, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004321, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003821, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003535, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003373, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003288, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003232, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003176, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003087, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002931, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002716, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002456, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002196, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001946, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001738, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001568, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001436, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001336, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001260, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001200, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001147, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001099, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001051, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001002, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000952, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000903, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000856, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000811, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000771, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000737, Accuracy = 1.0\n",
      "Epoch 18/19 - Number of Labeled Data: 95\n",
      "    Update 0 - Loss = 0.051182, Accuracy = 0.9895\n",
      "    Update 1 - Loss = 0.025765, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.009456, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.004352, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.003830, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.005067, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.006608, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.007065, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.006199, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.004954, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.003994, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003384, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.002976, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002714, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002524, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002343, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002158, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001980, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001810, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001659, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001532, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001430, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001343, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001266, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001194, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001126, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001060, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000996, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000938, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000884, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000836, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000793, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000755, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000722, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000693, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000668, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000646, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000627, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000609, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000594, Accuracy = 1.0\n",
      "Epoch 19/19 - Number of Labeled Data: 100\n",
      "    Update 0 - Loss = 0.123425, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.067287, Accuracy = 0.98\n",
      "    Update 2 - Loss = 0.021514, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.008606, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.008686, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.009042, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.009461, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.010143, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.009716, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.006480, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004965, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004552, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004430, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004400, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004395, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004212, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003850, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003443, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003097, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002828, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002625, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002483, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002384, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002310, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002241, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002160, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002060, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001947, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001824, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001696, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001572, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001456, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001353, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001263, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001184, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001114, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001053, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001000, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000953, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000913, Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "max_train_subset_size  = 100\n",
    "n_new_labels_per_epoch = 5\n",
    "n_updates_per_epoch    = 40\n",
    "lr                     = 2e-2\n",
    "weight_decay           = 0\n",
    "epsilon                = 0.05\n",
    "\n",
    "student = MNISTClassifier().to(device)\n",
    "\n",
    "laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                               batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "student.train()\n",
    "\n",
    "teacher_preds = []\n",
    "noisy_labels  = []\n",
    "student_train_history = {'n_labels': {}, 'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_total_epochs):\n",
    "    if i_epoch == 0:\n",
    "        new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "    else:\n",
    "        max_probs_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in student_unlabeled_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "\n",
    "                outs  = student(imgs)\n",
    "                probs = outs.softmax(dim=1)\n",
    "\n",
    "                max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "        max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "        \n",
    "        new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                             max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "    for idx in new_label_indices:\n",
    "        student_labeled_dataset.indices.append(idx)\n",
    "        student_unlabeled_dataset.indices.remove(idx)\n",
    "        label_pred_counts, label_preds = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28), True)\n",
    "        noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "        mnist_testset.targets[idx] = noisy_label\n",
    "\n",
    "        teacher_preds.append(label_preds)\n",
    "        noisy_labels.append(noisy_label)\n",
    "        \n",
    "    student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "    \n",
    "    print(\"Epoch {:d}/{:d} - Number of Labeled Data: {:d}\".format(i_epoch, n_total_epochs-1, len(student_labeled_dataset)))\n",
    "\n",
    "    student_train_history['n_labels'][i_epoch] = init_subset_size + (i_epoch * n_new_labels_per_epoch)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i_update in range(n_updates_per_epoch):\n",
    "        imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = student(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(\"    Update {:d} - Loss = {:.6f}, Accuracy = {:.4}\".format(i_update, loss.item(), accuracy))\n",
    "\n",
    "    student_train_history['avg_losses'][i_epoch]     = losses\n",
    "    student_train_history['avg_accuracies'][i_epoch] = accuracies\n",
    "\n",
    "teacher_preds = torch.stack(teacher_preds, dim=1)\n",
    "noisy_labels  = torch.tensor(noisy_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Final Student Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:12:00.036339Z",
     "start_time": "2019-06-25T17:11:59.653922Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/33\n",
      "Average Loss: 1.434910111427307\n",
      "Average Accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "student.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs   = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = student(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PATE Analysis to Measure the Information Leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:24:19.765119Z",
     "start_time": "2019-06-25T17:24:18.189862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon:   1.6973147844840117\n"
     ]
    }
   ],
   "source": [
    "# Noisy Predictions as indices\n",
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds.numpy(), noisy_labels.numpy(), epsilon, moments=18)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:  \", data_dep_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:24:25.579338Z",
     "start_time": "2019-06-25T17:24:24.043261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon:   1.6174774676520607\n"
     ]
    }
   ],
   "source": [
    "# Predictions without Noise as indices\n",
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds.numpy(), np.argmax(np.apply_along_axis(lambda x: np.bincount(x, None, 10), 0, teacher_preds.numpy()), 0), epsilon, moments=18)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:  \", data_dep_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T17:24:29.721387Z",
     "start_time": "2019-06-25T17:24:28.437267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon:   1.5258742466643267\n"
     ]
    }
   ],
   "source": [
    "# True Labels as indices\n",
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds.numpy(), mnist_testset.true_targets[student_labeled_dataset.indices], epsilon, moments=18)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:  \", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
