{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Project:\n",
    "\n",
    "For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:39:17.604671Z",
     "start_time": "2019-06-23T13:39:14.815133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:39:17.766839Z",
     "start_time": "2019-06-23T13:39:17.607113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 60000\n",
      "Test Set Size: 10000\n",
      "\n",
      "Min Data Value: tensor(0, dtype=torch.uint8)\n",
      "Max Data Value: tensor(255, dtype=torch.uint8)\n",
      "\n",
      "Train Label Counts: {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test Label Counts: {0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset  = datasets.MNIST(root='../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset.true_targets = mnist_testset.targets.clone() # data points that are considered \"unlabeled\" will be re-labeled by teachers later\n",
    "\n",
    "print(\"Training Set Size:\", len(mnist_trainset))\n",
    "print(\"Test Set Size:\", len(mnist_testset))\n",
    "print()\n",
    "print(\"Min Data Value:\", torch.min(mnist_trainset.data.min(), mnist_testset.data.min()))\n",
    "print(\"Max Data Value:\", torch.max(mnist_trainset.data.max(), mnist_testset.data.max()))\n",
    "print()\n",
    "print(\"Train Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_trainset.targets, return_counts=True))})\n",
    "print(\"Test Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_testset.targets, return_counts=True))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:39:17.786665Z",
     "start_time": "2019-06-23T13:39:17.769304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each teacher dataset: 240\n",
      "Size of the dataset available to the student: 9000\n",
      "Size of the test dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "n_teachers = 250\n",
    "\n",
    "_teacher_dataset_len = len(mnist_trainset) // n_teachers\n",
    "\n",
    "teacher_datasets = [data.Subset(mnist_trainset, list(range(i*_teacher_dataset_len, (i+1)*_teacher_dataset_len))) for i in range(n_teachers)]\n",
    "student_dataset  = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9))))\n",
    "test_dataset     = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9), len(mnist_testset))))\n",
    "\n",
    "print(\"Size of each teacher dataset:\", _teacher_dataset_len)\n",
    "print(\"Size of the dataset available to the student:\", len(student_dataset))\n",
    "print(\"Size of the test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:39:18.777269Z",
     "start_time": "2019-06-23T13:39:18.766853Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        # 1x28x28\n",
    "        self.bn0        = nn.BatchNorm2d(1)\n",
    "        self.conv0      = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.bn1        = nn.BatchNorm2d(5)\n",
    "        self.maxpool0   = nn.MaxPool2d(2)\n",
    "        # 5x14x14\n",
    "        self.conv1      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn2        = nn.BatchNorm2d(5)\n",
    "        self.maxpool1   = nn.MaxPool2d(2)\n",
    "        # 5x 7x 7\n",
    "        self.conv2      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn3        = nn.BatchNorm2d(5)\n",
    "        self.maxpool2   = nn.MaxPool2d(2, padding=1)\n",
    "        # 5x 4x 4 = 80\n",
    "        self.fc         = nn.Linear(80, 10)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(self.bn0(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.fc(x.view(-1, 80))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Teacher & DF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:39:22.958639Z",
     "start_time": "2019-06-23T13:39:19.559551Z"
    }
   },
   "outputs": [],
   "source": [
    "teachers      = [MNISTClassifier().to(device) for _ in range(n_teachers)]\n",
    "student       = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Teachers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:45:41.215686Z",
     "start_time": "2019-06-23T13:39:24.083877Z"
    },
    "code_folding": [
     12
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9             \n",
      "    Avg Losses: [2.21073, 2.23918, 2.28086, 2.15874, 2.23866, 2.31621, 2.30713, 2.18633, 2.17418, 2.16536, 2.21159, 2.13759, 2.29504, 2.13437, 2.26481, 2.26822, 2.36746, 1.982, 2.2323, 2.13046, 2.18558, 2.3023, 2.18393, 2.23326, 2.22305, 2.19732, 2.31659, 2.25757, 2.18945, 2.30273, 2.24863, 2.29796, 2.19766, 2.19736, 2.23516, 2.10273, 2.25671, 2.16018, 2.15332, 2.15617, 2.16629, 2.16903, 2.29986, 2.15375, 2.35322, 2.26402, 2.16145, 2.11861, 1.9837, 2.22307, 2.18739, 2.1666, 2.20664, 2.20077, 2.16129, 2.13993, 2.22303, 2.21677, 2.25294, 2.318, 2.30551, 2.1139, 2.02318, 2.24366, 2.12847, 2.18998, 2.38609, 2.24913, 2.11516, 2.1852, 2.28901, 2.16478, 2.27972, 2.20896, 2.18185, 2.15838, 2.26615, 2.29928, 1.90267, 2.15768, 2.23865, 2.09571, 2.17137, 2.01474, 2.18474, 2.08203, 2.26916, 2.14139, 2.13376, 2.00431, 2.27429, 2.25236, 2.2412, 2.15806, 2.06265, 2.15356, 2.22228, 2.06031, 2.17198, 2.18582, 2.32406, 2.3228, 2.16512, 2.31682, 2.1459, 2.20135, 2.27286, 2.17005, 2.24154, 2.33784, 2.09488, 2.32376, 2.29292, 2.13337, 2.168, 2.31548, 2.10926, 2.1934, 2.36461, 2.26305, 2.09429, 2.28596, 2.17563, 2.25983, 2.3113, 2.20922, 2.22492, 2.2454, 2.21729, 2.0837, 2.29063, 2.25299, 2.18992, 2.16562, 2.30043, 2.34616, 2.26113, 2.27231, 2.16817, 2.31263, 2.33401, 2.21849, 2.1174, 2.11123, 2.20396, 2.25619, 2.01475, 2.05484, 2.22974, 2.09647, 2.29722, 2.36117, 2.28311, 2.20881, 2.26532, 2.33023, 2.186, 2.31897, 2.23161, 2.18338, 2.10811, 2.29595, 2.16346, 2.25251, 2.2622, 2.17528, 2.3172, 2.13499, 2.23191, 2.23288, 1.9902, 2.2193, 2.10468, 2.25035, 2.24638, 2.11847, 2.11505, 2.22427, 2.30591, 2.21544, 2.17284, 2.21771, 2.1784, 2.30839, 2.2152, 2.10152, 2.18159, 2.31007, 2.21134, 2.10331, 2.26013, 2.27187, 2.08699, 2.29745, 2.22577, 2.25388, 2.13596, 2.23598, 2.11999, 2.24028, 2.13461, 2.11814, 2.13933, 2.21759, 2.20369, 2.33002, 2.3528, 2.17646, 2.17335, 2.25637, 2.02236, 2.22642, 2.36992, 2.27582, 2.25047, 2.25065, 2.27415, 2.32967, 2.21808, 2.24284, 2.14604, 2.29484, 2.23476, 2.2296, 2.0718, 2.20586, 2.07811, 2.17823, 2.17631, 2.17855, 2.09659, 2.25036, 2.19659, 2.28594, 2.27595, 2.23097, 2.03611, 2.11549, 2.17534, 2.2058, 2.12737, 2.22151, 2.07211, 2.28076, 1.97502, 2.21552, 1.90485, 2.16851, 2.28436, 2.01619]\n",
      "    Avg Accuracies: [0.1917, 0.2208, 0.1833, 0.2458, 0.2542, 0.1583, 0.1917, 0.3167, 0.2333, 0.2083, 0.2292, 0.3167, 0.1458, 0.275, 0.2292, 0.1792, 0.1292, 0.3625, 0.1833, 0.2208, 0.2125, 0.2083, 0.1875, 0.1917, 0.25, 0.2667, 0.1708, 0.1833, 0.2333, 0.1583, 0.1958, 0.2208, 0.2875, 0.2208, 0.1875, 0.2625, 0.2042, 0.2292, 0.275, 0.2333, 0.2625, 0.2458, 0.1333, 0.275, 0.1583, 0.1958, 0.3167, 0.2583, 0.3708, 0.2583, 0.2042, 0.2292, 0.2042, 0.2583, 0.2417, 0.225, 0.1958, 0.2292, 0.1667, 0.1542, 0.1708, 0.3042, 0.3333, 0.25, 0.2667, 0.2167, 0.125, 0.2, 0.2458, 0.2708, 0.1375, 0.2125, 0.1417, 0.2292, 0.225, 0.2333, 0.2542, 0.1792, 0.35, 0.2458, 0.2542, 0.3292, 0.2417, 0.2792, 0.2208, 0.3, 0.1333, 0.2417, 0.2417, 0.3125, 0.1375, 0.2375, 0.225, 0.2417, 0.2708, 0.2708, 0.2833, 0.3708, 0.2417, 0.2125, 0.1458, 0.1458, 0.2333, 0.1833, 0.3333, 0.2292, 0.1917, 0.2875, 0.2333, 0.2208, 0.2333, 0.1667, 0.2375, 0.2167, 0.2542, 0.1458, 0.3542, 0.2083, 0.1333, 0.2292, 0.275, 0.1208, 0.2125, 0.2083, 0.2125, 0.2708, 0.1792, 0.1958, 0.2292, 0.275, 0.1292, 0.2167, 0.2083, 0.2042, 0.1875, 0.1292, 0.2042, 0.1708, 0.2458, 0.2167, 0.2042, 0.2333, 0.2708, 0.2667, 0.2, 0.1708, 0.2542, 0.3083, 0.1958, 0.2875, 0.1833, 0.1458, 0.1667, 0.2458, 0.1875, 0.1208, 0.1958, 0.175, 0.1958, 0.1917, 0.3042, 0.2083, 0.2417, 0.2292, 0.2292, 0.2792, 0.1208, 0.2458, 0.2, 0.225, 0.2542, 0.1625, 0.2875, 0.2292, 0.2167, 0.2792, 0.2458, 0.1917, 0.1833, 0.2042, 0.25, 0.2333, 0.2042, 0.1625, 0.2333, 0.2583, 0.2333, 0.1292, 0.2333, 0.3, 0.2208, 0.2458, 0.2958, 0.2792, 0.2083, 0.1792, 0.2417, 0.1917, 0.275, 0.2, 0.275, 0.2583, 0.2083, 0.2083, 0.2375, 0.2167, 0.1708, 0.25, 0.2542, 0.2083, 0.325, 0.2458, 0.1542, 0.1708, 0.2792, 0.1583, 0.1958, 0.1583, 0.1792, 0.2208, 0.2833, 0.2333, 0.1583, 0.2083, 0.3125, 0.1625, 0.2625, 0.2792, 0.1625, 0.2625, 0.3, 0.1958, 0.2417, 0.2333, 0.1792, 0.2667, 0.2917, 0.2833, 0.2208, 0.1625, 0.275, 0.1875, 0.2833, 0.1375, 0.3833, 0.2375, 0.375, 0.2083, 0.2125, 0.4208]\n",
      "\n",
      "Epoch 1/9             \n",
      "    Avg Losses: [1.42381, 1.39537, 1.74487, 1.53985, 1.55253, 1.90142, 1.62009, 1.4135, 1.30981, 1.38843, 1.39188, 1.24705, 1.86741, 1.33969, 1.33815, 1.3306, 1.84276, 0.95245, 1.50066, 1.12283, 1.53449, 1.89858, 1.44705, 1.65217, 1.69226, 1.1997, 1.83251, 1.62285, 1.36112, 1.75379, 1.60444, 1.61523, 1.31669, 1.62977, 1.77638, 1.47222, 1.79817, 1.33695, 1.43391, 1.46353, 1.23988, 1.35297, 1.95186, 1.29823, 1.95154, 1.67819, 1.28619, 1.34109, 1.00773, 1.47126, 1.53107, 1.47704, 1.4076, 1.44465, 1.53864, 1.19278, 1.57052, 1.58738, 1.74866, 1.90252, 1.76197, 1.24593, 0.9745, 1.6813, 1.32292, 1.42093, 1.98005, 1.57496, 1.40484, 1.46477, 1.99371, 1.40583, 1.98369, 1.61364, 1.48053, 1.37721, 1.69897, 1.82911, 0.89683, 1.29328, 1.677, 1.21664, 1.66508, 1.06224, 1.48296, 1.14285, 1.77176, 1.5192, 1.2997, 0.97415, 1.58493, 1.57689, 1.5984, 1.42763, 1.31415, 1.30406, 1.28475, 1.02804, 1.39818, 1.60773, 2.01164, 1.98581, 1.45242, 1.91757, 1.1857, 1.58552, 1.68537, 1.42052, 1.60991, 1.68559, 1.38486, 1.90846, 1.51598, 1.37456, 1.53038, 1.73341, 1.20852, 1.49144, 2.04071, 1.58566, 1.33482, 1.86689, 1.42537, 1.6486, 1.61695, 1.55603, 1.67668, 1.76015, 1.44691, 1.31895, 1.7989, 1.76222, 1.55916, 1.43701, 1.8509, 2.10753, 1.44544, 1.75486, 1.3932, 1.51323, 1.61157, 1.45711, 1.19002, 1.31292, 1.51953, 1.72311, 1.14192, 1.23265, 1.65739, 1.17559, 1.53354, 1.79744, 1.68659, 1.6411, 1.76463, 1.91536, 1.58411, 1.71895, 1.64447, 1.37587, 1.43552, 1.55067, 1.30771, 1.43608, 1.48642, 1.50677, 1.78682, 1.30656, 1.59476, 1.4626, 0.94181, 1.57376, 1.39517, 1.44049, 1.55957, 1.43553, 1.14401, 1.64256, 1.89102, 1.6014, 1.41941, 1.42416, 1.29406, 1.71719, 1.59306, 1.30824, 1.39046, 1.98514, 1.37188, 1.38513, 1.60011, 1.69304, 1.27429, 1.70502, 1.72458, 1.61647, 1.40712, 1.64285, 1.29312, 1.69142, 1.45707, 1.25022, 1.36998, 1.65383, 1.41502, 1.89952, 1.86783, 1.38564, 1.43751, 1.57334, 1.26326, 1.64884, 2.19366, 1.84127, 1.47181, 1.47616, 1.49856, 1.9591, 1.60749, 1.52544, 1.44046, 1.75859, 1.48846, 1.5461, 1.33984, 1.42182, 1.01291, 1.31295, 1.54863, 1.51149, 1.26342, 1.4558, 1.53571, 1.69842, 1.81812, 1.30321, 1.19927, 1.47293, 1.43928, 1.66977, 1.34175, 1.52437, 1.02248, 1.69081, 0.92745, 1.42398, 0.70244, 1.35278, 1.61002, 0.88342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.5667, 0.6292, 0.4625, 0.6042, 0.5083, 0.3833, 0.4833, 0.5375, 0.6708, 0.6333, 0.5708, 0.6292, 0.4917, 0.6375, 0.7042, 0.6333, 0.4708, 0.7708, 0.5583, 0.7542, 0.5, 0.3833, 0.5417, 0.4417, 0.5, 0.7458, 0.375, 0.4208, 0.6583, 0.4542, 0.5583, 0.5, 0.6792, 0.4875, 0.3792, 0.5375, 0.4833, 0.6292, 0.6083, 0.5458, 0.6792, 0.625, 0.4042, 0.6292, 0.3167, 0.5583, 0.6125, 0.6125, 0.7375, 0.6125, 0.5417, 0.5417, 0.6542, 0.6, 0.5792, 0.7667, 0.5417, 0.5042, 0.4083, 0.4125, 0.4583, 0.6458, 0.7042, 0.5125, 0.6083, 0.525, 0.3542, 0.6208, 0.5292, 0.5875, 0.325, 0.6375, 0.2875, 0.4833, 0.5458, 0.6083, 0.5917, 0.4, 0.7417, 0.6958, 0.4833, 0.6792, 0.475, 0.6792, 0.5875, 0.6917, 0.475, 0.5542, 0.6167, 0.7833, 0.6125, 0.5208, 0.5583, 0.5708, 0.6333, 0.6792, 0.6292, 0.725, 0.5958, 0.5208, 0.3375, 0.3875, 0.5833, 0.3958, 0.7, 0.5167, 0.5042, 0.5625, 0.5042, 0.5583, 0.5875, 0.4042, 0.5667, 0.6, 0.575, 0.4917, 0.7375, 0.525, 0.325, 0.5333, 0.6167, 0.4708, 0.5625, 0.4833, 0.5542, 0.525, 0.5208, 0.4667, 0.6167, 0.6208, 0.475, 0.4292, 0.4792, 0.5667, 0.4208, 0.2667, 0.575, 0.3958, 0.6875, 0.5542, 0.6542, 0.5375, 0.7042, 0.6042, 0.5792, 0.5375, 0.7167, 0.6292, 0.4292, 0.6792, 0.5, 0.5333, 0.4708, 0.475, 0.4167, 0.4167, 0.5583, 0.475, 0.5, 0.5875, 0.5375, 0.5708, 0.6458, 0.6583, 0.5458, 0.5292, 0.3667, 0.6, 0.5208, 0.5667, 0.775, 0.5333, 0.6333, 0.5667, 0.525, 0.5458, 0.6917, 0.5125, 0.4083, 0.4667, 0.6, 0.6042, 0.6875, 0.4542, 0.4792, 0.6625, 0.6375, 0.4083, 0.6, 0.5583, 0.6, 0.5292, 0.6208, 0.425, 0.4708, 0.575, 0.5875, 0.5625, 0.6083, 0.4833, 0.5417, 0.6833, 0.5875, 0.4667, 0.5958, 0.3625, 0.4542, 0.6458, 0.6208, 0.5375, 0.625, 0.5292, 0.1833, 0.3708, 0.5375, 0.6292, 0.575, 0.3708, 0.525, 0.5958, 0.5958, 0.4583, 0.6458, 0.5167, 0.5583, 0.6542, 0.7875, 0.6083, 0.5417, 0.5375, 0.725, 0.6375, 0.5667, 0.4792, 0.4042, 0.7167, 0.6167, 0.5292, 0.6667, 0.4875, 0.625, 0.6167, 0.7542, 0.5625, 0.75, 0.5625, 0.8708, 0.6833, 0.6, 0.7958]\n",
      "\n",
      "Epoch 2/9             \n",
      "    Avg Losses: [0.66599, 0.68, 1.12474, 0.94034, 0.87837, 1.19405, 0.95927, 0.68644, 0.60857, 0.6313, 0.68368, 0.53514, 1.05277, 0.73045, 0.72797, 0.57532, 1.11161, 0.43986, 0.73435, 0.50105, 0.86579, 1.18369, 0.89181, 1.06135, 0.99738, 0.48809, 1.09057, 0.80912, 0.67014, 1.06789, 0.84192, 0.8452, 0.69559, 0.92112, 1.10743, 0.88722, 1.10064, 0.68435, 0.69713, 0.90724, 0.49809, 0.58526, 1.35001, 0.60153, 1.20756, 0.94735, 0.5831, 0.64751, 0.5806, 0.64268, 0.79085, 0.83259, 0.62535, 0.74643, 0.95486, 0.4387, 0.94367, 1.00357, 1.14919, 1.29178, 1.03752, 0.66397, 0.59021, 0.9811, 0.64928, 0.82397, 1.34643, 0.76407, 0.68749, 0.77847, 1.34026, 0.59694, 1.39065, 1.05931, 0.77265, 0.65953, 0.75683, 1.25792, 0.40736, 0.59923, 0.98679, 0.60373, 1.02912, 0.47348, 0.8163, 0.53822, 1.03332, 0.85762, 0.62372, 0.41193, 0.71429, 0.65646, 0.87922, 0.81352, 0.80651, 0.58685, 0.68456, 0.42698, 0.66215, 0.91345, 1.41813, 1.51601, 0.76186, 1.18984, 0.53504, 0.8023, 0.91004, 0.75111, 0.81586, 1.02382, 0.81306, 1.21674, 0.87108, 0.76017, 0.87342, 0.94199, 0.61365, 0.91401, 1.51914, 0.84702, 0.79193, 1.06661, 0.72766, 0.91778, 0.84166, 0.94358, 1.04837, 1.04955, 0.75506, 0.80042, 1.08596, 1.11449, 0.8611, 0.77262, 1.31092, 1.6177, 0.74286, 1.07584, 0.60249, 0.75645, 0.76992, 0.86336, 0.53998, 0.7142, 0.8105, 0.98294, 0.62944, 0.5848, 0.96158, 0.53288, 0.84607, 1.105, 0.96856, 1.00391, 1.03573, 1.09328, 0.90556, 1.1071, 0.98892, 0.73693, 0.83677, 0.85334, 0.58472, 0.71735, 0.85879, 0.80836, 1.18639, 0.67979, 0.87918, 0.79398, 0.49305, 0.77364, 0.8869, 0.64375, 0.78308, 0.77796, 0.60326, 0.97946, 1.2149, 0.87099, 0.7001, 0.70706, 0.62539, 0.87781, 0.94258, 0.68555, 0.74049, 1.34597, 0.77008, 0.80915, 0.80504, 0.91615, 0.73554, 1.10003, 0.98002, 0.82342, 0.83352, 1.01544, 0.61114, 0.90205, 0.82121, 0.59938, 0.7985, 1.11072, 0.78088, 1.25657, 1.27262, 0.66867, 0.74174, 0.83759, 0.78769, 0.85224, 1.74937, 1.21045, 0.82449, 0.70356, 0.75905, 1.39963, 0.84399, 0.7188, 0.81278, 1.15215, 0.79036, 0.80981, 0.85224, 0.62689, 0.36006, 0.58909, 0.90114, 0.94261, 0.54388, 0.7067, 0.79103, 0.86456, 1.1887, 0.55697, 0.60989, 0.78352, 0.65399, 0.91318, 0.79228, 0.73644, 0.31869, 0.76447, 0.289, 0.64678, 0.22662, 0.51067, 0.74232, 0.27579]\n",
      "    Avg Accuracies: [0.8333, 0.7833, 0.6458, 0.7375, 0.7417, 0.6292, 0.7583, 0.8333, 0.8542, 0.8292, 0.8, 0.875, 0.7417, 0.8, 0.7833, 0.875, 0.7292, 0.875, 0.8083, 0.8792, 0.7792, 0.6583, 0.7542, 0.65, 0.7208, 0.8833, 0.725, 0.7917, 0.7875, 0.7458, 0.725, 0.8, 0.8042, 0.6875, 0.6792, 0.7417, 0.7042, 0.8125, 0.7958, 0.7625, 0.8583, 0.8167, 0.6083, 0.85, 0.7167, 0.7375, 0.8375, 0.7917, 0.8292, 0.85, 0.7625, 0.775, 0.8417, 0.8042, 0.725, 0.8833, 0.7208, 0.7, 0.6167, 0.5792, 0.6542, 0.8583, 0.8292, 0.7292, 0.8083, 0.775, 0.6292, 0.775, 0.8083, 0.7708, 0.6292, 0.8625, 0.65, 0.6625, 0.7542, 0.8083, 0.8167, 0.6292, 0.8875, 0.8708, 0.7042, 0.8292, 0.7333, 0.8583, 0.7417, 0.8958, 0.6917, 0.7583, 0.8458, 0.9042, 0.8167, 0.8667, 0.7667, 0.7625, 0.7542, 0.8417, 0.8, 0.8625, 0.8167, 0.7417, 0.5917, 0.6083, 0.7917, 0.6208, 0.8583, 0.7833, 0.75, 0.7958, 0.7542, 0.7, 0.7833, 0.6583, 0.75, 0.7833, 0.7417, 0.7917, 0.8292, 0.7542, 0.5792, 0.7917, 0.7583, 0.7292, 0.7958, 0.7375, 0.7583, 0.7375, 0.7292, 0.7083, 0.8125, 0.7417, 0.6917, 0.6708, 0.7417, 0.7875, 0.575, 0.4708, 0.7958, 0.7333, 0.8667, 0.825, 0.8167, 0.7625, 0.85, 0.7833, 0.7917, 0.725, 0.8375, 0.8417, 0.7708, 0.8542, 0.7792, 0.7375, 0.7042, 0.725, 0.7542, 0.7583, 0.7417, 0.7167, 0.6917, 0.7542, 0.7333, 0.7625, 0.8292, 0.8167, 0.7083, 0.7833, 0.6542, 0.7958, 0.7583, 0.8125, 0.8667, 0.8125, 0.75, 0.8542, 0.7958, 0.8083, 0.8292, 0.7375, 0.675, 0.7042, 0.8125, 0.825, 0.8, 0.7625, 0.7208, 0.8292, 0.7875, 0.6458, 0.7583, 0.7708, 0.775, 0.7375, 0.7917, 0.6667, 0.6792, 0.7958, 0.7667, 0.725, 0.825, 0.7625, 0.7792, 0.8167, 0.7667, 0.65, 0.8, 0.6833, 0.625, 0.8125, 0.8042, 0.7792, 0.7417, 0.7333, 0.3667, 0.6083, 0.75, 0.85, 0.8208, 0.5792, 0.7625, 0.85, 0.7833, 0.6833, 0.8333, 0.7625, 0.7458, 0.8042, 0.9125, 0.8208, 0.7083, 0.7458, 0.8625, 0.7958, 0.775, 0.7375, 0.6833, 0.8833, 0.8125, 0.7667, 0.8542, 0.7875, 0.7708, 0.8167, 0.9208, 0.8458, 0.9292, 0.8167, 0.9375, 0.8833, 0.8625, 0.9625]\n",
      "\n",
      "Epoch 3/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.48196, 0.39495, 0.64809, 0.63718, 0.49077, 0.60653, 0.66273, 0.38232, 0.34925, 0.33786, 0.29736, 0.29568, 0.48175, 0.46401, 0.42631, 0.31803, 0.68814, 0.28315, 0.42986, 0.30587, 0.58125, 0.71571, 0.51409, 0.67838, 0.57366, 0.25557, 0.52692, 0.42819, 0.38539, 0.62895, 0.46286, 0.4921, 0.43013, 0.58855, 0.69507, 0.63504, 0.70596, 0.38837, 0.42889, 0.62651, 0.25766, 0.34913, 0.82218, 0.27526, 0.57192, 0.63083, 0.34517, 0.3787, 0.41217, 0.31513, 0.41947, 0.45023, 0.34627, 0.38713, 0.66425, 0.26189, 0.59932, 0.61769, 0.72941, 0.82716, 0.54384, 0.35755, 0.39373, 0.58415, 0.3106, 0.45864, 0.7979, 0.39925, 0.39961, 0.41193, 0.70602, 0.29887, 0.71757, 0.65548, 0.40805, 0.3696, 0.31718, 0.88587, 0.25379, 0.34058, 0.54434, 0.37237, 0.61531, 0.26921, 0.47284, 0.28939, 0.73809, 0.45363, 0.31637, 0.24237, 0.32734, 0.28687, 0.52126, 0.46653, 0.54293, 0.34268, 0.41552, 0.27459, 0.3654, 0.53991, 0.72576, 0.93967, 0.44891, 0.71731, 0.30885, 0.3954, 0.54019, 0.53909, 0.42298, 0.65565, 0.56769, 0.67844, 0.60497, 0.45226, 0.47973, 0.50558, 0.40781, 0.57054, 0.9823, 0.45685, 0.50564, 0.57251, 0.41695, 0.51667, 0.50825, 0.60181, 0.58578, 0.7305, 0.46127, 0.51297, 0.63576, 0.64091, 0.48706, 0.45464, 0.818, 1.12682, 0.50097, 0.56388, 0.30145, 0.39376, 0.44791, 0.42866, 0.31135, 0.42883, 0.48343, 0.59808, 0.40895, 0.32713, 0.50017, 0.23611, 0.52368, 0.57339, 0.60061, 0.65181, 0.62357, 0.50196, 0.48496, 0.61577, 0.59275, 0.52364, 0.48737, 0.50036, 0.3021, 0.45976, 0.51327, 0.50841, 0.70025, 0.37053, 0.45433, 0.42663, 0.33122, 0.44625, 0.61729, 0.41484, 0.41625, 0.47309, 0.3541, 0.60182, 0.68031, 0.60647, 0.39479, 0.3552, 0.36673, 0.4614, 0.62608, 0.50295, 0.51306, 0.75801, 0.38947, 0.55062, 0.44288, 0.49432, 0.43826, 0.69196, 0.52238, 0.41408, 0.53916, 0.70469, 0.35342, 0.47564, 0.50128, 0.38504, 0.50143, 0.81823, 0.41797, 0.73371, 0.74227, 0.45252, 0.42971, 0.46308, 0.58568, 0.48526, 0.94056, 0.79722, 0.42808, 0.35031, 0.3797, 0.83904, 0.48552, 0.44227, 0.55609, 0.71893, 0.40844, 0.42552, 0.57096, 0.27701, 0.17773, 0.3699, 0.4969, 0.5945, 0.28993, 0.43079, 0.50099, 0.45257, 0.71246, 0.36631, 0.35184, 0.49862, 0.32361, 0.46052, 0.49918, 0.37334, 0.13116, 0.25812, 0.10515, 0.28947, 0.07066, 0.23102, 0.33573, 0.12248]\n",
      "    Avg Accuracies: [0.85, 0.8667, 0.8458, 0.7958, 0.8458, 0.8042, 0.825, 0.8958, 0.9, 0.8958, 0.9417, 0.9167, 0.8875, 0.8417, 0.875, 0.925, 0.8042, 0.9083, 0.875, 0.9208, 0.7833, 0.7958, 0.8583, 0.775, 0.8333, 0.9417, 0.85, 0.8625, 0.8792, 0.8042, 0.8458, 0.8167, 0.85, 0.8042, 0.7792, 0.7708, 0.7833, 0.8667, 0.8625, 0.8125, 0.9083, 0.8792, 0.725, 0.9375, 0.8375, 0.8125, 0.875, 0.8542, 0.8875, 0.9125, 0.8708, 0.8708, 0.9, 0.9125, 0.8, 0.9167, 0.825, 0.7917, 0.7583, 0.7333, 0.8, 0.9208, 0.8833, 0.8125, 0.9, 0.8625, 0.7667, 0.8708, 0.8875, 0.8583, 0.8, 0.9, 0.8208, 0.775, 0.8708, 0.8792, 0.9333, 0.75, 0.925, 0.9042, 0.8375, 0.8875, 0.8333, 0.925, 0.8583, 0.9167, 0.7625, 0.8792, 0.9042, 0.9333, 0.9, 0.9, 0.7958, 0.8917, 0.8208, 0.8958, 0.8708, 0.925, 0.8792, 0.825, 0.825, 0.7292, 0.85, 0.7833, 0.9, 0.8917, 0.8292, 0.8458, 0.8583, 0.8458, 0.7917, 0.7708, 0.7875, 0.85, 0.8833, 0.8625, 0.875, 0.8333, 0.7042, 0.8833, 0.825, 0.8083, 0.8833, 0.8542, 0.8458, 0.8, 0.8292, 0.7458, 0.8542, 0.85, 0.8292, 0.8, 0.8167, 0.8708, 0.7583, 0.6583, 0.8417, 0.8667, 0.925, 0.8833, 0.8208, 0.8875, 0.9292, 0.8667, 0.8417, 0.7958, 0.8917, 0.9083, 0.8792, 0.9375, 0.8042, 0.8333, 0.7792, 0.7958, 0.8167, 0.8625, 0.8417, 0.8417, 0.8417, 0.8125, 0.8667, 0.8375, 0.925, 0.8375, 0.8208, 0.8542, 0.7708, 0.8708, 0.8833, 0.8917, 0.9042, 0.8875, 0.8083, 0.8792, 0.85, 0.8583, 0.8917, 0.8, 0.7833, 0.7958, 0.8917, 0.8917, 0.8708, 0.875, 0.7958, 0.8417, 0.825, 0.7833, 0.8792, 0.8292, 0.8792, 0.85, 0.8833, 0.7833, 0.8375, 0.8958, 0.8125, 0.7792, 0.8833, 0.8417, 0.8417, 0.8833, 0.8333, 0.7542, 0.8875, 0.8083, 0.7458, 0.8208, 0.8792, 0.8667, 0.7792, 0.85, 0.7542, 0.7667, 0.8833, 0.8833, 0.9, 0.7292, 0.8667, 0.8792, 0.8208, 0.8, 0.9125, 0.8917, 0.7875, 0.925, 0.9417, 0.875, 0.875, 0.8, 0.9292, 0.8542, 0.85, 0.85, 0.7833, 0.8917, 0.8917, 0.8542, 0.9083, 0.875, 0.8292, 0.8958, 0.9667, 0.9417, 0.9833, 0.9125, 0.9833, 0.9333, 0.9167, 0.9792]\n",
      "\n",
      "Epoch 4/9             \n",
      "    Avg Losses: [0.28891, 0.22555, 0.3559, 0.39205, 0.37431, 0.35275, 0.48511, 0.21426, 0.20961, 0.22675, 0.19763, 0.2125, 0.28091, 0.28781, 0.26523, 0.18045, 0.41467, 0.16987, 0.32037, 0.18861, 0.39436, 0.41576, 0.37297, 0.51465, 0.35067, 0.15036, 0.31396, 0.25741, 0.22803, 0.41936, 0.22509, 0.30999, 0.2781, 0.4521, 0.43524, 0.41927, 0.53501, 0.27912, 0.28236, 0.40846, 0.13843, 0.2014, 0.50212, 0.15856, 0.35133, 0.37036, 0.27215, 0.28247, 0.29078, 0.19666, 0.25415, 0.26818, 0.22572, 0.24095, 0.44897, 0.1706, 0.40138, 0.41233, 0.39791, 0.56953, 0.32189, 0.34489, 0.28947, 0.42231, 0.19222, 0.27286, 0.50155, 0.28283, 0.2123, 0.31109, 0.50026, 0.18521, 0.36325, 0.44203, 0.24668, 0.24076, 0.21205, 0.63301, 0.15116, 0.19759, 0.32279, 0.22464, 0.4399, 0.22262, 0.37989, 0.16058, 0.51012, 0.3606, 0.1845, 0.11659, 0.14364, 0.28149, 0.35765, 0.28448, 0.45711, 0.17376, 0.31657, 0.15993, 0.28201, 0.36495, 0.42985, 0.52217, 0.32008, 0.48602, 0.17758, 0.26284, 0.39039, 0.41634, 0.25962, 0.42664, 0.3671, 0.47567, 0.29817, 0.29895, 0.39614, 0.28799, 0.28318, 0.37699, 0.69169, 0.27331, 0.32267, 0.37107, 0.26674, 0.31559, 0.33103, 0.38293, 0.33134, 0.39419, 0.25239, 0.41048, 0.44502, 0.40158, 0.33931, 0.29996, 0.46534, 0.67173, 0.29514, 0.32455, 0.14047, 0.22306, 0.32852, 0.29049, 0.20378, 0.28117, 0.27963, 0.42489, 0.23599, 0.19227, 0.29525, 0.14941, 0.38838, 0.34504, 0.49706, 0.44597, 0.34686, 0.27158, 0.27715, 0.40581, 0.40901, 0.39445, 0.29299, 0.36259, 0.19459, 0.40968, 0.34214, 0.35567, 0.39995, 0.19855, 0.28549, 0.27163, 0.17832, 0.26995, 0.44641, 0.23026, 0.20783, 0.2799, 0.22709, 0.41039, 0.37302, 0.45191, 0.26457, 0.24938, 0.20663, 0.26095, 0.36947, 0.36359, 0.34524, 0.43218, 0.21164, 0.46288, 0.34954, 0.27777, 0.3618, 0.52711, 0.38742, 0.24886, 0.39912, 0.39963, 0.23724, 0.31508, 0.2684, 0.32909, 0.35508, 0.63776, 0.27884, 0.49175, 0.45297, 0.29253, 0.31188, 0.2981, 0.4531, 0.25048, 0.49075, 0.58698, 0.2364, 0.16753, 0.27775, 0.62616, 0.32195, 0.26165, 0.51905, 0.49771, 0.23781, 0.25961, 0.40497, 0.16743, 0.06296, 0.2803, 0.33499, 0.37259, 0.25426, 0.31233, 0.38671, 0.35384, 0.50924, 0.24215, 0.19551, 0.31726, 0.23083, 0.28225, 0.33196, 0.20754, 0.13915, 0.11998, 0.04575, 0.13365, 0.03929, 0.09566, 0.2536, 0.0965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9042, 0.9375, 0.8875, 0.8958, 0.8875, 0.8625, 0.8292, 0.9583, 0.9292, 0.9125, 0.9542, 0.9292, 0.925, 0.9, 0.9042, 0.9417, 0.8833, 0.9417, 0.9042, 0.95, 0.875, 0.8583, 0.8958, 0.8375, 0.8958, 0.9542, 0.8958, 0.9167, 0.9167, 0.8833, 0.9375, 0.9, 0.9125, 0.8208, 0.8625, 0.8792, 0.8042, 0.9, 0.9083, 0.8708, 0.9625, 0.9333, 0.8208, 0.9458, 0.8792, 0.9042, 0.8958, 0.875, 0.9042, 0.95, 0.9083, 0.9292, 0.9458, 0.9375, 0.8417, 0.9458, 0.875, 0.8542, 0.875, 0.8125, 0.875, 0.8667, 0.9, 0.8625, 0.95, 0.9167, 0.8292, 0.8875, 0.9208, 0.9083, 0.8333, 0.9292, 0.8833, 0.8708, 0.9208, 0.9333, 0.925, 0.8083, 0.9625, 0.95, 0.875, 0.9375, 0.8708, 0.9333, 0.9125, 0.9583, 0.8417, 0.8958, 0.9542, 0.9667, 0.9625, 0.8917, 0.8875, 0.925, 0.875, 0.9458, 0.9042, 0.9458, 0.8875, 0.8833, 0.8542, 0.8208, 0.9125, 0.8625, 0.9542, 0.9292, 0.8875, 0.8792, 0.9042, 0.8917, 0.8667, 0.8375, 0.9375, 0.9042, 0.8542, 0.9125, 0.9125, 0.9, 0.7917, 0.9167, 0.8917, 0.8667, 0.9042, 0.9167, 0.8875, 0.8833, 0.8917, 0.8917, 0.9208, 0.8833, 0.8708, 0.8542, 0.85, 0.9042, 0.825, 0.8042, 0.9375, 0.9333, 0.9667, 0.9292, 0.8792, 0.9208, 0.9458, 0.9083, 0.8833, 0.8667, 0.9417, 0.9417, 0.9, 0.9542, 0.8792, 0.8875, 0.85, 0.8542, 0.8958, 0.9208, 0.9167, 0.8708, 0.8542, 0.8625, 0.9125, 0.8792, 0.9458, 0.875, 0.8875, 0.8792, 0.8833, 0.9375, 0.9167, 0.9167, 0.9458, 0.8958, 0.8625, 0.9417, 0.9625, 0.9125, 0.9542, 0.8708, 0.8458, 0.8375, 0.9333, 0.9, 0.9208, 0.9292, 0.9042, 0.8708, 0.8833, 0.8583, 0.9417, 0.8625, 0.8833, 0.9208, 0.8875, 0.8333, 0.8625, 0.9292, 0.8542, 0.8708, 0.9167, 0.8958, 0.9292, 0.8958, 0.8917, 0.7875, 0.925, 0.8292, 0.8667, 0.9083, 0.9333, 0.9042, 0.8792, 0.925, 0.8667, 0.7917, 0.9458, 0.9542, 0.9083, 0.7833, 0.9125, 0.9292, 0.85, 0.8708, 0.9333, 0.9083, 0.8708, 0.9583, 0.9833, 0.9125, 0.9042, 0.8583, 0.9167, 0.9042, 0.8875, 0.8875, 0.8333, 0.9333, 0.9375, 0.8958, 0.9333, 0.9167, 0.9083, 0.9375, 0.9667, 0.9708, 0.9917, 0.9708, 0.9917, 0.9792, 0.9208, 0.9792]\n",
      "\n",
      "Epoch 5/9             \n",
      "    Avg Losses: [0.16412, 0.11239, 0.19013, 0.28325, 0.27105, 0.20363, 0.30046, 0.17488, 0.10403, 0.16652, 0.15891, 0.14053, 0.13259, 0.16479, 0.15708, 0.13441, 0.28862, 0.08136, 0.20084, 0.1439, 0.23833, 0.29733, 0.22705, 0.34782, 0.19949, 0.08441, 0.18473, 0.18505, 0.14938, 0.28203, 0.18728, 0.25392, 0.17235, 0.30473, 0.30131, 0.35084, 0.38434, 0.20641, 0.20945, 0.26157, 0.08601, 0.13559, 0.32763, 0.1068, 0.23235, 0.19494, 0.19722, 0.30252, 0.22601, 0.11361, 0.1161, 0.17755, 0.10504, 0.21733, 0.27971, 0.20105, 0.27286, 0.28203, 0.27646, 0.40654, 0.21544, 0.16365, 0.20697, 0.30489, 0.14909, 0.15456, 0.32931, 0.13681, 0.14417, 0.25785, 0.43813, 0.14958, 0.21068, 0.27681, 0.17352, 0.13406, 0.13238, 0.39186, 0.1121, 0.12407, 0.21507, 0.12431, 0.25223, 0.19477, 0.2732, 0.10154, 0.32295, 0.2849, 0.12288, 0.08924, 0.11191, 0.14064, 0.22584, 0.24145, 0.32359, 0.09037, 0.18131, 0.13499, 0.15849, 0.20723, 0.24406, 0.34501, 0.31216, 0.35453, 0.10929, 0.15397, 0.24203, 0.26822, 0.178, 0.28859, 0.29093, 0.27758, 0.23424, 0.19514, 0.22631, 0.14069, 0.25468, 0.25712, 0.53964, 0.26217, 0.15554, 0.3047, 0.27111, 0.2378, 0.29425, 0.28465, 0.19269, 0.21068, 0.26748, 0.35665, 0.34253, 0.26069, 0.18465, 0.1699, 0.21951, 0.39214, 0.20234, 0.25376, 0.08123, 0.12708, 0.2461, 0.13121, 0.1867, 0.22287, 0.23677, 0.2947, 0.21679, 0.09353, 0.22586, 0.08382, 0.23549, 0.20162, 0.27007, 0.31747, 0.25873, 0.16417, 0.21701, 0.28042, 0.31053, 0.17731, 0.16344, 0.29301, 0.10069, 0.32916, 0.19927, 0.24159, 0.2826, 0.14555, 0.22054, 0.23785, 0.15649, 0.18352, 0.29607, 0.21047, 0.11096, 0.15599, 0.18266, 0.28777, 0.20878, 0.23957, 0.2012, 0.14115, 0.15798, 0.12821, 0.21549, 0.26567, 0.2519, 0.26321, 0.1273, 0.30482, 0.2997, 0.15328, 0.22622, 0.31453, 0.2081, 0.16017, 0.29679, 0.28014, 0.12021, 0.21463, 0.19036, 0.1916, 0.25342, 0.44778, 0.16983, 0.28907, 0.31367, 0.19306, 0.16162, 0.16611, 0.28249, 0.16611, 0.31193, 0.44053, 0.1622, 0.08517, 0.22002, 0.53205, 0.18343, 0.17292, 0.35897, 0.37807, 0.12379, 0.18304, 0.26809, 0.08159, 0.03747, 0.17643, 0.19806, 0.19109, 0.16654, 0.15146, 0.29257, 0.25246, 0.33863, 0.23296, 0.0965, 0.18713, 0.1772, 0.18325, 0.21985, 0.12177, 0.12993, 0.07065, 0.01711, 0.07351, 0.01577, 0.0569, 0.12047, 0.06009]\n",
      "    Avg Accuracies: [0.95, 0.975, 0.9458, 0.9, 0.9, 0.9417, 0.8958, 0.9583, 0.975, 0.9417, 0.9625, 0.9583, 0.9667, 0.9458, 0.9708, 0.9583, 0.9083, 0.9833, 0.9625, 0.9542, 0.9333, 0.9083, 0.925, 0.9, 0.9417, 0.9875, 0.9458, 0.95, 0.9542, 0.9167, 0.95, 0.9083, 0.9542, 0.8917, 0.9, 0.8708, 0.8875, 0.9208, 0.9375, 0.9, 0.9792, 0.9625, 0.8875, 0.9667, 0.9292, 0.9542, 0.925, 0.8917, 0.9292, 0.975, 0.975, 0.9333, 0.9833, 0.9333, 0.9167, 0.9292, 0.9167, 0.9125, 0.9375, 0.85, 0.9333, 0.9625, 0.9417, 0.9083, 0.9542, 0.9667, 0.9083, 0.9583, 0.9542, 0.9042, 0.8458, 0.9458, 0.9458, 0.9208, 0.9458, 0.95, 0.95, 0.875, 0.975, 0.9708, 0.9208, 0.9792, 0.9292, 0.9375, 0.9042, 0.9792, 0.8875, 0.9167, 0.9625, 0.975, 0.9625, 0.9542, 0.9375, 0.9458, 0.8833, 0.9833, 0.9583, 0.9417, 0.9417, 0.9417, 0.9125, 0.9042, 0.8792, 0.8833, 0.975, 0.9458, 0.9333, 0.925, 0.9542, 0.925, 0.9208, 0.8792, 0.9167, 0.9542, 0.925, 0.9667, 0.9333, 0.9208, 0.8375, 0.9042, 0.9583, 0.9083, 0.9125, 0.9458, 0.9042, 0.9292, 0.9458, 0.9375, 0.875, 0.8625, 0.8958, 0.925, 0.925, 0.95, 0.95, 0.8792, 0.95, 0.9333, 0.9833, 0.9542, 0.925, 0.9583, 0.9542, 0.9375, 0.9333, 0.8917, 0.9208, 0.9708, 0.925, 0.9833, 0.9292, 0.9417, 0.925, 0.8917, 0.9333, 0.9542, 0.925, 0.9167, 0.8875, 0.9583, 0.95, 0.9125, 0.9667, 0.8708, 0.9458, 0.9292, 0.9083, 0.9583, 0.9417, 0.9125, 0.95, 0.9583, 0.9083, 0.9333, 0.975, 0.9333, 0.9542, 0.9083, 0.9458, 0.9208, 0.9208, 0.9583, 0.95, 0.9667, 0.9417, 0.8875, 0.925, 0.9083, 0.9625, 0.9167, 0.9292, 0.9625, 0.9292, 0.9208, 0.925, 0.9542, 0.8875, 0.9125, 0.9667, 0.9333, 0.9417, 0.9458, 0.9208, 0.8542, 0.9417, 0.9083, 0.8917, 0.95, 0.9667, 0.95, 0.925, 0.9375, 0.8958, 0.8583, 0.9625, 0.9792, 0.9375, 0.8667, 0.9417, 0.9542, 0.875, 0.875, 0.9583, 0.9417, 0.9125, 0.9875, 0.9958, 0.9625, 0.9417, 0.9458, 0.9458, 0.9542, 0.8958, 0.9125, 0.8875, 0.9125, 0.9833, 0.9333, 0.9542, 0.9542, 0.9458, 0.9625, 0.9458, 0.9792, 1.0, 0.9875, 1.0, 0.9917, 0.9583, 0.9875]\n",
      "\n",
      "Epoch 6/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.1074, 0.06861, 0.12346, 0.17381, 0.19751, 0.15397, 0.19522, 0.08123, 0.07793, 0.10249, 0.11256, 0.08273, 0.13709, 0.10065, 0.08645, 0.10457, 0.20085, 0.06274, 0.15415, 0.13035, 0.16211, 0.20123, 0.1143, 0.30885, 0.13082, 0.04043, 0.15364, 0.1132, 0.0955, 0.20392, 0.11453, 0.16834, 0.11068, 0.25404, 0.19169, 0.2573, 0.2746, 0.12853, 0.13266, 0.16418, 0.04659, 0.07401, 0.23937, 0.064, 0.17943, 0.1117, 0.10853, 0.21967, 0.18882, 0.08947, 0.07911, 0.09582, 0.07128, 0.20902, 0.20377, 0.08675, 0.17988, 0.27651, 0.25849, 0.23588, 0.14984, 0.1217, 0.17776, 0.23356, 0.09189, 0.12041, 0.26665, 0.10467, 0.09447, 0.23183, 0.27607, 0.12257, 0.24177, 0.17097, 0.19736, 0.14328, 0.09079, 0.30686, 0.05962, 0.06421, 0.12345, 0.05246, 0.1385, 0.14288, 0.16574, 0.04048, 0.24354, 0.27874, 0.07252, 0.08183, 0.06819, 0.08057, 0.16821, 0.20314, 0.23753, 0.04492, 0.08764, 0.07426, 0.07873, 0.15216, 0.15277, 0.24914, 0.12397, 0.26457, 0.04785, 0.11176, 0.18045, 0.19225, 0.11157, 0.19625, 0.20463, 0.20355, 0.1177, 0.12817, 0.12556, 0.08764, 0.15913, 0.17252, 0.38469, 0.12852, 0.08187, 0.14952, 0.16542, 0.15974, 0.18997, 0.20741, 0.11951, 0.11643, 0.14983, 0.20232, 0.1979, 0.1641, 0.10662, 0.08054, 0.16169, 0.28767, 0.12013, 0.14832, 0.06094, 0.06975, 0.15442, 0.08261, 0.16513, 0.14271, 0.18587, 0.27068, 0.12267, 0.06244, 0.15166, 0.05841, 0.15493, 0.13757, 0.25459, 0.21647, 0.15643, 0.11098, 0.13553, 0.22731, 0.16102, 0.15543, 0.11729, 0.2058, 0.07651, 0.25666, 0.17625, 0.1588, 0.18224, 0.15081, 0.15641, 0.16194, 0.08463, 0.14162, 0.25208, 0.10878, 0.09365, 0.12305, 0.13023, 0.23146, 0.13409, 0.15505, 0.15865, 0.15615, 0.09161, 0.11882, 0.13409, 0.19404, 0.24064, 0.21007, 0.10701, 0.21974, 0.1827, 0.10299, 0.12469, 0.21638, 0.13024, 0.11848, 0.16576, 0.18613, 0.16786, 0.18281, 0.13389, 0.10677, 0.19518, 0.36855, 0.09146, 0.21421, 0.23371, 0.11791, 0.09749, 0.0917, 0.18684, 0.09855, 0.24883, 0.33378, 0.09323, 0.0619, 0.1411, 0.43674, 0.131, 0.10726, 0.25302, 0.2475, 0.08158, 0.10625, 0.24293, 0.06518, 0.025, 0.19171, 0.16391, 0.14776, 0.11814, 0.07114, 0.16079, 0.17058, 0.23581, 0.14126, 0.08129, 0.12732, 0.11255, 0.121, 0.13751, 0.09883, 0.06891, 0.03144, 0.00923, 0.04478, 0.01696, 0.02835, 0.07226, 0.03629]\n",
      "    Avg Accuracies: [0.975, 0.9833, 0.95, 0.9542, 0.9458, 0.9583, 0.9542, 0.9792, 0.9833, 0.9708, 0.975, 0.975, 0.9583, 0.9792, 0.9833, 0.9583, 0.9542, 0.9792, 0.9542, 0.9583, 0.9625, 0.95, 0.9708, 0.9083, 0.9542, 0.9958, 0.9458, 0.9667, 0.9792, 0.925, 0.9792, 0.9458, 0.9792, 0.9208, 0.9583, 0.9167, 0.9042, 0.9625, 0.9458, 0.95, 0.9875, 0.9792, 0.9333, 0.9792, 0.9417, 0.9708, 0.975, 0.9333, 0.9458, 0.975, 0.9833, 0.9792, 0.9792, 0.9375, 0.9458, 0.9708, 0.9583, 0.8958, 0.925, 0.9167, 0.95, 0.9625, 0.9458, 0.9167, 0.9792, 0.975, 0.9042, 0.9708, 0.975, 0.9125, 0.9083, 0.9667, 0.9125, 0.9542, 0.9375, 0.9542, 0.9708, 0.9208, 0.9958, 0.9875, 0.9667, 0.9875, 0.95, 0.95, 0.9542, 1.0, 0.9375, 0.9042, 0.9917, 0.9875, 0.9833, 0.9792, 0.95, 0.9333, 0.9083, 0.9917, 0.9917, 0.9833, 0.9833, 0.9625, 0.95, 0.925, 0.9833, 0.9167, 0.9958, 0.9708, 0.9458, 0.925, 0.9583, 0.95, 0.925, 0.9333, 0.9667, 0.9583, 0.9625, 0.975, 0.9458, 0.9667, 0.9083, 0.9667, 0.9833, 0.9625, 0.9333, 0.9583, 0.9417, 0.925, 0.975, 0.9833, 0.9625, 0.9333, 0.95, 0.95, 0.9667, 0.9958, 0.9542, 0.9, 0.9667, 0.9583, 0.9875, 0.9875, 0.95, 0.9833, 0.9458, 0.9583, 0.9292, 0.9, 0.9583, 0.9833, 0.95, 0.9917, 0.9583, 0.975, 0.9125, 0.9375, 0.95, 0.9667, 0.9708, 0.9292, 0.9625, 0.9542, 0.9708, 0.9333, 0.9792, 0.9208, 0.9583, 0.9458, 0.9458, 0.9625, 0.9583, 0.9625, 0.9792, 0.9542, 0.9292, 0.9708, 0.975, 0.9625, 0.9667, 0.9208, 0.9708, 0.9583, 0.9458, 0.9458, 0.9708, 0.9667, 0.9667, 0.9125, 0.925, 0.925, 0.9792, 0.9292, 0.9417, 0.9625, 0.9667, 0.9375, 0.9542, 0.9708, 0.9458, 0.9417, 0.9542, 0.9458, 0.9625, 0.9667, 0.9542, 0.875, 0.975, 0.9375, 0.9208, 0.9583, 0.975, 0.975, 0.95, 0.9792, 0.9125, 0.875, 0.9833, 0.9875, 0.95, 0.8292, 0.9542, 0.9708, 0.9208, 0.9375, 0.9708, 0.9667, 0.9375, 0.9792, 0.9958, 0.9333, 0.9542, 0.95, 0.9667, 0.9917, 0.9583, 0.95, 0.9333, 0.9625, 0.975, 0.975, 0.9625, 0.9583, 0.9583, 0.9708, 0.9792, 0.9958, 1.0, 0.9958, 1.0, 1.0, 0.9792, 0.9917]\n",
      "\n",
      "Epoch 7/9             \n",
      "    Avg Losses: [0.05834, 0.07073, 0.08048, 0.07723, 0.14766, 0.09428, 0.11831, 0.09316, 0.03594, 0.07427, 0.07501, 0.07897, 0.09248, 0.08953, 0.08008, 0.0705, 0.14159, 0.03598, 0.15169, 0.15071, 0.11873, 0.15116, 0.08383, 0.29215, 0.07085, 0.0376, 0.06338, 0.07612, 0.05012, 0.13298, 0.0838, 0.12638, 0.0824, 0.19103, 0.15062, 0.21299, 0.15251, 0.09092, 0.08215, 0.11794, 0.02428, 0.07532, 0.16234, 0.03915, 0.11609, 0.06736, 0.06923, 0.11172, 0.13336, 0.11812, 0.05341, 0.0876, 0.05019, 0.15527, 0.15327, 0.04041, 0.12113, 0.13545, 0.15894, 0.15275, 0.14181, 0.10206, 0.12466, 0.16352, 0.05864, 0.10498, 0.1863, 0.03548, 0.05875, 0.17585, 0.19658, 0.11113, 0.14367, 0.10598, 0.0971, 0.11461, 0.0907, 0.20549, 0.04446, 0.03815, 0.07343, 0.03706, 0.0885, 0.0818, 0.12666, 0.02235, 0.14937, 0.22467, 0.04491, 0.09874, 0.04611, 0.05763, 0.12512, 0.16099, 0.17344, 0.02844, 0.07946, 0.03392, 0.05917, 0.11675, 0.07673, 0.16764, 0.11129, 0.19539, 0.03987, 0.05793, 0.16118, 0.11207, 0.10681, 0.13936, 0.13778, 0.10341, 0.09604, 0.09357, 0.09441, 0.05137, 0.10099, 0.15354, 0.28305, 0.09868, 0.04798, 0.1122, 0.13167, 0.08084, 0.12489, 0.10592, 0.07056, 0.06152, 0.13416, 0.18005, 0.15234, 0.16698, 0.07931, 0.07689, 0.09468, 0.15341, 0.11923, 0.08494, 0.05096, 0.05187, 0.10946, 0.05173, 0.15078, 0.1079, 0.12459, 0.20785, 0.0606, 0.05401, 0.16609, 0.02451, 0.09221, 0.08881, 0.18718, 0.12956, 0.09895, 0.11188, 0.07355, 0.16424, 0.09883, 0.10579, 0.07706, 0.17925, 0.04685, 0.11473, 0.14386, 0.08306, 0.08656, 0.09548, 0.07656, 0.1382, 0.04533, 0.07456, 0.17704, 0.07637, 0.0433, 0.1247, 0.09634, 0.19201, 0.09896, 0.0981, 0.10884, 0.10387, 0.07847, 0.07226, 0.07672, 0.14141, 0.13027, 0.13495, 0.0685, 0.1397, 0.11586, 0.08228, 0.0931, 0.13826, 0.04973, 0.07563, 0.14502, 0.12779, 0.09102, 0.13722, 0.08805, 0.05969, 0.14222, 0.23495, 0.05096, 0.1913, 0.15645, 0.07945, 0.06091, 0.08171, 0.13454, 0.03966, 0.1508, 0.23055, 0.0622, 0.02619, 0.10545, 0.25248, 0.08477, 0.07293, 0.21859, 0.19562, 0.04432, 0.11077, 0.12891, 0.06556, 0.01394, 0.0931, 0.13437, 0.10313, 0.08052, 0.05752, 0.12136, 0.11983, 0.15357, 0.1129, 0.04563, 0.08184, 0.06908, 0.11068, 0.15029, 0.05929, 0.03309, 0.01686, 0.0044, 0.01961, 0.00476, 0.02047, 0.04663, 0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9875, 0.9833, 0.975, 0.9833, 0.9458, 0.975, 0.9708, 0.9667, 0.9958, 0.975, 0.9833, 0.9875, 0.975, 0.9792, 0.9792, 0.975, 0.9417, 0.9958, 0.95, 0.9542, 0.975, 0.95, 0.9917, 0.9083, 0.9792, 0.9875, 0.9958, 0.9875, 0.9875, 0.9667, 0.9708, 0.9625, 0.9833, 0.9375, 0.9583, 0.9333, 0.9583, 0.9792, 0.9875, 0.9667, 1.0, 0.9833, 0.9667, 0.9917, 0.9708, 0.9833, 0.9833, 0.9667, 0.9667, 0.9667, 0.9875, 0.9708, 0.9917, 0.9375, 0.9417, 0.9917, 0.975, 0.9708, 0.9333, 0.9542, 0.9583, 0.9625, 0.9625, 0.95, 0.9958, 0.9792, 0.9625, 1.0, 0.9917, 0.925, 0.9333, 0.9625, 0.9625, 0.9792, 0.975, 0.9667, 0.9792, 0.9375, 0.9875, 0.9958, 0.9833, 0.9917, 0.9875, 0.9833, 0.9708, 1.0, 0.9375, 0.9208, 0.9917, 0.9667, 0.9833, 0.9875, 0.9625, 0.95, 0.9458, 1.0, 0.9792, 1.0, 0.9833, 0.9625, 0.9833, 0.9667, 0.975, 0.9292, 0.9958, 0.9917, 0.9542, 0.9833, 0.9625, 0.9625, 0.95, 0.975, 0.9667, 0.9833, 0.9833, 0.9917, 0.975, 0.9458, 0.9375, 0.9625, 0.9917, 0.9708, 0.9667, 0.9792, 0.9708, 0.975, 0.9917, 0.9917, 0.9542, 0.95, 0.9625, 0.9542, 0.9833, 0.9875, 0.975, 0.9458, 0.9708, 0.975, 0.9833, 0.9917, 0.975, 0.9875, 0.9583, 0.9708, 0.9542, 0.925, 0.9917, 0.9833, 0.95, 1.0, 0.9792, 0.9708, 0.9417, 0.975, 0.9792, 0.9542, 0.9833, 0.95, 0.9792, 0.9708, 0.975, 0.9375, 0.9875, 0.975, 0.9458, 0.9833, 0.9708, 0.9792, 0.9833, 0.95, 0.9917, 0.9833, 0.9542, 0.9792, 0.9917, 0.9542, 0.9792, 0.9458, 0.9708, 0.9792, 0.9625, 0.9708, 0.9792, 0.9792, 0.9792, 0.95, 0.9625, 0.9625, 0.9833, 0.9625, 0.975, 0.9708, 0.975, 0.9625, 0.9917, 0.9708, 0.95, 0.9583, 0.975, 0.9583, 0.975, 0.9833, 0.9542, 0.9292, 0.9917, 0.9375, 0.9542, 0.9833, 0.9917, 0.975, 0.975, 1.0, 0.9542, 0.9375, 0.9917, 1.0, 0.975, 0.925, 0.9708, 0.9833, 0.9167, 0.9375, 0.9958, 0.9708, 0.975, 0.9792, 1.0, 0.975, 0.9542, 0.9708, 0.975, 0.9875, 0.9667, 0.9542, 0.9708, 0.9708, 0.9917, 0.9792, 0.9875, 0.975, 0.9542, 0.9875, 0.9917, 1.0, 1.0, 1.0, 1.0, 0.9958, 0.9875, 0.9958]\n",
      "\n",
      "Epoch 8/9             \n",
      "    Avg Losses: [0.03995, 0.06138, 0.05498, 0.05741, 0.11932, 0.07282, 0.07717, 0.06039, 0.0328, 0.05466, 0.07413, 0.03731, 0.05234, 0.07359, 0.07445, 0.07456, 0.08113, 0.02935, 0.14579, 0.09662, 0.12304, 0.10189, 0.04081, 0.21289, 0.05037, 0.0157, 0.05585, 0.06108, 0.03363, 0.07983, 0.0785, 0.09365, 0.06347, 0.1062, 0.1171, 0.21627, 0.14345, 0.06783, 0.04709, 0.07632, 0.01413, 0.05045, 0.14531, 0.02, 0.09626, 0.04659, 0.04171, 0.06314, 0.11405, 0.10141, 0.02429, 0.0374, 0.02497, 0.08123, 0.09782, 0.0238, 0.07472, 0.09935, 0.10462, 0.1223, 0.07706, 0.06268, 0.07553, 0.12508, 0.03365, 0.05932, 0.12814, 0.03181, 0.02442, 0.11184, 0.12332, 0.08, 0.13529, 0.07043, 0.08337, 0.05866, 0.04461, 0.12817, 0.02157, 0.02401, 0.05311, 0.01627, 0.04943, 0.03796, 0.07311, 0.01777, 0.09249, 0.13959, 0.03528, 0.07452, 0.02218, 0.0414, 0.08074, 0.08508, 0.1042, 0.01736, 0.07006, 0.03164, 0.0486, 0.11468, 0.06329, 0.10339, 0.07184, 0.11471, 0.02154, 0.03899, 0.12231, 0.06217, 0.08267, 0.11617, 0.17663, 0.06378, 0.0408, 0.04725, 0.07034, 0.0229, 0.06104, 0.08616, 0.2355, 0.05675, 0.03414, 0.06694, 0.09499, 0.04141, 0.11153, 0.08158, 0.04676, 0.02652, 0.07094, 0.07979, 0.12188, 0.10273, 0.04103, 0.05286, 0.0487, 0.08498, 0.08765, 0.05744, 0.04908, 0.03623, 0.0719, 0.04638, 0.07608, 0.05198, 0.08632, 0.1537, 0.04903, 0.03436, 0.08959, 0.01384, 0.05914, 0.05402, 0.1222, 0.08763, 0.06904, 0.06092, 0.05584, 0.10831, 0.04885, 0.06428, 0.06374, 0.13289, 0.01868, 0.09898, 0.15506, 0.04388, 0.0747, 0.06223, 0.04179, 0.0842, 0.0742, 0.07674, 0.13776, 0.04493, 0.0399, 0.04661, 0.06763, 0.2018, 0.0689, 0.06095, 0.06468, 0.06971, 0.05409, 0.03921, 0.04764, 0.07128, 0.09299, 0.13289, 0.07974, 0.13021, 0.06883, 0.09108, 0.05685, 0.08938, 0.02413, 0.05022, 0.12936, 0.09618, 0.05981, 0.07425, 0.06648, 0.05245, 0.11526, 0.17413, 0.04409, 0.17026, 0.06758, 0.04611, 0.03372, 0.07905, 0.06935, 0.0208, 0.09181, 0.1475, 0.0399, 0.01547, 0.05443, 0.17368, 0.05923, 0.04588, 0.19771, 0.15837, 0.02159, 0.07528, 0.10893, 0.05143, 0.00993, 0.06734, 0.12708, 0.07694, 0.05161, 0.03519, 0.07979, 0.08691, 0.10513, 0.0721, 0.03496, 0.02968, 0.03104, 0.04705, 0.11012, 0.04319, 0.01558, 0.00823, 0.00296, 0.00904, 0.00289, 0.02576, 0.03286, 0.01303]\n",
      "    Avg Accuracies: [0.9958, 0.9875, 0.9875, 0.9917, 0.95, 0.9792, 0.9875, 0.9875, 0.9958, 0.9917, 0.9833, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.9917, 0.9917, 0.9458, 0.975, 0.9625, 0.9792, 1.0, 0.925, 0.9917, 1.0, 0.9875, 0.9875, 0.9958, 0.9833, 0.9708, 0.9625, 0.9958, 0.9667, 0.9708, 0.925, 0.9542, 0.9833, 0.9958, 0.9833, 1.0, 0.9917, 0.9625, 1.0, 0.975, 0.9917, 0.9958, 0.9917, 0.9708, 0.975, 0.9958, 0.9958, 1.0, 0.975, 0.9708, 1.0, 0.9875, 0.9792, 0.9792, 0.975, 0.9792, 0.9917, 0.9792, 0.9542, 0.9958, 0.9875, 0.9667, 0.9958, 1.0, 0.9625, 0.9583, 0.9792, 0.9583, 0.9917, 0.9792, 0.9875, 0.9833, 0.9625, 1.0, 1.0, 0.9875, 1.0, 0.9958, 0.9958, 0.9833, 1.0, 0.9833, 0.95, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.9792, 0.975, 1.0, 0.975, 0.9958, 0.9875, 0.9625, 0.9917, 0.9708, 0.9792, 0.9708, 1.0, 0.9917, 0.9625, 0.9917, 0.9792, 0.975, 0.9542, 0.9875, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 0.9792, 0.9375, 0.9875, 0.9917, 0.9875, 0.975, 1.0, 0.9667, 0.9875, 1.0, 1.0, 0.9833, 0.9833, 0.9625, 0.975, 0.9958, 0.9958, 0.9917, 0.9833, 0.9833, 0.9792, 0.9875, 0.9958, 0.9833, 0.9917, 0.9833, 0.9917, 0.975, 0.9417, 0.9958, 0.9958, 0.9625, 1.0, 0.9958, 0.9792, 0.975, 0.9833, 0.9792, 0.975, 0.9917, 0.9708, 1.0, 0.9875, 0.9792, 0.9625, 1.0, 0.9667, 0.9458, 0.9958, 0.9792, 0.9875, 0.9958, 0.9833, 0.9875, 0.9792, 0.9625, 0.9875, 0.9917, 0.9958, 0.9708, 0.9292, 0.9875, 0.9875, 0.9875, 0.9875, 0.9875, 0.9958, 0.9958, 0.9917, 0.975, 0.9625, 0.9667, 0.9625, 0.9875, 0.9708, 0.9792, 0.9708, 1.0, 0.9917, 0.9583, 0.9833, 0.9833, 0.9875, 0.9792, 0.9917, 0.9625, 0.9542, 0.9958, 0.9417, 0.9833, 0.9958, 1.0, 0.9833, 0.9917, 1.0, 0.975, 0.9583, 0.9958, 1.0, 0.9792, 0.9417, 0.9917, 0.9958, 0.9417, 0.9458, 1.0, 0.975, 0.9583, 0.9917, 1.0, 0.9833, 0.9667, 0.9792, 0.9958, 0.9958, 0.9792, 0.975, 0.9792, 0.9875, 0.9917, 0.9958, 1.0, 0.9958, 0.975, 0.9917, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9917, 0.9958]\n",
      "\n",
      "Epoch 9/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.031, 0.04517, 0.03066, 0.03894, 0.08107, 0.04407, 0.06208, 0.03247, 0.02878, 0.03631, 0.04314, 0.03273, 0.04891, 0.06261, 0.03742, 0.08304, 0.05914, 0.03059, 0.10272, 0.03446, 0.07539, 0.05777, 0.03378, 0.12612, 0.04476, 0.02137, 0.04388, 0.04683, 0.03168, 0.05777, 0.05729, 0.08648, 0.03384, 0.08456, 0.1063, 0.10001, 0.19139, 0.0377, 0.02038, 0.06355, 0.0085, 0.04787, 0.08315, 0.01412, 0.06868, 0.02623, 0.03351, 0.05543, 0.05108, 0.08458, 0.0228, 0.04318, 0.01196, 0.07169, 0.04412, 0.01501, 0.05284, 0.06107, 0.06247, 0.10537, 0.05127, 0.04609, 0.05002, 0.07577, 0.02377, 0.04016, 0.09452, 0.01583, 0.01738, 0.08198, 0.06597, 0.041, 0.0525, 0.05162, 0.05392, 0.04268, 0.03771, 0.15664, 0.01386, 0.01505, 0.04282, 0.01018, 0.04226, 0.02363, 0.03655, 0.00893, 0.05827, 0.1312, 0.02546, 0.03908, 0.02683, 0.01898, 0.05536, 0.05859, 0.07012, 0.01602, 0.07654, 0.01529, 0.02497, 0.11608, 0.03385, 0.06528, 0.04918, 0.10789, 0.01682, 0.02393, 0.0752, 0.04562, 0.02782, 0.06975, 0.12874, 0.04362, 0.02517, 0.04364, 0.02334, 0.01919, 0.03114, 0.06032, 0.23028, 0.05918, 0.02968, 0.0466, 0.06809, 0.03677, 0.11087, 0.0658, 0.03001, 0.01421, 0.05348, 0.07975, 0.08566, 0.08074, 0.03126, 0.02765, 0.02421, 0.04847, 0.05997, 0.0596, 0.01982, 0.02501, 0.04101, 0.02418, 0.05609, 0.03103, 0.07675, 0.07899, 0.05093, 0.03367, 0.05159, 0.00675, 0.03329, 0.04174, 0.09989, 0.05583, 0.061, 0.09116, 0.03579, 0.07384, 0.03385, 0.05379, 0.0505, 0.11037, 0.00978, 0.09812, 0.07278, 0.02639, 0.04169, 0.02731, 0.03048, 0.05581, 0.13625, 0.04432, 0.10021, 0.02846, 0.01842, 0.03752, 0.06903, 0.12882, 0.05086, 0.03399, 0.05068, 0.03752, 0.03096, 0.01933, 0.04209, 0.03607, 0.05568, 0.06465, 0.04503, 0.07891, 0.06134, 0.09457, 0.03837, 0.06526, 0.01308, 0.02891, 0.08042, 0.04495, 0.0623, 0.03799, 0.04995, 0.05798, 0.07308, 0.14735, 0.02783, 0.13948, 0.05538, 0.0283, 0.03052, 0.05152, 0.0431, 0.01517, 0.04914, 0.06653, 0.02532, 0.01004, 0.05024, 0.12523, 0.03719, 0.03692, 0.12954, 0.08095, 0.01483, 0.09324, 0.10394, 0.01863, 0.00498, 0.04823, 0.11471, 0.05475, 0.03008, 0.02111, 0.05877, 0.04387, 0.09106, 0.03546, 0.0212, 0.01903, 0.03429, 0.03449, 0.10482, 0.0291, 0.01662, 0.00645, 0.00198, 0.00633, 0.00237, 0.01456, 0.02026, 0.00679]\n",
      "    Avg Accuracies: [1.0, 0.9833, 0.9958, 0.9917, 0.9708, 0.9917, 0.9917, 0.9958, 0.9917, 0.9875, 0.9917, 0.9958, 0.9917, 0.9792, 0.9917, 0.975, 0.9833, 0.9958, 0.9625, 0.9958, 0.9833, 0.9917, 0.9958, 0.975, 0.9875, 0.9958, 0.9875, 0.9917, 0.9958, 0.9875, 0.9875, 0.9667, 1.0, 0.9708, 0.9583, 0.9708, 0.9417, 0.9917, 0.9958, 0.9917, 1.0, 0.9792, 0.9833, 1.0, 0.9792, 1.0, 0.9958, 0.9875, 0.9958, 0.9708, 1.0, 0.9958, 1.0, 0.9875, 0.9958, 1.0, 0.9917, 0.9875, 0.9875, 0.9708, 0.9833, 0.9958, 0.9917, 0.9875, 1.0, 0.9958, 0.975, 1.0, 1.0, 0.9708, 0.9833, 0.9875, 0.9917, 0.9917, 0.9917, 0.9917, 0.9917, 0.9542, 1.0, 1.0, 0.9875, 1.0, 0.9917, 1.0, 1.0, 1.0, 0.9917, 0.9625, 0.9958, 0.9875, 0.9917, 1.0, 0.9917, 0.9958, 0.9833, 1.0, 0.975, 1.0, 1.0, 0.9667, 0.9958, 0.9875, 0.9875, 0.9708, 0.9958, 0.9958, 0.9792, 0.9958, 1.0, 0.9917, 0.9583, 0.9958, 0.9958, 0.9875, 1.0, 1.0, 1.0, 0.9875, 0.925, 0.9875, 0.9958, 0.9958, 0.9792, 0.9958, 0.9667, 0.9792, 0.9958, 1.0, 0.9875, 0.975, 0.9833, 0.9833, 0.9958, 1.0, 1.0, 1.0, 0.9875, 0.9833, 1.0, 1.0, 0.9958, 1.0, 0.9875, 1.0, 0.9708, 0.975, 0.9917, 0.9917, 0.9833, 1.0, 0.9958, 0.9958, 0.975, 0.9917, 0.9875, 0.975, 0.9917, 0.9875, 0.9958, 0.9833, 0.9833, 0.9583, 1.0, 0.9708, 0.9833, 1.0, 0.9958, 1.0, 0.9958, 0.9875, 0.9542, 0.9958, 0.9667, 0.9958, 0.9958, 0.9917, 0.9792, 0.9583, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9875, 0.9917, 0.9958, 0.9792, 0.9958, 0.9875, 0.9875, 0.9708, 1.0, 0.9917, 1.0, 1.0, 0.975, 1.0, 0.9917, 0.9917, 0.9917, 0.9833, 0.9833, 0.9625, 1.0, 0.9583, 0.9958, 1.0, 0.9958, 0.9792, 0.9958, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9875, 0.9625, 0.9917, 0.9875, 0.9583, 0.9792, 1.0, 0.9625, 0.9667, 1.0, 1.0, 0.9958, 0.9583, 0.9917, 0.9958, 1.0, 0.9792, 0.9958, 0.975, 1.0, 0.9958, 1.0, 0.9917, 0.9958, 0.9667, 0.9958, 0.9958, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr         = 3e-2\n",
    "n_epochs   = 10\n",
    "batch_size = 30\n",
    "\n",
    "teacher_dataloaders = [data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True) for dataset in teacher_datasets]\n",
    "teacher_optimizers  = [optim.Adam(model.parameters(), lr=lr) for model in teachers]\n",
    "criterion           = nn.CrossEntropyLoss()\n",
    "\n",
    "for model in teachers:\n",
    "    model.train()\n",
    "\n",
    "teachers_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    avg_losses      = []\n",
    "    avg_accuracies  = []\n",
    "\n",
    "    for i_model in range(n_teachers):\n",
    "        instance_count = 0\n",
    "        total_loss     = 0.\n",
    "        correct_count  = 0\n",
    "\n",
    "        model      = teachers[i_model]\n",
    "        dataloader = teacher_dataloaders[i_model]\n",
    "        optimizer  = teacher_optimizers[i_model]\n",
    "\n",
    "        n_batches = len(dataloader)\n",
    "        _prev_str_len = 0\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            _batch_str = \"Teacher {:d}/{:d}: ({:d}/{:d})\".format(i_model, n_teachers-1, i, n_batches-1)\n",
    "            print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "            _prev_str_len = len(_batch_str)\n",
    "\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs  = model(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            \n",
    "            correct_count += (preds == labels).sum().item()\n",
    "\n",
    "        avg_losses.append(total_loss / instance_count)\n",
    "        avg_accuracies.append(correct_count / instance_count)\n",
    "\n",
    "    _epoch_str = \"Epoch {:d}/{:d}\".format(i_epoch, n_epochs-1)\n",
    "    _epoch_str += ' ' * (_prev_str_len - len(_epoch_str))\n",
    "    print(_epoch_str)\n",
    "    print(\"    Avg Losses:\", [round(avg_loss, 5) for avg_loss in avg_losses])\n",
    "    print(\"    Avg Accuracies:\", [round(avg_acc, 4) for avg_acc in avg_accuracies])\n",
    "    print()\n",
    "\n",
    "    teachers_train_history['avg_losses'][i_epoch]     = avg_losses\n",
    "    teachers_train_history['avg_accuracies'][i_epoch] = avg_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Evaluation (Average and Aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:45:43.162977Z",
     "start_time": "2019-06-23T13:45:41.218662Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/0 - Teacher 249/249\n",
      "\n",
      "Average Loss: 0.7376202709960937\n",
      "Average Accuracy: 0.81604\n",
      "\n",
      "Aggregate Accuracy: 0.9639999866485596\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "preds_lists_list = []\n",
    "labels_list      = []\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "\n",
    "    imgs   = imgs.to(device)\n",
    "    labels_list.append(labels)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            preds_list.append(preds.cpu())\n",
    "\n",
    "            total_loss += criterion(outs, labels).item()\n",
    "            correct_count += (preds == labels).sum().item()\n",
    "    preds_lists_list.append(preds_list)\n",
    "\n",
    "preds_tensor = torch.cat([torch.stack(preds_list, dim=0) for preds_list in preds_lists_list], dim=1)\n",
    "preds_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=preds_tensor.numpy()))\n",
    "\n",
    "aggregate_preds = preds_counts.argmax(dim=0)\n",
    "labels          = torch.cat(labels_list, dim=0)\n",
    "\n",
    "aggregate_acc = (aggregate_preds == labels).float().mean().item()\n",
    "\n",
    "print('\\n')\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)\n",
    "print()\n",
    "print(\"Aggregate Accuracy:\", aggregate_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:45:43.172401Z",
     "start_time": "2019-06-23T13:45:43.164962Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def aggregate_counts(img):\n",
    "    assert 3 <= img.dim() <= 4\n",
    "    if img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    else:\n",
    "        assert img.size(0) == 1\n",
    "\n",
    "    img = img.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in teachers:\n",
    "            model.eval()\n",
    "            preds_list.append(model(img).argmax(dim=1).view(1).cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(preds_list, dim=0)\n",
    "    \n",
    "    counts = torch.bincount(preds_tensor, minlength=10)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:47:16.534375Z",
     "start_time": "2019-06-23T13:45:43.174385Z"
    },
    "code_folding": [
     26
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19 - Number of Labeled Data: 5\n",
      "    Update 0 - Loss = 2.516278, Accuracy = 0.0\n",
      "    Update 1 - Loss = 1.813576, Accuracy = 0.2\n",
      "    Update 2 - Loss = 1.451643, Accuracy = 1.0\n",
      "    Update 3 - Loss = 1.171823, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.919899, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.684254, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.458117, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.295014, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.171470, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.095434, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.055843, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.034436, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.020803, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.012203, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.007342, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004648, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003143, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002238, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001647, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001253, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.000992, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.000808, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.000676, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.000574, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000493, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000427, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000373, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000327, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000287, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000254, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000226, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000202, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000181, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000163, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000147, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000133, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000122, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000112, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000103, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000096, Accuracy = 1.0\n",
      "Epoch 1/19 - Number of Labeled Data: 10\n",
      "    Update 0 - Loss = 7.142645, Accuracy = 0.5\n",
      "    Update 1 - Loss = 5.819629, Accuracy = 0.5\n",
      "    Update 2 - Loss = 4.560112, Accuracy = 0.5\n",
      "    Update 3 - Loss = 3.351021, Accuracy = 0.5\n",
      "    Update 4 - Loss = 2.202668, Accuracy = 0.5\n",
      "    Update 5 - Loss = 1.267532, Accuracy = 0.5\n",
      "    Update 6 - Loss = 0.930900, Accuracy = 0.8\n",
      "    Update 7 - Loss = 1.058115, Accuracy = 0.5\n",
      "    Update 8 - Loss = 1.004715, Accuracy = 0.7\n",
      "    Update 9 - Loss = 0.883809, Accuracy = 0.7\n",
      "    Update 10 - Loss = 0.809739, Accuracy = 0.9\n",
      "    Update 11 - Loss = 0.738041, Accuracy = 0.9\n",
      "    Update 12 - Loss = 0.643513, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.528487, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.435609, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.375363, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.331126, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.284804, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.239593, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.200764, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.167680, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.137045, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.110239, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.090082, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.075311, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.062943, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.052700, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.045025, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.038680, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.033210, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.028382, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.024087, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.020368, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.017285, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.014811, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.012811, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.011155, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.009767, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.008647, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.007734, Accuracy = 1.0\n",
      "Epoch 2/19 - Number of Labeled Data: 15\n",
      "    Update 0 - Loss = 1.470749, Accuracy = 0.6667\n",
      "    Update 1 - Loss = 1.263096, Accuracy = 0.7333\n",
      "    Update 2 - Loss = 1.082523, Accuracy = 0.7333\n",
      "    Update 3 - Loss = 0.843437, Accuracy = 0.7333\n",
      "    Update 4 - Loss = 0.594992, Accuracy = 0.8667\n",
      "    Update 5 - Loss = 0.404676, Accuracy = 0.8667\n",
      "    Update 6 - Loss = 0.261019, Accuracy = 0.8667\n",
      "    Update 7 - Loss = 0.156057, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.102234, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.090366, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.097840, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.106916, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.104622, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.089848, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.068914, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.050828, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.038901, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.031038, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.025762, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.021616, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.018231, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.015413, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.013306, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.011718, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.010541, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.009621, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.008872, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.008235, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.007664, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.007157, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.006694, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.006260, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.005856, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.005496, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.005156, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.004834, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.004529, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.004247, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.003986, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.003741, Accuracy = 1.0\n",
      "Epoch 3/19 - Number of Labeled Data: 20\n",
      "    Update 0 - Loss = 0.499935, Accuracy = 0.75\n",
      "    Update 1 - Loss = 0.394060, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.286967, Accuracy = 0.9\n",
      "    Update 3 - Loss = 0.210475, Accuracy = 0.95\n",
      "    Update 4 - Loss = 0.151256, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.114820, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.085932, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.064553, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.051356, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.043621, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.038367, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.033601, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.028693, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.023608, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.019058, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.015550, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.013081, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.011479, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.010345, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.009526, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.008882, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.008374, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.007896, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.007446, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.006984, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.006494, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.006006, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.005541, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.005110, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004718, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004359, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.004039, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003764, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003526, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.003324, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.003146, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002984, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002841, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002714, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002600, Accuracy = 1.0\n",
      "Epoch 4/19 - Number of Labeled Data: 25\n",
      "    Update 0 - Loss = 0.587641, Accuracy = 0.84\n",
      "    Update 1 - Loss = 0.469896, Accuracy = 0.84\n",
      "    Update 2 - Loss = 0.319660, Accuracy = 0.92\n",
      "    Update 3 - Loss = 0.189048, Accuracy = 0.96\n",
      "    Update 4 - Loss = 0.105251, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.067484, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 6 - Loss = 0.052588, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.052224, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.054399, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.051951, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.047679, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.041908, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.035657, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.029232, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.023192, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.018134, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.014471, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.011922, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.010199, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.008990, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.008168, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.007558, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.007101, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.006749, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.006417, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.006087, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.005755, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.005406, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.005058, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004711, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004390, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.004102, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003847, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003621, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.003417, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.003235, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.003072, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002930, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002802, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002683, Accuracy = 1.0\n",
      "Epoch 5/19 - Number of Labeled Data: 30\n",
      "    Update 0 - Loss = 0.585546, Accuracy = 0.8333\n",
      "    Update 1 - Loss = 0.440050, Accuracy = 0.9333\n",
      "    Update 2 - Loss = 0.334932, Accuracy = 0.9333\n",
      "    Update 3 - Loss = 0.229987, Accuracy = 0.9667\n",
      "    Update 4 - Loss = 0.142660, Accuracy = 0.9667\n",
      "    Update 5 - Loss = 0.093745, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.060595, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.046282, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.045173, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.048952, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.048970, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.045335, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.041640, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.038411, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.035689, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.031797, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.026856, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.021775, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.017513, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.014397, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.012178, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.010553, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.009339, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.008349, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.007507, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.006754, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.006064, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.005465, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.004969, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004548, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004193, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003889, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003638, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003430, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.003253, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.003105, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002978, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002856, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002739, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002623, Accuracy = 1.0\n",
      "Epoch 6/19 - Number of Labeled Data: 35\n",
      "    Update 0 - Loss = 0.494697, Accuracy = 0.9429\n",
      "    Update 1 - Loss = 0.398487, Accuracy = 0.9429\n",
      "    Update 2 - Loss = 0.308782, Accuracy = 0.9714\n",
      "    Update 3 - Loss = 0.224914, Accuracy = 0.9714\n",
      "    Update 4 - Loss = 0.159116, Accuracy = 0.9714\n",
      "    Update 5 - Loss = 0.100978, Accuracy = 0.9714\n",
      "    Update 6 - Loss = 0.052776, Accuracy = 0.9714\n",
      "    Update 7 - Loss = 0.040330, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.070838, Accuracy = 0.9714\n",
      "    Update 9 - Loss = 0.065004, Accuracy = 0.9714\n",
      "    Update 10 - Loss = 0.051440, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.046566, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.028285, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.015457, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.009803, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.008322, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.008953, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.010640, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.012204, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.012564, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.011589, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.009994, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.008337, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.007000, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.006057, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.005374, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.004868, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.004507, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.004242, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004003, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.003755, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003505, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003257, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.003031, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002825, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002644, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002489, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.002355, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.002239, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.002135, Accuracy = 1.0\n",
      "Epoch 7/19 - Number of Labeled Data: 40\n",
      "    Update 0 - Loss = 0.230476, Accuracy = 0.925\n",
      "    Update 1 - Loss = 0.114195, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.052065, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.034213, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.040825, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.028948, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.019898, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.018903, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.026310, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.032042, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.025208, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.018910, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.015155, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.012632, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.010725, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.009251, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.008075, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.007140, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.006246, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.005494, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.004801, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.004223, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003757, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.003389, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.003075, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002827, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002641, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002500, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002387, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002288, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.002195, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.002112, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.002032, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001956, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001882, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001813, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001748, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001686, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001628, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001574, Accuracy = 1.0\n",
      "Epoch 8/19 - Number of Labeled Data: 45\n",
      "    Update 0 - Loss = 0.241657, Accuracy = 0.8889\n",
      "    Update 1 - Loss = 0.166678, Accuracy = 0.9333\n",
      "    Update 2 - Loss = 0.083447, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.043143, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.030346, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.028723, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.031117, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.030416, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.026520, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.021726, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.018055, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.016047, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.014972, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 13 - Loss = 0.014036, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.012747, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.010987, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.009037, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.007350, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.006059, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.005089, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.004386, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003851, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003444, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.003123, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002857, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002637, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002451, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002297, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002167, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002055, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001959, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001874, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001794, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001718, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001645, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001577, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001513, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001455, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001401, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001351, Accuracy = 1.0\n",
      "Epoch 9/19 - Number of Labeled Data: 50\n",
      "    Update 0 - Loss = 0.178050, Accuracy = 0.92\n",
      "    Update 1 - Loss = 0.118515, Accuracy = 0.94\n",
      "    Update 2 - Loss = 0.063175, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.032827, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.020975, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.019884, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.021587, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.020963, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.018313, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.015412, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.012929, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.010870, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.009319, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.008211, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.007488, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.006835, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.006109, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.005329, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.004535, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003848, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003314, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002908, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002604, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002378, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002215, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002086, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001976, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001878, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001790, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001707, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001629, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001555, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001484, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001415, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001349, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001287, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001229, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001173, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001122, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001075, Accuracy = 1.0\n",
      "Epoch 10/19 - Number of Labeled Data: 55\n",
      "    Update 0 - Loss = 0.145027, Accuracy = 0.9273\n",
      "    Update 1 - Loss = 0.080648, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.037738, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.024969, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.020671, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.016073, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.012212, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.011154, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.011276, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.011721, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.011819, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.010939, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.009383, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.007729, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.006313, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005144, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004227, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003530, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003019, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002658, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002393, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002186, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002020, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001887, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001776, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001681, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001603, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001539, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001487, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001441, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001395, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001351, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001308, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001266, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001225, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001187, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001150, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001113, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001079, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001046, Accuracy = 1.0\n",
      "Epoch 11/19 - Number of Labeled Data: 60\n",
      "    Update 0 - Loss = 0.131560, Accuracy = 0.9333\n",
      "    Update 1 - Loss = 0.092533, Accuracy = 0.9833\n",
      "    Update 2 - Loss = 0.052290, Accuracy = 0.9833\n",
      "    Update 3 - Loss = 0.029346, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.015670, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.009673, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.008294, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.008955, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.010321, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.011145, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.010924, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.009857, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.008426, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.007230, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.006458, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005948, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.005560, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.005167, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.004718, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.004289, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003871, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003494, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003178, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002916, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002698, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002512, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002348, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002198, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002056, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001929, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001814, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001710, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001617, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001534, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001459, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001392, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001330, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001273, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001221, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001173, Accuracy = 1.0\n",
      "Epoch 12/19 - Number of Labeled Data: 65\n",
      "    Update 0 - Loss = 0.198724, Accuracy = 0.9231\n",
      "    Update 1 - Loss = 0.114581, Accuracy = 0.9846\n",
      "    Update 2 - Loss = 0.051770, Accuracy = 0.9846\n",
      "    Update 3 - Loss = 0.048724, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.060878, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.021786, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.010837, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.009327, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.013339, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.015727, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.012847, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.009966, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.008469, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.007746, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.007163, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.006352, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.005527, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.004949, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.004603, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.004366, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 20 - Loss = 0.004142, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003877, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003570, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.003259, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002961, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002677, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002429, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002213, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002029, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001876, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001743, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001628, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001528, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001442, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001367, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001302, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001246, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001197, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001154, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001116, Accuracy = 1.0\n",
      "Epoch 13/19 - Number of Labeled Data: 70\n",
      "    Update 0 - Loss = 0.115539, Accuracy = 0.9429\n",
      "    Update 1 - Loss = 0.058664, Accuracy = 0.9857\n",
      "    Update 2 - Loss = 0.029971, Accuracy = 0.9857\n",
      "    Update 3 - Loss = 0.020080, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.017232, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.018215, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.013333, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.011883, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.011517, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.007090, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004402, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003442, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003138, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003037, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002996, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002969, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002917, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002843, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002752, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002638, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002502, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002334, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002149, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001972, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001805, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001654, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001521, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001405, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001305, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001220, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001147, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001084, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001029, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000982, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000940, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000903, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000870, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000841, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000814, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000790, Accuracy = 1.0\n",
      "Epoch 14/19 - Number of Labeled Data: 75\n",
      "    Update 0 - Loss = 0.098135, Accuracy = 0.9467\n",
      "    Update 1 - Loss = 0.043283, Accuracy = 0.9867\n",
      "    Update 2 - Loss = 0.017832, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.012086, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.015216, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.013353, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.012015, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.010723, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.008557, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.007099, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.006918, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.007329, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.007223, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.006419, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.005270, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004213, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003437, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002929, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002608, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002388, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002218, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002074, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001942, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001823, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001722, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001632, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001550, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001477, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001410, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001347, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001287, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001230, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001175, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001121, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001069, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001020, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000975, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000932, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000893, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000857, Accuracy = 1.0\n",
      "Epoch 15/19 - Number of Labeled Data: 80\n",
      "    Update 0 - Loss = 0.205877, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.115339, Accuracy = 0.9625\n",
      "    Update 2 - Loss = 0.046779, Accuracy = 0.9875\n",
      "    Update 3 - Loss = 0.036480, Accuracy = 0.9875\n",
      "    Update 4 - Loss = 0.043114, Accuracy = 0.9875\n",
      "    Update 5 - Loss = 0.025932, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.019110, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.018108, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.021099, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.017119, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.010435, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.007177, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.006122, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.006035, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.006207, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.006031, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.005391, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.004595, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003845, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003286, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002887, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002602, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002381, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002203, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002041, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001886, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001738, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001598, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001466, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001346, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001239, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001146, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001065, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000996, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000937, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000887, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000845, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000808, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000777, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000749, Accuracy = 1.0\n",
      "Epoch 16/19 - Number of Labeled Data: 85\n",
      "    Update 0 - Loss = 0.088558, Accuracy = 0.9412\n",
      "    Update 1 - Loss = 0.046062, Accuracy = 0.9882\n",
      "    Update 2 - Loss = 0.018749, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.008613, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.008855, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.010286, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.011094, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.012623, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.010285, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.006834, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004621, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003480, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.002928, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002674, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002526, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002408, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002289, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002163, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002042, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001938, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001854, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001787, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001732, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001687, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001645, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001604, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001562, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 27 - Loss = 0.001517, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001467, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001413, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001357, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001300, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001244, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001189, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001137, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001089, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001044, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001003, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000964, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000928, Accuracy = 1.0\n",
      "Epoch 17/19 - Number of Labeled Data: 90\n",
      "    Update 0 - Loss = 0.088850, Accuracy = 0.9556\n",
      "    Update 1 - Loss = 0.038739, Accuracy = 0.9889\n",
      "    Update 2 - Loss = 0.009990, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.005622, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.008264, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.012177, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.012014, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.009447, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.007102, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.005789, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.005260, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005093, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004999, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004716, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004159, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003564, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003128, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002871, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002646, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002424, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002185, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001964, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001777, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001619, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001487, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001378, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001288, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001210, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001143, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001087, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001039, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000996, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000957, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000922, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000890, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000861, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000834, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000809, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000786, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000764, Accuracy = 1.0\n",
      "Epoch 18/19 - Number of Labeled Data: 95\n",
      "    Update 0 - Loss = 0.091591, Accuracy = 0.9684\n",
      "    Update 1 - Loss = 0.055691, Accuracy = 0.9895\n",
      "    Update 2 - Loss = 0.025426, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.013618, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.011105, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.013196, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.013688, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.009787, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.006094, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.003878, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.002701, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.002079, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.001801, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.001760, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.001865, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002078, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002335, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002536, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002581, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002455, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002247, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002018, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001813, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001649, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001536, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001434, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001332, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001233, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001141, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001056, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000983, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000922, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000872, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000829, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000791, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000758, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000727, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000700, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000676, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000653, Accuracy = 1.0\n",
      "Epoch 19/19 - Number of Labeled Data: 100\n",
      "    Update 0 - Loss = 0.040182, Accuracy = 0.99\n",
      "    Update 1 - Loss = 0.016744, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.006423, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.006111, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.008891, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.008964, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.005956, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.003727, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.002824, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.002856, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.003189, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003236, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.002899, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002446, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002036, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001683, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001421, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001237, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001111, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001030, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.000980, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.000950, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.000934, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.000930, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000927, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000922, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000914, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000901, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000882, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000857, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000827, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000791, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000754, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000717, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000680, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000646, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000615, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000586, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000561, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000539, Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "max_train_subset_size  = 100\n",
    "n_new_labels_per_epoch = 5\n",
    "n_updates_per_epoch    = 40\n",
    "lr                     = 2e-2\n",
    "weight_decay           = 0\n",
    "epsilon                = 0.05\n",
    "\n",
    "student = MNISTClassifier().to(device)\n",
    "\n",
    "laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                               batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "student.train()\n",
    "\n",
    "teacher_preds = []\n",
    "noisy_labels  = []\n",
    "student_train_history = {'n_labels': {}, 'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_total_epochs):\n",
    "    if i_epoch == 0:\n",
    "        new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "    else:\n",
    "        max_probs_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in student_unlabeled_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "\n",
    "                outs  = student(imgs)\n",
    "                probs = outs.softmax(dim=1)\n",
    "\n",
    "                max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "        max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "        \n",
    "        new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                             max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "    for idx in new_label_indices:\n",
    "        student_labeled_dataset.indices.append(idx)\n",
    "        student_unlabeled_dataset.indices.remove(idx)\n",
    "        label_pred_counts = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28))\n",
    "        noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "        mnist_testset.targets[idx] = noisy_label\n",
    "        teacher_preds.append(label_pred_counts)\n",
    "        noisy_labels.append(noisy_label)\n",
    "        \n",
    "    student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "    \n",
    "    print(\"Epoch {:d}/{:d} - Number of Labeled Data: {:d}\".format(i_epoch, n_total_epochs-1, len(student_labeled_dataset)))\n",
    "\n",
    "    student_train_history['n_labels'][i_epoch] = init_subset_size + (i_epoch * n_new_labels_per_epoch)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i_update in range(n_updates_per_epoch):\n",
    "        imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = student(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(\"    Update {:d} - Loss = {:.6f}, Accuracy = {:.4}\".format(i_update, loss.item(), accuracy))\n",
    "\n",
    "    student_train_history['avg_losses'][i_epoch]     = losses\n",
    "    student_train_history['avg_accuracies'][i_epoch] = accuracies\n",
    "\n",
    "teacher_preds = torch.stack(teacher_preds, dim=1)\n",
    "noisy_labels  = torch.tensor(noisy_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Final Student Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:47:16.887027Z",
     "start_time": "2019-06-23T13:47:16.536327Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/33\n",
      "Average Loss: 1.3743693885803223\n",
      "Average Accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "student.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs   = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = student(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PATE Analysis to Measure the Information Leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:47:23.114262Z",
     "start_time": "2019-06-23T13:47:16.888515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon: 5.30258509299405\n"
     ]
    }
   ],
   "source": [
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds, noisy_labels, epsilon)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
