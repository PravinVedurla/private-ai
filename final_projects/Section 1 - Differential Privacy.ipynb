{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Project:\n",
    "\n",
    "For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:01:30.389493Z",
     "start_time": "2019-06-23T13:01:26.522322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:01:31.524293Z",
     "start_time": "2019-06-23T13:01:30.392422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 60000\n",
      "Test Set Size: 10000\n",
      "\n",
      "Min Data Value: tensor(0, dtype=torch.uint8)\n",
      "Max Data Value: tensor(255, dtype=torch.uint8)\n",
      "\n",
      "Train Label Counts: {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test Label Counts: {0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset  = datasets.MNIST(root='../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset.true_targets = mnist_testset.targets.clone() # data points that are considered \"unlabeled\" will be re-labeled by teachers later\n",
    "\n",
    "print(\"Training Set Size:\", len(mnist_trainset))\n",
    "print(\"Test Set Size:\", len(mnist_testset))\n",
    "print()\n",
    "print(\"Min Data Value:\", torch.min(mnist_trainset.data.min(), mnist_testset.data.min()))\n",
    "print(\"Max Data Value:\", torch.max(mnist_trainset.data.max(), mnist_testset.data.max()))\n",
    "print()\n",
    "print(\"Train Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_trainset.targets, return_counts=True))})\n",
    "print(\"Test Label Counts:\", {label.item():count.item() for label, count in zip(*torch.unique(mnist_testset.targets, return_counts=True))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:01:31.546109Z",
     "start_time": "2019-06-23T13:01:31.527261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each teacher dataset: 240\n",
      "Size of the dataset available to the student: 9000\n",
      "Size of the test dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "n_teachers = 250\n",
    "\n",
    "_teacher_dataset_len = len(mnist_trainset) // n_teachers\n",
    "\n",
    "teacher_datasets = [data.Subset(mnist_trainset, list(range(i*_teacher_dataset_len, (i+1)*_teacher_dataset_len))) for i in range(n_teachers)]\n",
    "student_dataset  = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9))))\n",
    "test_dataset     = data.Subset(mnist_testset, list(range(int(len(mnist_testset) * 0.9), len(mnist_testset))))\n",
    "\n",
    "print(\"Size of each teacher dataset:\", _teacher_dataset_len)\n",
    "print(\"Size of the dataset available to the student:\", len(student_dataset))\n",
    "print(\"Size of the test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:01:31.559515Z",
     "start_time": "2019-06-23T13:01:31.548589Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        # 1x28x28\n",
    "        self.bn0        = nn.BatchNorm2d(1)\n",
    "        self.conv0      = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        self.bn1        = nn.BatchNorm2d(5)\n",
    "        self.maxpool0   = nn.MaxPool2d(2)\n",
    "        # 5x14x14\n",
    "        self.conv1      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn2        = nn.BatchNorm2d(5)\n",
    "        self.maxpool1   = nn.MaxPool2d(2)\n",
    "        # 5x 7x 7\n",
    "        self.conv2      = nn.Conv2d(5, 5, 3, padding=1)\n",
    "        self.bn3        = nn.BatchNorm2d(5)\n",
    "        self.maxpool2   = nn.MaxPool2d(2, padding=1)\n",
    "        # 5x 4x 4 = 80\n",
    "        self.fc         = nn.Linear(80, 10)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(self.bn0(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.fc(x.view(-1, 80))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Teacher & DF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:01:35.060897Z",
     "start_time": "2019-06-23T13:01:31.562973Z"
    }
   },
   "outputs": [],
   "source": [
    "teachers      = [MNISTClassifier().to(device) for _ in range(n_teachers)]\n",
    "student       = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:07:47.300407Z",
     "start_time": "2019-06-23T13:01:35.062878Z"
    },
    "code_folding": [
     12
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9             \n",
      "    Avg Losses: [2.21073, 2.23918, 2.28086, 2.15874, 2.23866, 2.31621, 2.30713, 2.18633, 2.17418, 2.16536, 2.21159, 2.13759, 2.29504, 2.13437, 2.26481, 2.26822, 2.36746, 1.982, 2.2323, 2.13046, 2.18558, 2.3023, 2.18393, 2.23326, 2.22305, 2.19732, 2.31659, 2.25757, 2.18945, 2.30273, 2.24863, 2.29796, 2.19766, 2.19736, 2.23516, 2.10273, 2.25671, 2.16019, 2.15332, 2.15617, 2.16629, 2.16903, 2.29991, 2.15375, 2.35322, 2.26402, 2.16145, 2.11861, 1.9837, 2.22307, 2.18739, 2.1666, 2.20664, 2.20077, 2.16129, 2.13993, 2.22303, 2.21677, 2.25294, 2.318, 2.30551, 2.1139, 2.02318, 2.24366, 2.12847, 2.18998, 2.38609, 2.24913, 2.11516, 2.1852, 2.28901, 2.16478, 2.27972, 2.20896, 2.18185, 2.15838, 2.26615, 2.29928, 1.90267, 2.15768, 2.23865, 2.09571, 2.17137, 2.01474, 2.18474, 2.08203, 2.26916, 2.14139, 2.13376, 2.00431, 2.27429, 2.25236, 2.2412, 2.15806, 2.06265, 2.15356, 2.22228, 2.06031, 2.17198, 2.18582, 2.32406, 2.32279, 2.16512, 2.31682, 2.1459, 2.20135, 2.27286, 2.17005, 2.24154, 2.33773, 2.09488, 2.32376, 2.29292, 2.13337, 2.168, 2.31548, 2.10926, 2.1934, 2.36461, 2.26305, 2.09429, 2.28596, 2.17563, 2.25983, 2.3113, 2.20922, 2.22492, 2.2454, 2.21729, 2.0837, 2.29063, 2.25299, 2.18992, 2.16562, 2.30043, 2.34616, 2.26113, 2.27231, 2.16817, 2.31263, 2.33401, 2.21849, 2.1174, 2.11123, 2.20396, 2.25619, 2.01475, 2.05484, 2.22974, 2.09647, 2.29722, 2.36117, 2.28311, 2.20881, 2.26532, 2.33023, 2.186, 2.31897, 2.23161, 2.18338, 2.10811, 2.29595, 2.16346, 2.25251, 2.2622, 2.17528, 2.3172, 2.135, 2.23191, 2.23288, 1.9902, 2.2193, 2.10468, 2.25035, 2.24638, 2.11847, 2.11505, 2.22427, 2.30591, 2.21544, 2.17284, 2.21771, 2.1784, 2.30839, 2.2152, 2.10152, 2.18159, 2.31007, 2.21134, 2.10331, 2.26013, 2.27187, 2.08699, 2.29745, 2.22577, 2.25388, 2.13596, 2.23598, 2.11999, 2.24028, 2.13461, 2.11814, 2.13933, 2.21759, 2.20369, 2.33002, 2.3528, 2.17646, 2.17335, 2.25637, 2.02236, 2.22642, 2.36992, 2.27649, 2.25047, 2.25078, 2.27415, 2.32967, 2.21808, 2.24284, 2.14604, 2.29484, 2.23476, 2.2296, 2.0718, 2.20586, 2.07811, 2.17823, 2.17631, 2.17855, 2.09659, 2.25036, 2.19659, 2.28594, 2.27595, 2.23097, 2.03611, 2.11549, 2.17534, 2.2058, 2.12737, 2.22151, 2.07211, 2.28077, 1.97503, 2.21552, 1.90485, 2.16851, 2.28436, 2.01619]\n",
      "    Avg Accuracies: [0.1917, 0.2208, 0.1833, 0.2458, 0.2542, 0.1583, 0.1917, 0.3167, 0.2333, 0.2083, 0.2292, 0.3167, 0.1458, 0.275, 0.2292, 0.1792, 0.1292, 0.3625, 0.1833, 0.2208, 0.2125, 0.2083, 0.1875, 0.1917, 0.25, 0.2667, 0.1708, 0.1833, 0.2333, 0.1583, 0.1958, 0.2208, 0.2875, 0.2208, 0.1875, 0.2625, 0.2042, 0.2292, 0.275, 0.2333, 0.2625, 0.2458, 0.1333, 0.275, 0.1583, 0.1958, 0.3167, 0.2583, 0.3708, 0.2583, 0.2042, 0.2292, 0.2042, 0.2583, 0.2417, 0.225, 0.1958, 0.2292, 0.1667, 0.1542, 0.1708, 0.3042, 0.3333, 0.25, 0.2667, 0.2167, 0.125, 0.2, 0.2458, 0.2708, 0.1375, 0.2125, 0.1417, 0.2292, 0.225, 0.2333, 0.2542, 0.1792, 0.35, 0.2458, 0.2542, 0.3292, 0.2417, 0.2792, 0.2208, 0.3, 0.1333, 0.2417, 0.2417, 0.3125, 0.1375, 0.2375, 0.225, 0.2417, 0.2708, 0.2708, 0.2833, 0.3708, 0.2417, 0.2125, 0.1458, 0.1458, 0.2333, 0.1833, 0.3333, 0.2292, 0.1917, 0.2875, 0.2333, 0.2125, 0.2333, 0.1667, 0.2375, 0.2167, 0.2542, 0.1458, 0.3542, 0.2083, 0.1333, 0.2292, 0.275, 0.1208, 0.2125, 0.2083, 0.2125, 0.2708, 0.1792, 0.1958, 0.2292, 0.275, 0.1292, 0.2167, 0.2083, 0.2042, 0.1875, 0.1292, 0.2042, 0.1708, 0.2458, 0.2167, 0.2042, 0.2333, 0.2708, 0.2667, 0.2, 0.1708, 0.2542, 0.3083, 0.1958, 0.2875, 0.1833, 0.1458, 0.1667, 0.2458, 0.1875, 0.1208, 0.1958, 0.175, 0.1958, 0.1917, 0.3042, 0.2083, 0.2417, 0.2292, 0.2292, 0.2792, 0.1208, 0.2458, 0.2, 0.225, 0.2542, 0.1625, 0.2875, 0.2292, 0.2167, 0.2792, 0.2458, 0.1917, 0.1833, 0.2042, 0.25, 0.2333, 0.2042, 0.1625, 0.2333, 0.2583, 0.2333, 0.1292, 0.2333, 0.3, 0.2208, 0.2458, 0.2958, 0.2792, 0.2083, 0.1792, 0.2417, 0.1917, 0.275, 0.2, 0.275, 0.2583, 0.2083, 0.2083, 0.2375, 0.2167, 0.1708, 0.25, 0.2542, 0.2083, 0.325, 0.2458, 0.1542, 0.1792, 0.2792, 0.1583, 0.1958, 0.1583, 0.1792, 0.2208, 0.2833, 0.2333, 0.1583, 0.2083, 0.3125, 0.1625, 0.2625, 0.2792, 0.1625, 0.2625, 0.3, 0.1958, 0.2417, 0.2333, 0.1792, 0.2667, 0.2917, 0.2833, 0.2208, 0.1625, 0.275, 0.1875, 0.2833, 0.1375, 0.3833, 0.2375, 0.375, 0.2083, 0.2125, 0.4208]\n",
      "\n",
      "Epoch 1/9             \n",
      "    Avg Losses: [1.42381, 1.39537, 1.74487, 1.53985, 1.55253, 1.90142, 1.62009, 1.4135, 1.30981, 1.38843, 1.39188, 1.24705, 1.86741, 1.33969, 1.33815, 1.3306, 1.84276, 0.95245, 1.50066, 1.12283, 1.53454, 1.89858, 1.44705, 1.65217, 1.69226, 1.19967, 1.83251, 1.62285, 1.36112, 1.75379, 1.60444, 1.61523, 1.31669, 1.62977, 1.77638, 1.47225, 1.79817, 1.33695, 1.43391, 1.46353, 1.24017, 1.35401, 1.95149, 1.29823, 1.95154, 1.67819, 1.28619, 1.34109, 1.0076, 1.47126, 1.53107, 1.47704, 1.4076, 1.44501, 1.53864, 1.19278, 1.57052, 1.58738, 1.74866, 1.90252, 1.76198, 1.24593, 0.97451, 1.6813, 1.32292, 1.42092, 1.97998, 1.57496, 1.40484, 1.46477, 1.99371, 1.40583, 1.98369, 1.61364, 1.48053, 1.37721, 1.69897, 1.82911, 0.89683, 1.29328, 1.677, 1.21664, 1.66508, 1.06224, 1.48296, 1.14285, 1.77176, 1.5192, 1.2997, 0.97415, 1.58493, 1.57689, 1.5984, 1.42763, 1.31415, 1.30406, 1.28475, 1.02804, 1.39818, 1.60773, 2.01164, 1.98241, 1.45242, 1.91757, 1.1857, 1.58552, 1.68537, 1.42052, 1.60991, 1.6828, 1.38486, 1.90846, 1.51598, 1.37456, 1.53038, 1.73341, 1.20852, 1.49144, 2.04071, 1.58566, 1.33482, 1.86689, 1.42537, 1.6486, 1.61695, 1.5561, 1.67668, 1.76015, 1.44703, 1.31895, 1.7989, 1.76222, 1.55916, 1.43701, 1.8509, 2.10753, 1.44544, 1.75486, 1.3932, 1.51323, 1.61157, 1.45711, 1.19002, 1.31292, 1.51953, 1.72311, 1.14192, 1.23265, 1.65739, 1.17559, 1.53354, 1.79744, 1.68659, 1.6411, 1.76463, 1.91536, 1.58411, 1.71895, 1.64447, 1.37587, 1.43552, 1.55132, 1.30771, 1.43608, 1.48642, 1.50677, 1.78681, 1.30656, 1.59476, 1.4626, 0.94181, 1.57376, 1.39517, 1.44049, 1.55957, 1.43553, 1.14401, 1.64256, 1.89102, 1.6014, 1.41941, 1.42416, 1.29406, 1.71719, 1.59306, 1.30824, 1.39046, 1.98514, 1.37188, 1.38513, 1.60011, 1.69304, 1.27431, 1.70502, 1.72458, 1.61647, 1.40712, 1.64285, 1.29312, 1.69142, 1.45707, 1.25022, 1.36998, 1.65383, 1.41502, 1.89952, 1.86793, 1.38564, 1.43751, 1.57334, 1.26326, 1.64884, 2.19365, 1.82912, 1.47181, 1.47486, 1.49856, 1.95868, 1.60749, 1.52544, 1.44046, 1.75859, 1.48846, 1.5461, 1.33984, 1.42182, 1.01291, 1.31295, 1.54863, 1.51149, 1.26342, 1.4558, 1.5351, 1.69838, 1.81812, 1.30321, 1.19927, 1.47293, 1.43928, 1.66977, 1.34175, 1.52437, 1.02248, 1.69023, 0.92628, 1.42398, 0.70244, 1.35278, 1.61002, 0.88342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.5667, 0.6292, 0.4625, 0.6042, 0.5083, 0.3833, 0.4833, 0.5375, 0.6708, 0.6333, 0.5708, 0.6292, 0.4917, 0.6375, 0.7042, 0.6333, 0.4708, 0.7708, 0.5583, 0.7542, 0.5, 0.3833, 0.5417, 0.4417, 0.5, 0.7458, 0.375, 0.4208, 0.6583, 0.4542, 0.5583, 0.5, 0.6792, 0.4875, 0.3792, 0.5375, 0.4833, 0.6292, 0.6083, 0.5458, 0.6792, 0.625, 0.4125, 0.6292, 0.3167, 0.5583, 0.6125, 0.6125, 0.7375, 0.6125, 0.5417, 0.5417, 0.6542, 0.6, 0.5792, 0.7667, 0.5417, 0.5042, 0.4083, 0.4125, 0.4583, 0.6458, 0.7042, 0.5125, 0.6083, 0.525, 0.3542, 0.6208, 0.5292, 0.5875, 0.325, 0.6375, 0.2875, 0.4833, 0.5458, 0.6083, 0.5917, 0.4, 0.7417, 0.6958, 0.4833, 0.6792, 0.475, 0.6792, 0.5875, 0.6917, 0.475, 0.5542, 0.6167, 0.7833, 0.6125, 0.5208, 0.5583, 0.5708, 0.6333, 0.6792, 0.6292, 0.725, 0.5958, 0.5208, 0.3375, 0.3917, 0.5833, 0.3958, 0.7, 0.5167, 0.5042, 0.5625, 0.5042, 0.5625, 0.5875, 0.4042, 0.5667, 0.6, 0.575, 0.4917, 0.7375, 0.525, 0.325, 0.5333, 0.6167, 0.4708, 0.5625, 0.4833, 0.5542, 0.525, 0.5208, 0.4667, 0.6167, 0.6208, 0.475, 0.4292, 0.4792, 0.5667, 0.4208, 0.2667, 0.575, 0.3958, 0.6875, 0.5542, 0.6542, 0.5375, 0.7042, 0.6042, 0.5792, 0.5375, 0.7167, 0.6292, 0.4292, 0.6792, 0.5, 0.5333, 0.4708, 0.475, 0.4167, 0.4167, 0.5583, 0.475, 0.5, 0.5875, 0.5375, 0.5708, 0.6458, 0.6583, 0.5458, 0.5292, 0.3667, 0.6, 0.5208, 0.5667, 0.775, 0.5333, 0.6333, 0.5667, 0.525, 0.5458, 0.6917, 0.5125, 0.4083, 0.4667, 0.6, 0.6042, 0.6875, 0.4542, 0.4792, 0.6625, 0.6375, 0.4083, 0.6, 0.5583, 0.6, 0.5292, 0.6208, 0.425, 0.4708, 0.575, 0.5875, 0.5625, 0.6083, 0.4833, 0.5417, 0.6833, 0.5875, 0.4667, 0.5958, 0.3625, 0.4542, 0.6458, 0.6208, 0.5375, 0.625, 0.5292, 0.1833, 0.3708, 0.5375, 0.6375, 0.575, 0.3708, 0.525, 0.5958, 0.5958, 0.4583, 0.6458, 0.5167, 0.5583, 0.6542, 0.7875, 0.6083, 0.5417, 0.5375, 0.725, 0.6375, 0.5667, 0.4792, 0.4042, 0.7167, 0.6167, 0.5292, 0.6667, 0.4875, 0.625, 0.6167, 0.7542, 0.5667, 0.75, 0.5625, 0.8708, 0.6833, 0.6, 0.7958]\n",
      "\n",
      "Epoch 2/9             \n",
      "    Avg Losses: [0.66599, 0.68, 1.12474, 0.94035, 0.87837, 1.19405, 0.95927, 0.68643, 0.60857, 0.6313, 0.68368, 0.53514, 1.05277, 0.73045, 0.72797, 0.57532, 1.11161, 0.43986, 0.73435, 0.50105, 0.86767, 1.18369, 0.89181, 1.06066, 0.99737, 0.48823, 1.09057, 0.80912, 0.67014, 1.06789, 0.84192, 0.8452, 0.69559, 0.92172, 1.10743, 0.88686, 1.10064, 0.68435, 0.69713, 0.90724, 0.49681, 0.58764, 1.35203, 0.60153, 1.20756, 0.94735, 0.5831, 0.64751, 0.58494, 0.64268, 0.79085, 0.83259, 0.62535, 0.74641, 0.95486, 0.4387, 0.94367, 1.00357, 1.14919, 1.29178, 1.03752, 0.66397, 0.58902, 0.9811, 0.64928, 0.82396, 1.34565, 0.76407, 0.68749, 0.77847, 1.34026, 0.59694, 1.39065, 1.05931, 0.77265, 0.65953, 0.75683, 1.25792, 0.40736, 0.59923, 0.98679, 0.60373, 1.02912, 0.47348, 0.8163, 0.53822, 1.03332, 0.85762, 0.62372, 0.41193, 0.71429, 0.65654, 0.87922, 0.81375, 0.80651, 0.58685, 0.68455, 0.42698, 0.66215, 0.91345, 1.41813, 1.52535, 0.76166, 1.18984, 0.53504, 0.8023, 0.91003, 0.75111, 0.81586, 1.0115, 0.81306, 1.21674, 0.87108, 0.76017, 0.87342, 0.942, 0.61365, 0.91401, 1.51914, 0.84708, 0.79193, 1.06661, 0.72766, 0.91778, 0.84166, 0.9422, 1.04837, 1.04955, 0.75538, 0.80042, 1.08596, 1.11449, 0.8611, 0.77262, 1.31092, 1.61769, 0.74286, 1.07584, 0.60249, 0.75645, 0.76992, 0.86336, 0.53998, 0.7142, 0.8105, 0.98299, 0.62944, 0.5848, 0.96158, 0.53288, 0.84607, 1.105, 0.96856, 1.00391, 1.03573, 1.09328, 0.90556, 1.1071, 0.98892, 0.73693, 0.83677, 0.85324, 0.58472, 0.71735, 0.85879, 0.80836, 1.18544, 0.67979, 0.87918, 0.79398, 0.49305, 0.77364, 0.8869, 0.64375, 0.78308, 0.77796, 0.60326, 0.97946, 1.2149, 0.87099, 0.7001, 0.70706, 0.62539, 0.87781, 0.94258, 0.68555, 0.74049, 1.34597, 0.77008, 0.80915, 0.80504, 0.91615, 0.73466, 1.10003, 0.98002, 0.82342, 0.83352, 1.01544, 0.61114, 0.90205, 0.82121, 0.59938, 0.7985, 1.11068, 0.78088, 1.25657, 1.26994, 0.66875, 0.74174, 0.83759, 0.78769, 0.85224, 1.74938, 1.18292, 0.82449, 0.71559, 0.75905, 1.4021, 0.84399, 0.7188, 0.81278, 1.15215, 0.79036, 0.80981, 0.85224, 0.62689, 0.36006, 0.58909, 0.90115, 0.94261, 0.54388, 0.7067, 0.79463, 0.86382, 1.18871, 0.55697, 0.60989, 0.78352, 0.65399, 0.91318, 0.79228, 0.73644, 0.31869, 0.76147, 0.28624, 0.64678, 0.22662, 0.51067, 0.74232, 0.27579]\n",
      "    Avg Accuracies: [0.8333, 0.7833, 0.6458, 0.7375, 0.7417, 0.6292, 0.7583, 0.8333, 0.8542, 0.8292, 0.8, 0.875, 0.7417, 0.8, 0.7833, 0.875, 0.7292, 0.875, 0.8083, 0.8792, 0.7708, 0.6583, 0.7542, 0.6583, 0.7208, 0.8833, 0.725, 0.7917, 0.7875, 0.7458, 0.725, 0.8, 0.8042, 0.6875, 0.6792, 0.7417, 0.7042, 0.8125, 0.7958, 0.7625, 0.8667, 0.8125, 0.5958, 0.85, 0.7167, 0.7375, 0.8375, 0.7917, 0.8417, 0.85, 0.7625, 0.775, 0.8417, 0.8042, 0.725, 0.8833, 0.7208, 0.7, 0.6167, 0.5792, 0.6542, 0.8583, 0.8333, 0.7292, 0.8083, 0.775, 0.625, 0.775, 0.8083, 0.7708, 0.6292, 0.8625, 0.65, 0.6625, 0.7542, 0.8083, 0.8167, 0.6292, 0.8875, 0.8708, 0.7042, 0.8292, 0.7333, 0.8583, 0.7417, 0.8958, 0.6917, 0.7583, 0.8458, 0.9042, 0.8167, 0.8667, 0.7667, 0.7625, 0.7542, 0.8417, 0.8, 0.8625, 0.8167, 0.7417, 0.5917, 0.6083, 0.7875, 0.6208, 0.8583, 0.7833, 0.75, 0.7958, 0.7542, 0.7125, 0.7833, 0.6583, 0.75, 0.7833, 0.7417, 0.7917, 0.8292, 0.7542, 0.5792, 0.7917, 0.7583, 0.7292, 0.7958, 0.7375, 0.7583, 0.7333, 0.7292, 0.7083, 0.8042, 0.7417, 0.6917, 0.6708, 0.7417, 0.7875, 0.575, 0.4708, 0.7958, 0.7333, 0.8667, 0.825, 0.8167, 0.7625, 0.85, 0.7833, 0.7917, 0.725, 0.8375, 0.8417, 0.7708, 0.8542, 0.7792, 0.7375, 0.7042, 0.725, 0.7542, 0.7583, 0.7417, 0.7167, 0.6917, 0.7542, 0.7333, 0.7542, 0.8292, 0.8167, 0.7083, 0.7833, 0.6542, 0.7958, 0.7583, 0.8125, 0.8667, 0.8125, 0.75, 0.8542, 0.7958, 0.8083, 0.8292, 0.7375, 0.675, 0.7042, 0.8125, 0.825, 0.8, 0.7625, 0.7208, 0.8292, 0.7875, 0.6458, 0.7583, 0.7708, 0.775, 0.7375, 0.7875, 0.6667, 0.6792, 0.7958, 0.7667, 0.725, 0.825, 0.7625, 0.7792, 0.8167, 0.7667, 0.65, 0.8, 0.6833, 0.6208, 0.8125, 0.8042, 0.7792, 0.7417, 0.7333, 0.3667, 0.6333, 0.75, 0.8458, 0.8208, 0.575, 0.7625, 0.85, 0.7833, 0.6833, 0.8333, 0.7625, 0.7458, 0.8042, 0.9125, 0.8208, 0.7083, 0.7458, 0.8625, 0.7958, 0.775, 0.7375, 0.6833, 0.8833, 0.8125, 0.7667, 0.8542, 0.7875, 0.7708, 0.8167, 0.9208, 0.8417, 0.9333, 0.8167, 0.9375, 0.8833, 0.8625, 0.9625]\n",
      "\n",
      "Epoch 3/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.48196, 0.39495, 0.64809, 0.63741, 0.49077, 0.60653, 0.66273, 0.3823, 0.34925, 0.33786, 0.29736, 0.29569, 0.48175, 0.46401, 0.42631, 0.31803, 0.68814, 0.28315, 0.42986, 0.30587, 0.58295, 0.71571, 0.51475, 0.66945, 0.57366, 0.25418, 0.52692, 0.42819, 0.38567, 0.62894, 0.46286, 0.4921, 0.43013, 0.5892, 0.69507, 0.62799, 0.70596, 0.38762, 0.42889, 0.62651, 0.25701, 0.34896, 0.82233, 0.27526, 0.57192, 0.63084, 0.34517, 0.3787, 0.41386, 0.31513, 0.41947, 0.45023, 0.34627, 0.39547, 0.66425, 0.26189, 0.59932, 0.61769, 0.72941, 0.82716, 0.54384, 0.35755, 0.39575, 0.58415, 0.3106, 0.45865, 0.79431, 0.39925, 0.39961, 0.41193, 0.70602, 0.29866, 0.71757, 0.65548, 0.40805, 0.3696, 0.31718, 0.88587, 0.25379, 0.34058, 0.54434, 0.37237, 0.61531, 0.26922, 0.47284, 0.28939, 0.73809, 0.45363, 0.31637, 0.24237, 0.32734, 0.28693, 0.52126, 0.46532, 0.54293, 0.34269, 0.41552, 0.27459, 0.3654, 0.53991, 0.72576, 0.94148, 0.44812, 0.71731, 0.30885, 0.3954, 0.54082, 0.53909, 0.42298, 0.64224, 0.56769, 0.67844, 0.60497, 0.4522, 0.47973, 0.5055, 0.40781, 0.57054, 0.9823, 0.45909, 0.50563, 0.57251, 0.41695, 0.51667, 0.50825, 0.6069, 0.58578, 0.7305, 0.47277, 0.51299, 0.63576, 0.64091, 0.48706, 0.45464, 0.818, 1.1267, 0.50097, 0.56388, 0.30145, 0.39376, 0.44791, 0.42866, 0.31135, 0.42883, 0.48344, 0.59819, 0.40895, 0.32713, 0.50017, 0.23611, 0.52366, 0.57339, 0.60061, 0.65181, 0.62357, 0.50196, 0.48496, 0.61577, 0.59275, 0.52364, 0.48737, 0.49912, 0.3021, 0.45976, 0.51327, 0.50803, 0.69884, 0.37053, 0.45433, 0.42669, 0.33122, 0.44625, 0.61729, 0.41484, 0.41625, 0.47304, 0.3541, 0.60182, 0.68031, 0.60647, 0.39479, 0.3552, 0.36673, 0.4614, 0.62608, 0.50295, 0.51306, 0.75801, 0.38947, 0.55062, 0.44288, 0.49432, 0.44232, 0.69196, 0.52238, 0.41408, 0.53916, 0.70469, 0.35342, 0.47564, 0.50128, 0.38504, 0.50143, 0.81774, 0.41797, 0.73371, 0.72841, 0.45132, 0.42971, 0.46308, 0.58568, 0.48524, 0.93896, 0.76619, 0.42808, 0.36213, 0.3797, 0.85078, 0.48552, 0.44227, 0.55609, 0.71893, 0.40844, 0.42552, 0.57096, 0.27701, 0.17773, 0.36979, 0.4969, 0.5945, 0.28993, 0.43079, 0.51329, 0.45096, 0.70995, 0.36631, 0.35184, 0.49862, 0.32361, 0.46052, 0.49918, 0.37334, 0.13107, 0.25859, 0.10553, 0.28947, 0.07066, 0.23102, 0.33573, 0.12248]\n",
      "    Avg Accuracies: [0.85, 0.8667, 0.8458, 0.7958, 0.8458, 0.8042, 0.825, 0.8958, 0.9, 0.8958, 0.9417, 0.9167, 0.8875, 0.8417, 0.875, 0.925, 0.8042, 0.9083, 0.875, 0.9208, 0.7917, 0.7958, 0.8583, 0.7708, 0.8333, 0.9458, 0.85, 0.8625, 0.8792, 0.8042, 0.8458, 0.8167, 0.85, 0.8042, 0.7792, 0.7833, 0.7833, 0.8667, 0.8625, 0.8125, 0.9167, 0.8792, 0.7458, 0.9375, 0.8375, 0.8125, 0.875, 0.8542, 0.8917, 0.9125, 0.8708, 0.8708, 0.9, 0.8958, 0.8, 0.9167, 0.825, 0.7917, 0.7583, 0.7333, 0.8, 0.9208, 0.8833, 0.8125, 0.9, 0.8625, 0.7708, 0.8708, 0.8875, 0.8583, 0.8, 0.9042, 0.8208, 0.775, 0.8708, 0.8792, 0.9333, 0.75, 0.925, 0.9042, 0.8375, 0.8875, 0.8333, 0.925, 0.8583, 0.9167, 0.7625, 0.8792, 0.9042, 0.9333, 0.9, 0.9, 0.7958, 0.8917, 0.8208, 0.8958, 0.8708, 0.925, 0.8792, 0.825, 0.825, 0.7333, 0.85, 0.7833, 0.9, 0.8917, 0.8333, 0.8458, 0.8583, 0.8458, 0.7917, 0.7708, 0.7875, 0.85, 0.8833, 0.8625, 0.875, 0.8333, 0.7042, 0.8833, 0.825, 0.8083, 0.8833, 0.8542, 0.8458, 0.7958, 0.8292, 0.7458, 0.8375, 0.85, 0.8292, 0.8, 0.8167, 0.8708, 0.7583, 0.6583, 0.8417, 0.8667, 0.925, 0.8833, 0.8208, 0.8875, 0.9292, 0.8667, 0.8417, 0.7958, 0.8917, 0.9083, 0.8792, 0.9375, 0.8042, 0.8333, 0.7792, 0.7958, 0.8167, 0.8625, 0.8417, 0.8417, 0.8417, 0.8125, 0.8667, 0.8417, 0.925, 0.8375, 0.8208, 0.8542, 0.7667, 0.8708, 0.8833, 0.8917, 0.9042, 0.8875, 0.8083, 0.8792, 0.85, 0.8583, 0.8917, 0.8, 0.7833, 0.7958, 0.8917, 0.8917, 0.8708, 0.875, 0.7958, 0.8417, 0.825, 0.7833, 0.8792, 0.8292, 0.8792, 0.85, 0.8708, 0.7833, 0.8375, 0.8958, 0.8125, 0.7792, 0.8833, 0.8417, 0.8417, 0.8833, 0.8333, 0.7542, 0.8875, 0.8083, 0.7667, 0.8208, 0.8792, 0.8667, 0.7792, 0.85, 0.7583, 0.7708, 0.8833, 0.8958, 0.9, 0.7167, 0.8667, 0.8792, 0.8208, 0.8, 0.9125, 0.8917, 0.7875, 0.925, 0.9417, 0.875, 0.875, 0.8, 0.9292, 0.8542, 0.8583, 0.8542, 0.7792, 0.8917, 0.8917, 0.8542, 0.9083, 0.875, 0.8292, 0.8958, 0.9667, 0.95, 0.9833, 0.9125, 0.9833, 0.9333, 0.9167, 0.9792]\n",
      "\n",
      "Epoch 4/9             \n",
      "    Avg Losses: [0.28891, 0.22555, 0.3559, 0.39023, 0.37431, 0.35275, 0.48511, 0.21394, 0.20961, 0.22675, 0.19763, 0.21251, 0.28091, 0.28781, 0.26523, 0.18045, 0.41467, 0.16987, 0.32037, 0.18861, 0.39433, 0.41576, 0.37449, 0.50219, 0.35067, 0.15185, 0.31396, 0.25741, 0.22776, 0.41897, 0.22509, 0.30999, 0.2781, 0.4487, 0.43524, 0.40831, 0.53501, 0.28574, 0.28236, 0.40846, 0.14392, 0.19668, 0.5025, 0.15856, 0.35133, 0.36871, 0.27215, 0.28247, 0.28401, 0.19666, 0.25415, 0.26818, 0.22573, 0.24178, 0.44897, 0.1706, 0.40138, 0.41233, 0.39791, 0.56953, 0.32189, 0.34489, 0.29231, 0.42231, 0.19222, 0.27278, 0.50622, 0.28283, 0.2123, 0.31118, 0.50026, 0.18146, 0.36325, 0.44203, 0.24668, 0.24076, 0.21205, 0.63301, 0.15116, 0.19759, 0.32279, 0.22464, 0.4399, 0.22261, 0.37989, 0.16058, 0.51012, 0.3606, 0.1845, 0.11659, 0.14364, 0.28062, 0.35765, 0.28533, 0.45711, 0.17376, 0.31657, 0.15993, 0.28201, 0.36495, 0.43011, 0.52525, 0.31863, 0.48602, 0.17758, 0.26284, 0.393, 0.41634, 0.25962, 0.38287, 0.3671, 0.47567, 0.29817, 0.30014, 0.39614, 0.28771, 0.28318, 0.37699, 0.69169, 0.27075, 0.32267, 0.37107, 0.26674, 0.31559, 0.33103, 0.38551, 0.33134, 0.39419, 0.25614, 0.4105, 0.44502, 0.40158, 0.33931, 0.29996, 0.46534, 0.67086, 0.29514, 0.32455, 0.14047, 0.22306, 0.32852, 0.29049, 0.20378, 0.28117, 0.27948, 0.42294, 0.23599, 0.19227, 0.29525, 0.14941, 0.38839, 0.34543, 0.49706, 0.44576, 0.34686, 0.27158, 0.27715, 0.40581, 0.40901, 0.39445, 0.29299, 0.34858, 0.19459, 0.40968, 0.34214, 0.35449, 0.40866, 0.19855, 0.28549, 0.27062, 0.17832, 0.26995, 0.44641, 0.23026, 0.20783, 0.28219, 0.22709, 0.41037, 0.37302, 0.45191, 0.26457, 0.24938, 0.20663, 0.26095, 0.36947, 0.36359, 0.34524, 0.43218, 0.21164, 0.46288, 0.34953, 0.27753, 0.37089, 0.52711, 0.38742, 0.24887, 0.39912, 0.39963, 0.23723, 0.31508, 0.2684, 0.32909, 0.35508, 0.63284, 0.27884, 0.49175, 0.43561, 0.29236, 0.31188, 0.2981, 0.4531, 0.25021, 0.48449, 0.51957, 0.2364, 0.17064, 0.27775, 0.63791, 0.32195, 0.26165, 0.51905, 0.49771, 0.23781, 0.25961, 0.40497, 0.16743, 0.06296, 0.28033, 0.33499, 0.37259, 0.25426, 0.31233, 0.41567, 0.34832, 0.50832, 0.24215, 0.19551, 0.31726, 0.2308, 0.28226, 0.33196, 0.20754, 0.13901, 0.12085, 0.04432, 0.13365, 0.03929, 0.09566, 0.2536, 0.0965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9042, 0.9375, 0.8875, 0.8958, 0.8875, 0.8625, 0.8292, 0.9583, 0.9292, 0.9125, 0.9542, 0.9292, 0.925, 0.9, 0.9042, 0.9417, 0.8833, 0.9417, 0.9042, 0.95, 0.8708, 0.8583, 0.8958, 0.8417, 0.8958, 0.9458, 0.8958, 0.9167, 0.9167, 0.8833, 0.9375, 0.9, 0.9125, 0.8167, 0.8625, 0.8708, 0.8042, 0.9, 0.9083, 0.8708, 0.9667, 0.9333, 0.8208, 0.9458, 0.8792, 0.9042, 0.8958, 0.875, 0.8958, 0.95, 0.9083, 0.9292, 0.9458, 0.9375, 0.8417, 0.9458, 0.875, 0.8542, 0.875, 0.8125, 0.875, 0.8667, 0.8958, 0.8625, 0.95, 0.9167, 0.8458, 0.8875, 0.9208, 0.9083, 0.8333, 0.9375, 0.8833, 0.8708, 0.9208, 0.9333, 0.925, 0.8083, 0.9625, 0.95, 0.875, 0.9375, 0.8708, 0.9333, 0.9125, 0.9583, 0.8417, 0.8958, 0.9542, 0.9667, 0.9625, 0.8917, 0.8875, 0.9208, 0.875, 0.9458, 0.9042, 0.9458, 0.8875, 0.8833, 0.8542, 0.8167, 0.9042, 0.8625, 0.9542, 0.9292, 0.8792, 0.8792, 0.9042, 0.9, 0.8667, 0.8375, 0.9375, 0.9, 0.8542, 0.9125, 0.9125, 0.9, 0.7917, 0.9083, 0.8917, 0.8667, 0.9042, 0.9167, 0.8875, 0.8917, 0.8917, 0.8917, 0.9208, 0.8833, 0.8708, 0.8542, 0.85, 0.9042, 0.825, 0.8042, 0.9375, 0.9333, 0.9667, 0.9292, 0.8792, 0.9208, 0.9458, 0.9083, 0.8833, 0.875, 0.9417, 0.9417, 0.9, 0.9542, 0.8792, 0.8875, 0.85, 0.8542, 0.8958, 0.9208, 0.9167, 0.8708, 0.8542, 0.8625, 0.9125, 0.8917, 0.9458, 0.875, 0.8875, 0.8833, 0.8708, 0.9375, 0.9167, 0.9208, 0.9458, 0.8958, 0.8625, 0.9417, 0.9625, 0.9125, 0.9542, 0.8708, 0.8458, 0.8375, 0.9333, 0.9, 0.9208, 0.9292, 0.9042, 0.8708, 0.8833, 0.8583, 0.9417, 0.8625, 0.8833, 0.9208, 0.8875, 0.8333, 0.8625, 0.9292, 0.8542, 0.8708, 0.9167, 0.8958, 0.9292, 0.8958, 0.8917, 0.7833, 0.925, 0.8292, 0.8708, 0.9042, 0.9333, 0.9042, 0.8792, 0.925, 0.8667, 0.8125, 0.9458, 0.9542, 0.9083, 0.7708, 0.9125, 0.9292, 0.85, 0.8708, 0.9333, 0.9083, 0.8708, 0.9583, 0.9833, 0.9125, 0.9042, 0.8583, 0.9167, 0.9042, 0.8875, 0.8958, 0.8292, 0.9333, 0.9375, 0.8958, 0.9333, 0.9167, 0.9083, 0.9375, 0.9667, 0.975, 0.9875, 0.9708, 0.9917, 0.9792, 0.9208, 0.9792]\n",
      "\n",
      "Epoch 5/9             \n",
      "    Avg Losses: [0.16412, 0.11238, 0.19013, 0.28199, 0.27105, 0.20363, 0.30046, 0.17323, 0.10403, 0.16652, 0.15891, 0.14055, 0.13259, 0.16479, 0.15708, 0.13441, 0.28863, 0.08136, 0.20084, 0.1439, 0.20792, 0.29733, 0.23148, 0.3516, 0.19949, 0.09054, 0.18473, 0.18505, 0.14955, 0.28307, 0.18728, 0.25392, 0.17235, 0.30713, 0.30131, 0.33304, 0.38434, 0.19929, 0.20945, 0.26157, 0.10033, 0.14145, 0.32146, 0.1068, 0.23235, 0.19656, 0.19722, 0.30252, 0.21943, 0.11361, 0.1161, 0.17755, 0.1052, 0.21269, 0.27971, 0.20105, 0.27286, 0.28203, 0.27646, 0.40654, 0.21544, 0.16365, 0.21493, 0.30489, 0.14909, 0.15678, 0.32252, 0.1368, 0.14417, 0.25806, 0.43813, 0.13805, 0.21068, 0.27681, 0.17352, 0.13406, 0.13238, 0.39186, 0.1121, 0.12407, 0.21506, 0.12431, 0.25223, 0.19667, 0.2732, 0.10154, 0.32296, 0.2849, 0.12288, 0.08924, 0.11191, 0.143, 0.22584, 0.24117, 0.32359, 0.09037, 0.18131, 0.135, 0.15849, 0.20724, 0.24612, 0.36693, 0.30095, 0.35446, 0.10929, 0.15397, 0.24262, 0.26822, 0.178, 0.26734, 0.29093, 0.27758, 0.23424, 0.19863, 0.22631, 0.1402, 0.25468, 0.25712, 0.53964, 0.2661, 0.15554, 0.3047, 0.27111, 0.23781, 0.29425, 0.26893, 0.19269, 0.21038, 0.27911, 0.35504, 0.34253, 0.26069, 0.18465, 0.1699, 0.21951, 0.39997, 0.20234, 0.25376, 0.08123, 0.12708, 0.2461, 0.13121, 0.1867, 0.22287, 0.23841, 0.29241, 0.21679, 0.09353, 0.22586, 0.08382, 0.23697, 0.20265, 0.27007, 0.31829, 0.25873, 0.16417, 0.21701, 0.28042, 0.31053, 0.17731, 0.16343, 0.28814, 0.10069, 0.32898, 0.19927, 0.24024, 0.28534, 0.14555, 0.22054, 0.23926, 0.15649, 0.18352, 0.29607, 0.21047, 0.11096, 0.15617, 0.18266, 0.28586, 0.20878, 0.23957, 0.2012, 0.14114, 0.15798, 0.12821, 0.21549, 0.26567, 0.2519, 0.26321, 0.1273, 0.30482, 0.30131, 0.15282, 0.21586, 0.31453, 0.2081, 0.16013, 0.29679, 0.28014, 0.12027, 0.21463, 0.19036, 0.1916, 0.25342, 0.44088, 0.16983, 0.28907, 0.29999, 0.19803, 0.16162, 0.16611, 0.28249, 0.16565, 0.30243, 0.37948, 0.1622, 0.08769, 0.22002, 0.57307, 0.18343, 0.17292, 0.35897, 0.37807, 0.12379, 0.18304, 0.26809, 0.08159, 0.03747, 0.1778, 0.19798, 0.19109, 0.16654, 0.15146, 0.33422, 0.2472, 0.32968, 0.23296, 0.0965, 0.18713, 0.17695, 0.18326, 0.21985, 0.12177, 0.13057, 0.10023, 0.01609, 0.07351, 0.01577, 0.0569, 0.12047, 0.06009]\n",
      "    Avg Accuracies: [0.95, 0.975, 0.9458, 0.9, 0.9, 0.9417, 0.8958, 0.9583, 0.975, 0.9417, 0.9625, 0.9583, 0.9667, 0.9458, 0.9708, 0.9583, 0.9083, 0.9833, 0.9625, 0.9542, 0.9333, 0.9083, 0.925, 0.8958, 0.9417, 0.9792, 0.9458, 0.95, 0.9542, 0.9208, 0.95, 0.9083, 0.9542, 0.8875, 0.9, 0.8833, 0.8875, 0.9417, 0.9375, 0.9, 0.9667, 0.9708, 0.9, 0.9667, 0.9292, 0.9542, 0.925, 0.8917, 0.9417, 0.975, 0.975, 0.9333, 0.9833, 0.9292, 0.9167, 0.9292, 0.9167, 0.9125, 0.9375, 0.85, 0.9333, 0.9625, 0.9292, 0.9083, 0.9542, 0.9625, 0.9042, 0.9583, 0.9542, 0.9, 0.8458, 0.9542, 0.9458, 0.9208, 0.9458, 0.95, 0.95, 0.875, 0.975, 0.9708, 0.9208, 0.9792, 0.9292, 0.9333, 0.9042, 0.9792, 0.8875, 0.9167, 0.9625, 0.975, 0.9625, 0.9542, 0.9375, 0.9333, 0.8833, 0.9833, 0.9583, 0.9417, 0.9417, 0.9417, 0.9083, 0.875, 0.8917, 0.8833, 0.975, 0.9458, 0.9333, 0.925, 0.9542, 0.9125, 0.9208, 0.8792, 0.9167, 0.9458, 0.925, 0.9708, 0.9333, 0.9208, 0.8375, 0.9042, 0.9583, 0.9083, 0.9125, 0.9458, 0.9042, 0.9333, 0.9458, 0.9375, 0.8917, 0.8625, 0.8958, 0.925, 0.925, 0.95, 0.95, 0.875, 0.95, 0.9333, 0.9833, 0.9542, 0.925, 0.9583, 0.9542, 0.9375, 0.925, 0.9083, 0.9208, 0.9708, 0.925, 0.9833, 0.925, 0.9417, 0.925, 0.8917, 0.9333, 0.9542, 0.925, 0.9167, 0.8875, 0.9583, 0.95, 0.925, 0.9667, 0.8708, 0.9458, 0.9333, 0.9083, 0.9583, 0.9417, 0.9208, 0.95, 0.9583, 0.9083, 0.9333, 0.975, 0.9292, 0.9542, 0.9125, 0.9458, 0.9208, 0.9208, 0.9583, 0.95, 0.9667, 0.9417, 0.8875, 0.925, 0.9083, 0.9625, 0.9167, 0.9292, 0.9583, 0.9292, 0.9208, 0.925, 0.9542, 0.8875, 0.9125, 0.9667, 0.9333, 0.9417, 0.9458, 0.9208, 0.8542, 0.9417, 0.9083, 0.9042, 0.9417, 0.9667, 0.95, 0.925, 0.9375, 0.9, 0.875, 0.9625, 0.9792, 0.9375, 0.8333, 0.9417, 0.9542, 0.875, 0.875, 0.9583, 0.9417, 0.9125, 0.9875, 0.9958, 0.9625, 0.9417, 0.9458, 0.9458, 0.9542, 0.8958, 0.9125, 0.9, 0.9125, 0.9833, 0.9333, 0.9542, 0.9542, 0.9458, 0.9625, 0.9458, 0.9708, 1.0, 0.9875, 1.0, 0.9917, 0.9583, 0.9875]\n",
      "\n",
      "Epoch 6/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.1074, 0.06861, 0.12346, 0.16572, 0.19751, 0.15397, 0.19522, 0.09769, 0.07793, 0.10236, 0.11256, 0.08271, 0.13709, 0.10065, 0.08645, 0.10457, 0.20076, 0.06274, 0.15415, 0.13035, 0.14771, 0.20123, 0.11762, 0.35824, 0.13082, 0.04693, 0.15365, 0.11319, 0.09722, 0.20756, 0.11444, 0.16824, 0.11068, 0.25624, 0.19169, 0.25073, 0.27459, 0.12609, 0.13266, 0.16434, 0.0484, 0.07022, 0.2266, 0.06401, 0.17943, 0.11122, 0.10853, 0.21967, 0.17725, 0.08947, 0.07911, 0.09582, 0.07157, 0.20472, 0.20377, 0.08675, 0.17988, 0.27651, 0.25836, 0.23588, 0.14984, 0.1217, 0.18287, 0.23356, 0.09189, 0.12174, 0.25915, 0.10465, 0.09447, 0.23169, 0.27607, 0.10575, 0.24177, 0.17098, 0.19736, 0.14328, 0.09079, 0.30686, 0.05961, 0.06423, 0.12343, 0.05246, 0.1385, 0.14781, 0.16574, 0.04048, 0.24366, 0.27874, 0.07252, 0.08183, 0.06819, 0.07301, 0.16821, 0.20635, 0.23753, 0.04492, 0.08764, 0.07426, 0.07873, 0.15205, 0.15731, 0.24319, 0.12427, 0.26653, 0.04785, 0.11176, 0.17957, 0.19215, 0.11156, 0.17336, 0.20463, 0.20355, 0.1177, 0.13017, 0.12556, 0.08695, 0.15913, 0.17252, 0.38469, 0.11963, 0.08188, 0.14952, 0.16541, 0.15976, 0.18997, 0.2, 0.11951, 0.11745, 0.1584, 0.20139, 0.1979, 0.1641, 0.10662, 0.08054, 0.16169, 0.27938, 0.12013, 0.14832, 0.06094, 0.06975, 0.15442, 0.08261, 0.16513, 0.14271, 0.18965, 0.27296, 0.12267, 0.06244, 0.15166, 0.05841, 0.15549, 0.13631, 0.25459, 0.2197, 0.15643, 0.11098, 0.13553, 0.22731, 0.16102, 0.15543, 0.11723, 0.21253, 0.07651, 0.25725, 0.17625, 0.15266, 0.19803, 0.15081, 0.15641, 0.15991, 0.08463, 0.14162, 0.25208, 0.10878, 0.09365, 0.12042, 0.13023, 0.23452, 0.13409, 0.15505, 0.15865, 0.15598, 0.09161, 0.11882, 0.13409, 0.19404, 0.24064, 0.21007, 0.10701, 0.21974, 0.18182, 0.10171, 0.12017, 0.21638, 0.13025, 0.11846, 0.16576, 0.18613, 0.17133, 0.18281, 0.13389, 0.10676, 0.19518, 0.37715, 0.09146, 0.21421, 0.20896, 0.11602, 0.09749, 0.0917, 0.18684, 0.09449, 0.25536, 0.25863, 0.09323, 0.0558, 0.1411, 0.42545, 0.13102, 0.10726, 0.25302, 0.2475, 0.08158, 0.10625, 0.24293, 0.06518, 0.025, 0.18471, 0.16272, 0.14776, 0.11814, 0.07114, 0.20081, 0.1613, 0.21557, 0.14126, 0.08129, 0.12732, 0.11158, 0.12106, 0.13751, 0.09883, 0.07116, 0.036, 0.00988, 0.04479, 0.01696, 0.02835, 0.07226, 0.03629]\n",
      "    Avg Accuracies: [0.975, 0.9833, 0.95, 0.9458, 0.9458, 0.9583, 0.9542, 0.975, 0.9833, 0.9708, 0.975, 0.975, 0.9583, 0.9792, 0.9833, 0.9583, 0.9542, 0.9792, 0.9542, 0.9583, 0.9667, 0.95, 0.9708, 0.8792, 0.9542, 0.9875, 0.9458, 0.9667, 0.9833, 0.9208, 0.9792, 0.9458, 0.9792, 0.9167, 0.9583, 0.9208, 0.9042, 0.9625, 0.9458, 0.95, 0.9875, 0.9875, 0.9333, 0.9792, 0.9417, 0.9708, 0.975, 0.9333, 0.9542, 0.975, 0.9833, 0.9792, 0.9792, 0.9208, 0.9458, 0.9708, 0.9583, 0.8958, 0.925, 0.9167, 0.95, 0.9625, 0.9542, 0.9167, 0.9792, 0.975, 0.925, 0.9708, 0.975, 0.9125, 0.9083, 0.975, 0.9125, 0.9542, 0.9375, 0.9542, 0.9708, 0.9208, 0.9958, 0.9875, 0.9667, 0.9875, 0.95, 0.95, 0.9542, 1.0, 0.9375, 0.9042, 0.9917, 0.9875, 0.9833, 0.9792, 0.95, 0.925, 0.9083, 0.9917, 0.9917, 0.9833, 0.9833, 0.9625, 0.9417, 0.9208, 0.975, 0.9167, 0.9958, 0.9708, 0.9458, 0.925, 0.9583, 0.9583, 0.925, 0.9333, 0.9667, 0.9583, 0.9625, 0.9792, 0.9458, 0.9667, 0.9083, 0.975, 0.9833, 0.9625, 0.9333, 0.9583, 0.9417, 0.9458, 0.975, 0.9833, 0.9583, 0.9375, 0.95, 0.95, 0.9667, 0.9958, 0.9542, 0.9125, 0.9667, 0.9583, 0.9875, 0.9875, 0.95, 0.9833, 0.9458, 0.9583, 0.9292, 0.8917, 0.9583, 0.9833, 0.95, 0.9917, 0.9583, 0.975, 0.9125, 0.9333, 0.95, 0.9667, 0.9708, 0.9292, 0.9625, 0.9542, 0.9708, 0.9292, 0.9792, 0.9208, 0.9583, 0.9458, 0.9333, 0.9625, 0.9583, 0.9625, 0.9792, 0.9542, 0.9292, 0.9708, 0.975, 0.9583, 0.9667, 0.9167, 0.9708, 0.9583, 0.9458, 0.9458, 0.9708, 0.9667, 0.9667, 0.9125, 0.925, 0.925, 0.9792, 0.9292, 0.9417, 0.9625, 0.9625, 0.9375, 0.9542, 0.9708, 0.9458, 0.9417, 0.95, 0.9458, 0.9625, 0.9667, 0.9542, 0.8625, 0.975, 0.9375, 0.9167, 0.9583, 0.975, 0.975, 0.95, 0.975, 0.9208, 0.9167, 0.9833, 0.9833, 0.95, 0.8417, 0.9542, 0.9708, 0.9208, 0.9375, 0.9708, 0.9667, 0.9375, 0.9792, 0.9958, 0.9458, 0.9542, 0.95, 0.9667, 0.9917, 0.9292, 0.9583, 0.9417, 0.9625, 0.975, 0.975, 0.9625, 0.9583, 0.9583, 0.9708, 0.975, 0.9958, 1.0, 0.9958, 1.0, 1.0, 0.9792, 0.9917]\n",
      "\n",
      "Epoch 7/9             \n",
      "    Avg Losses: [0.05834, 0.07073, 0.08048, 0.0759, 0.14767, 0.09428, 0.11831, 0.10729, 0.03594, 0.07484, 0.07501, 0.07809, 0.09248, 0.08953, 0.08009, 0.07049, 0.14388, 0.03598, 0.15169, 0.15071, 0.11598, 0.15116, 0.09223, 0.36379, 0.07085, 0.04353, 0.06343, 0.07612, 0.04899, 0.13912, 0.08442, 0.12489, 0.0824, 0.17956, 0.15062, 0.21212, 0.15246, 0.08065, 0.08215, 0.11845, 0.02238, 0.06818, 0.15697, 0.03919, 0.11609, 0.06766, 0.06923, 0.11172, 0.13619, 0.11812, 0.05342, 0.0876, 0.05018, 0.1313, 0.15327, 0.04041, 0.12113, 0.13546, 0.15777, 0.15275, 0.14181, 0.10206, 0.13484, 0.16352, 0.05864, 0.10252, 0.16425, 0.03554, 0.05875, 0.17418, 0.19658, 0.07786, 0.14367, 0.10612, 0.0971, 0.11461, 0.0907, 0.2055, 0.04447, 0.03827, 0.07336, 0.03706, 0.0885, 0.08657, 0.126, 0.02235, 0.14939, 0.22467, 0.04491, 0.09874, 0.0461, 0.05186, 0.12512, 0.1645, 0.17344, 0.02844, 0.07946, 0.03392, 0.05917, 0.11527, 0.0802, 0.15363, 0.11929, 0.19921, 0.03987, 0.05793, 0.17483, 0.11212, 0.10692, 0.12291, 0.13778, 0.10341, 0.09604, 0.1003, 0.09441, 0.05403, 0.10099, 0.15354, 0.28305, 0.11088, 0.04798, 0.1122, 0.13166, 0.08073, 0.12489, 0.09768, 0.07056, 0.06527, 0.13248, 0.17388, 0.15234, 0.16698, 0.07931, 0.07689, 0.09468, 0.15971, 0.11923, 0.08494, 0.05096, 0.05187, 0.10946, 0.05173, 0.15078, 0.1079, 0.12467, 0.2051, 0.0606, 0.05401, 0.16609, 0.02451, 0.09028, 0.08953, 0.18718, 0.13081, 0.09895, 0.11189, 0.07356, 0.16424, 0.09883, 0.10579, 0.0776, 0.22257, 0.04689, 0.11436, 0.14386, 0.0782, 0.10371, 0.09548, 0.07656, 0.13586, 0.04533, 0.07454, 0.17704, 0.07637, 0.0433, 0.12472, 0.09634, 0.19315, 0.09896, 0.0981, 0.10884, 0.10397, 0.07847, 0.07226, 0.07676, 0.14141, 0.13027, 0.13495, 0.0685, 0.1397, 0.10998, 0.07403, 0.08882, 0.13826, 0.04973, 0.0772, 0.14502, 0.12779, 0.09463, 0.13722, 0.08809, 0.05982, 0.14221, 0.22883, 0.05096, 0.1913, 0.15535, 0.07329, 0.06091, 0.08171, 0.13454, 0.03971, 0.15647, 0.13097, 0.0622, 0.02898, 0.10545, 0.27597, 0.08479, 0.07293, 0.21859, 0.19562, 0.04432, 0.11077, 0.12891, 0.06556, 0.01394, 0.08003, 0.1312, 0.10313, 0.08052, 0.05752, 0.13542, 0.12504, 0.13415, 0.1129, 0.04563, 0.08184, 0.06876, 0.11056, 0.15029, 0.05929, 0.03263, 0.01289, 0.0053, 0.01961, 0.00476, 0.02047, 0.04663, 0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Accuracies: [0.9875, 0.9833, 0.975, 0.9875, 0.9458, 0.975, 0.9708, 0.9583, 0.9958, 0.975, 0.9833, 0.9875, 0.975, 0.9792, 0.9792, 0.975, 0.9375, 0.9958, 0.95, 0.9542, 0.9708, 0.95, 0.9792, 0.8958, 0.9792, 0.9917, 0.9958, 0.9875, 0.9875, 0.9583, 0.9667, 0.9625, 0.9833, 0.9333, 0.9583, 0.9458, 0.9583, 0.975, 0.9875, 0.9667, 1.0, 0.9833, 0.9667, 0.9917, 0.9708, 0.9792, 0.9833, 0.9667, 0.9667, 0.9667, 0.9875, 0.9708, 0.9875, 0.9542, 0.9417, 0.9917, 0.975, 0.9708, 0.9375, 0.9542, 0.9583, 0.9625, 0.9458, 0.95, 0.9958, 0.9708, 0.9583, 1.0, 0.9917, 0.925, 0.9333, 0.975, 0.9625, 0.9792, 0.975, 0.9667, 0.9792, 0.9375, 0.9875, 0.9958, 0.9875, 0.9917, 0.9875, 0.9792, 0.9708, 1.0, 0.9375, 0.9208, 0.9917, 0.9667, 0.9833, 0.9875, 0.9625, 0.9583, 0.9458, 1.0, 0.9792, 1.0, 0.9833, 0.9625, 0.9833, 0.9792, 0.9667, 0.925, 0.9958, 0.9917, 0.9583, 0.9833, 0.9625, 0.9625, 0.95, 0.975, 0.9667, 0.9792, 0.9833, 0.9917, 0.975, 0.9458, 0.9375, 0.9583, 0.9917, 0.9708, 0.9667, 0.9792, 0.9708, 0.9833, 0.9917, 0.9875, 0.9583, 0.9458, 0.9625, 0.9542, 0.9833, 0.9875, 0.975, 0.9417, 0.9708, 0.975, 0.9833, 0.9917, 0.975, 0.9875, 0.9583, 0.9708, 0.9542, 0.9292, 0.9917, 0.9833, 0.95, 1.0, 0.975, 0.975, 0.9417, 0.9708, 0.9792, 0.9542, 0.9833, 0.95, 0.9792, 0.9708, 0.975, 0.9333, 0.9875, 0.975, 0.9458, 0.9792, 0.9708, 0.9792, 0.9833, 0.9417, 0.9917, 0.9833, 0.9542, 0.9792, 0.9917, 0.9542, 0.9792, 0.9375, 0.9708, 0.9792, 0.9625, 0.9708, 0.9792, 0.9792, 0.9792, 0.95, 0.9625, 0.9625, 0.9833, 0.9625, 0.9708, 0.9708, 0.9833, 0.9625, 0.9917, 0.9708, 0.95, 0.9583, 0.975, 0.9583, 0.975, 0.9833, 0.9542, 0.9292, 0.9917, 0.9375, 0.9417, 0.9917, 0.9917, 0.975, 0.975, 1.0, 0.95, 0.975, 0.9917, 0.9958, 0.975, 0.9042, 0.9708, 0.9833, 0.9167, 0.9375, 0.9958, 0.9708, 0.975, 0.9792, 1.0, 0.9792, 0.95, 0.9708, 0.975, 0.9875, 0.9542, 0.9625, 0.9792, 0.9708, 0.9917, 0.9792, 0.9875, 0.975, 0.9542, 0.9875, 0.9917, 1.0, 1.0, 1.0, 1.0, 0.9958, 0.9875, 0.9958]\n",
      "\n",
      "Epoch 8/9             \n",
      "    Avg Losses: [0.03995, 0.06138, 0.05498, 0.05937, 0.11938, 0.07282, 0.07717, 0.07598, 0.0328, 0.05675, 0.07413, 0.03702, 0.05234, 0.07359, 0.07446, 0.0746, 0.07749, 0.02935, 0.14579, 0.09662, 0.12711, 0.10189, 0.0497, 0.21912, 0.05037, 0.0205, 0.05565, 0.06114, 0.03264, 0.08392, 0.07822, 0.09292, 0.06347, 0.09481, 0.1171, 0.2332, 0.14281, 0.06555, 0.04709, 0.07495, 0.01685, 0.0476, 0.13112, 0.02001, 0.09626, 0.05094, 0.04171, 0.06314, 0.1165, 0.10141, 0.02434, 0.0374, 0.02496, 0.10846, 0.09782, 0.0238, 0.07472, 0.09936, 0.10416, 0.1223, 0.07706, 0.06268, 0.07891, 0.12508, 0.03365, 0.08217, 0.09688, 0.03177, 0.02443, 0.11464, 0.12332, 0.06809, 0.13529, 0.07142, 0.08337, 0.05866, 0.04461, 0.12817, 0.02156, 0.02411, 0.0524, 0.01627, 0.04943, 0.03875, 0.07297, 0.01777, 0.09158, 0.13959, 0.03528, 0.07452, 0.02217, 0.03994, 0.08074, 0.08782, 0.1042, 0.01736, 0.07006, 0.03164, 0.0486, 0.11163, 0.06635, 0.09998, 0.068, 0.11482, 0.02153, 0.03899, 0.13006, 0.0628, 0.08252, 0.08704, 0.17663, 0.06378, 0.0408, 0.05339, 0.07034, 0.0236, 0.06104, 0.08616, 0.2355, 0.07392, 0.03414, 0.06694, 0.09499, 0.04154, 0.11153, 0.0771, 0.04675, 0.0294, 0.06559, 0.07837, 0.12188, 0.10273, 0.04103, 0.05286, 0.0487, 0.09375, 0.08765, 0.05744, 0.04908, 0.03623, 0.0719, 0.04638, 0.07608, 0.05198, 0.08194, 0.12852, 0.04903, 0.03436, 0.08959, 0.01384, 0.05898, 0.05709, 0.1222, 0.08174, 0.06904, 0.06084, 0.05599, 0.10831, 0.04885, 0.06426, 0.06475, 0.16402, 0.01858, 0.09896, 0.15506, 0.04645, 0.08111, 0.06223, 0.04179, 0.09051, 0.0742, 0.07673, 0.13776, 0.04493, 0.0399, 0.05137, 0.06763, 0.20949, 0.0689, 0.06095, 0.06468, 0.07184, 0.05409, 0.03921, 0.04776, 0.07128, 0.09299, 0.13289, 0.07977, 0.13021, 0.06899, 0.07904, 0.05563, 0.08938, 0.02413, 0.053, 0.12936, 0.09618, 0.06279, 0.07425, 0.06659, 0.05267, 0.11526, 0.15349, 0.0441, 0.17026, 0.10549, 0.04128, 0.03372, 0.07905, 0.06935, 0.01918, 0.09003, 0.1027, 0.0399, 0.02168, 0.05443, 0.1782, 0.05931, 0.04588, 0.1977, 0.15837, 0.02162, 0.07528, 0.10893, 0.05143, 0.00993, 0.04827, 0.11693, 0.07694, 0.05161, 0.03519, 0.11815, 0.08425, 0.09932, 0.0721, 0.03496, 0.02968, 0.02931, 0.0467, 0.11012, 0.04319, 0.01513, 0.00854, 0.00315, 0.00905, 0.00289, 0.02576, 0.03286, 0.01304]\n",
      "    Avg Accuracies: [0.9958, 0.9875, 0.9875, 0.9875, 0.95, 0.9792, 0.9875, 0.9833, 0.9958, 0.9875, 0.9833, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.9875, 0.9917, 0.9458, 0.975, 0.9667, 0.9792, 0.9958, 0.925, 0.9917, 1.0, 0.9875, 0.9875, 0.9917, 0.9792, 0.9708, 0.9708, 0.9958, 0.9792, 0.9708, 0.9292, 0.9542, 0.9792, 0.9958, 0.9875, 0.9958, 0.9875, 0.9667, 1.0, 0.975, 0.9875, 0.9958, 0.9917, 0.975, 0.975, 0.9958, 0.9958, 1.0, 0.9625, 0.9708, 1.0, 0.9875, 0.9792, 0.9792, 0.975, 0.9792, 0.9917, 0.975, 0.9542, 0.9958, 0.9875, 0.9833, 0.9958, 1.0, 0.9625, 0.9583, 0.9833, 0.9583, 0.9917, 0.9792, 0.9875, 0.9833, 0.9625, 1.0, 1.0, 0.9875, 1.0, 0.9958, 0.9958, 0.9833, 1.0, 0.9792, 0.95, 0.9958, 0.9833, 0.9917, 0.9917, 0.9792, 0.975, 0.975, 1.0, 0.975, 0.9958, 0.9875, 0.9667, 0.9875, 0.9792, 0.9875, 0.9708, 1.0, 0.9917, 0.9583, 0.9917, 0.9792, 0.9833, 0.9542, 0.9875, 0.9958, 0.9958, 0.9875, 1.0, 0.9958, 0.9792, 0.9375, 0.975, 0.9917, 0.9875, 0.975, 1.0, 0.9667, 0.9875, 1.0, 1.0, 0.9875, 0.9917, 0.9625, 0.975, 0.9958, 0.9958, 0.9917, 0.9792, 0.9833, 0.9792, 0.9875, 0.9958, 0.9833, 0.9917, 0.9833, 0.9917, 0.9708, 0.9542, 0.9958, 0.9958, 0.9625, 1.0, 0.9958, 0.9833, 0.975, 0.9833, 0.9792, 0.975, 0.9917, 0.9708, 1.0, 0.9875, 0.9792, 0.95, 1.0, 0.9667, 0.9458, 0.9875, 0.9792, 0.9875, 0.9958, 0.9792, 0.9875, 0.9792, 0.9625, 0.9875, 0.9917, 0.9833, 0.9708, 0.925, 0.9875, 0.9875, 0.9875, 0.9875, 0.9875, 0.9958, 0.9958, 0.9917, 0.975, 0.9625, 0.9667, 0.9625, 0.9917, 0.9792, 0.9917, 0.9708, 1.0, 0.9917, 0.9583, 0.9833, 0.9792, 0.9875, 0.9792, 0.9917, 0.9625, 0.9708, 0.9958, 0.9417, 0.9667, 0.9958, 1.0, 0.9833, 0.9917, 1.0, 0.975, 0.9792, 0.9958, 0.9958, 0.9792, 0.9458, 0.9917, 0.9958, 0.9417, 0.9458, 1.0, 0.975, 0.9583, 0.9917, 1.0, 0.9917, 0.9667, 0.9792, 0.9958, 0.9958, 0.9667, 0.9708, 0.9792, 0.9875, 0.9917, 0.9958, 1.0, 0.9958, 0.975, 0.9917, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9917, 0.9958]\n",
      "\n",
      "Epoch 9/9             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Avg Losses: [0.031, 0.04517, 0.03066, 0.03853, 0.08106, 0.04407, 0.06208, 0.04161, 0.02878, 0.02693, 0.04314, 0.03276, 0.04891, 0.06261, 0.03742, 0.08305, 0.05574, 0.03059, 0.10272, 0.03446, 0.06582, 0.05777, 0.03435, 0.1887, 0.04476, 0.01933, 0.04384, 0.04694, 0.03277, 0.05583, 0.05274, 0.09152, 0.03383, 0.06364, 0.1063, 0.1065, 0.19398, 0.03162, 0.02038, 0.0596, 0.00964, 0.03247, 0.07761, 0.01417, 0.06868, 0.02896, 0.03351, 0.05543, 0.05676, 0.08458, 0.02304, 0.04318, 0.01237, 0.07209, 0.04412, 0.01501, 0.05284, 0.06108, 0.06457, 0.10537, 0.05127, 0.04609, 0.04659, 0.07577, 0.02377, 0.05176, 0.07767, 0.01572, 0.01738, 0.07799, 0.06597, 0.03406, 0.0525, 0.05407, 0.05392, 0.04268, 0.03771, 0.15664, 0.01386, 0.01508, 0.04156, 0.01018, 0.04226, 0.02449, 0.03742, 0.00893, 0.05948, 0.1312, 0.02544, 0.03908, 0.02674, 0.02006, 0.05536, 0.06879, 0.07012, 0.01602, 0.07654, 0.01529, 0.02497, 0.11268, 0.0302, 0.09495, 0.04479, 0.10638, 0.01686, 0.02393, 0.08488, 0.04661, 0.02749, 0.06641, 0.12874, 0.04362, 0.02517, 0.05219, 0.02334, 0.02221, 0.03114, 0.06032, 0.23028, 0.03474, 0.02968, 0.0466, 0.06812, 0.03595, 0.11087, 0.04011, 0.03, 0.01589, 0.04315, 0.07591, 0.08566, 0.08074, 0.03126, 0.02765, 0.02421, 0.06193, 0.05997, 0.0596, 0.01982, 0.02501, 0.04101, 0.02418, 0.05609, 0.03103, 0.07447, 0.07274, 0.05093, 0.03367, 0.05159, 0.00675, 0.03372, 0.04707, 0.09989, 0.06058, 0.061, 0.09375, 0.03587, 0.07384, 0.03385, 0.05388, 0.05259, 0.10005, 0.00975, 0.09722, 0.07278, 0.02836, 0.03875, 0.02731, 0.03048, 0.04656, 0.13625, 0.04393, 0.10021, 0.02846, 0.01842, 0.02962, 0.06903, 0.13464, 0.05086, 0.03399, 0.05068, 0.03873, 0.03096, 0.01933, 0.04217, 0.03607, 0.05568, 0.06465, 0.04528, 0.07891, 0.05279, 0.07048, 0.02688, 0.06526, 0.01308, 0.02978, 0.08042, 0.04495, 0.0594, 0.03799, 0.05027, 0.05807, 0.07308, 0.12716, 0.02783, 0.13948, 0.07017, 0.02369, 0.03052, 0.05152, 0.0431, 0.01497, 0.06522, 0.06046, 0.02532, 0.02166, 0.05024, 0.14869, 0.03732, 0.03691, 0.12954, 0.08095, 0.01484, 0.09324, 0.10394, 0.01863, 0.00498, 0.03746, 0.1049, 0.05475, 0.03008, 0.02111, 0.07793, 0.04338, 0.07822, 0.03546, 0.0212, 0.01903, 0.03422, 0.03515, 0.10482, 0.0291, 0.0174, 0.00404, 0.00224, 0.00635, 0.00237, 0.01455, 0.02026, 0.00679]\n",
      "    Avg Accuracies: [1.0, 0.9833, 0.9958, 1.0, 0.975, 0.9917, 0.9917, 0.9917, 0.9917, 0.9958, 0.9917, 0.9958, 0.9917, 0.9792, 0.9917, 0.975, 0.9833, 0.9958, 0.9625, 0.9958, 0.9792, 0.9917, 1.0, 0.9458, 0.9875, 0.9958, 0.9875, 0.9917, 1.0, 0.9875, 0.9875, 0.9667, 1.0, 1.0, 0.9583, 0.9667, 0.9333, 0.9958, 0.9958, 0.9917, 1.0, 0.9958, 0.9792, 1.0, 0.9792, 1.0, 0.9958, 0.9875, 0.9917, 0.9708, 1.0, 0.9958, 1.0, 0.9833, 0.9958, 1.0, 0.9917, 0.9875, 0.9875, 0.9708, 0.9833, 0.9958, 0.9875, 0.9875, 1.0, 0.9875, 0.9792, 1.0, 1.0, 0.975, 0.9833, 0.9917, 0.9917, 0.9875, 0.9917, 0.9917, 0.9917, 0.9542, 1.0, 1.0, 0.9875, 1.0, 0.9917, 1.0, 1.0, 1.0, 0.9917, 0.9625, 0.9958, 0.9875, 0.9917, 1.0, 0.9917, 0.9833, 0.9833, 1.0, 0.975, 1.0, 1.0, 0.9625, 0.9958, 0.975, 0.9917, 0.9667, 0.9958, 0.9958, 0.9667, 0.9917, 1.0, 0.9833, 0.9583, 0.9958, 0.9958, 0.9875, 1.0, 1.0, 1.0, 0.9875, 0.925, 0.9958, 0.9958, 0.9958, 0.9792, 0.9958, 0.9667, 0.9958, 0.9958, 1.0, 0.9958, 0.9833, 0.9833, 0.9833, 0.9958, 1.0, 1.0, 0.9917, 0.9875, 0.9833, 1.0, 1.0, 0.9958, 1.0, 0.9875, 1.0, 0.975, 0.9833, 0.9917, 0.9917, 0.9833, 1.0, 0.9917, 0.9917, 0.975, 0.9917, 0.9875, 0.9667, 0.9917, 0.9875, 0.9958, 0.9833, 0.9833, 0.975, 1.0, 0.975, 0.9833, 1.0, 0.9958, 1.0, 0.9958, 0.9958, 0.9542, 0.9958, 0.9667, 0.9958, 0.9958, 1.0, 0.9792, 0.95, 0.9958, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9875, 0.9917, 0.9958, 0.9792, 0.9958, 0.9875, 0.9833, 0.9792, 1.0, 0.9917, 1.0, 1.0, 0.975, 1.0, 0.9875, 0.9917, 0.9917, 0.9875, 0.9833, 0.9667, 1.0, 0.9583, 0.9917, 1.0, 0.9958, 0.9792, 0.9958, 1.0, 0.9875, 0.9917, 1.0, 0.9958, 0.9875, 0.9542, 0.9917, 0.9875, 0.9583, 0.9792, 1.0, 0.9625, 0.9667, 1.0, 1.0, 0.9958, 0.9583, 0.9917, 0.9958, 1.0, 0.9792, 1.0, 0.9875, 1.0, 0.9958, 1.0, 0.9875, 0.9958, 0.9667, 0.9958, 0.9958, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr         = 3e-2\n",
    "n_epochs   = 10\n",
    "batch_size = 30\n",
    "\n",
    "teacher_dataloaders = [data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True) for dataset in teacher_datasets]\n",
    "teacher_optimizers  = [optim.Adam(model.parameters(), lr=lr) for model in teachers]\n",
    "criterion           = nn.CrossEntropyLoss()\n",
    "\n",
    "for model in teachers:\n",
    "    model.train()\n",
    "\n",
    "teachers_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    avg_losses      = []\n",
    "    avg_accuracies  = []\n",
    "\n",
    "    for i_model in range(n_teachers):\n",
    "        instance_count = 0\n",
    "        total_loss     = 0.\n",
    "        correct_count  = 0\n",
    "\n",
    "        model      = teachers[i_model]\n",
    "        dataloader = teacher_dataloaders[i_model]\n",
    "        optimizer  = teacher_optimizers[i_model]\n",
    "\n",
    "        n_batches = len(dataloader)\n",
    "        _prev_str_len = 0\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            _batch_str = \"Teacher {:d}/{:d}: ({:d}/{:d})\".format(i_model, n_teachers-1, i, n_batches-1)\n",
    "            print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "            _prev_str_len = len(_batch_str)\n",
    "\n",
    "            instance_count += imgs.size(0)\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs  = model(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            \n",
    "            correct_count += (preds == labels).sum().item()\n",
    "\n",
    "        avg_losses.append(total_loss / instance_count)\n",
    "        avg_accuracies.append(correct_count / instance_count)\n",
    "\n",
    "    _epoch_str = \"Epoch {:d}/{:d}\".format(i_epoch, n_epochs-1)\n",
    "    _epoch_str += ' ' * (_prev_str_len - len(_epoch_str))\n",
    "    print(_epoch_str)\n",
    "    print(\"    Avg Losses:\", [round(avg_loss, 5) for avg_loss in avg_losses])\n",
    "    print(\"    Avg Accuracies:\", [round(avg_acc, 4) for avg_acc in avg_accuracies])\n",
    "    print()\n",
    "\n",
    "    teachers_train_history['avg_losses'][i_epoch]     = avg_losses\n",
    "    teachers_train_history['avg_accuracies'][i_epoch] = avg_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:07:47.310361Z",
     "start_time": "2019-06-23T13:07:47.303879Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def aggregate_counts(img):\n",
    "    assert 3 <= img.dim() <= 4\n",
    "    if img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    else:\n",
    "        assert img.size(0) == 1\n",
    "\n",
    "    img = img.to(device)\n",
    "\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in teachers:\n",
    "            model.eval()\n",
    "            preds_list.append(model(img).argmax(dim=1).view(1).cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(preds_list, dim=0)\n",
    "    \n",
    "    counts = torch.bincount(preds_tensor, minlength=10)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:07:49.275474Z",
     "start_time": "2019-06-23T13:07:47.313336Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/0 - Teacher 249/249\n",
      "\n",
      "Average Loss: 0.7388171423339843\n",
      "Average Accuracy: 0.815684\n",
      "\n",
      "Aggregate Accuracy: 0.9629999995231628\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "# Teacher Test\n",
    "if True:\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    preds_lists_list = []\n",
    "    labels_list      = []\n",
    "\n",
    "    n_batches = len(test_dataloader)\n",
    "    _prev_str_len = 0\n",
    "    for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels_list.append(labels)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for j, model in enumerate(teachers):\n",
    "                instance_count += imgs.size(0)\n",
    "\n",
    "                _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "                print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "                _prev_str_len = len(_progress_str)\n",
    "\n",
    "                outs  = model(imgs)\n",
    "                preds = outs.argmax(dim=1)\n",
    "                preds_list.append(preds.cpu())\n",
    "\n",
    "                total_loss += criterion(outs, labels).item()\n",
    "                correct_count += (preds == labels).sum().item()\n",
    "        preds_lists_list.append(preds_list)\n",
    "\n",
    "    preds_tensor = torch.cat([torch.stack(preds_list, dim=0) for preds_list in preds_lists_list], dim=1)\n",
    "    preds_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=preds_tensor.numpy()))\n",
    "\n",
    "    aggregate_preds = preds_counts.argmax(dim=0)\n",
    "    labels          = torch.cat(labels_list, dim=0)\n",
    "\n",
    "    aggregate_acc = (aggregate_preds == labels).float().mean().item()\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Average Loss:\", total_loss / instance_count)\n",
    "    print(\"Average Accuracy:\", correct_count / instance_count)\n",
    "    print()\n",
    "    print(\"Aggregate Accuracy:\", aggregate_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch 0/0 - Teacher 249/249\n",
    "\n",
    "Average Loss: 0.7504612662353516\n",
    "Average Accuracy: 0.814112\n",
    "\n",
    "Aggregate Accuracy: 0.9670000076293945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:08:10.737894Z",
     "start_time": "2019-06-23T13:07:49.276963Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/17 - Teacher 249/249\n",
      "tensor([[7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        ...,\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 4, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0]])\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "dataloader = data.DataLoader(student_dataset, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "batches_of_preds = []\n",
    "\n",
    "n_batches = len(dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, _) in enumerate(dataloader):\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    batch_of_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            batch_of_preds.append(preds.cpu())\n",
    "    \n",
    "    batches_of_preds.append(batch_of_preds)\n",
    "        \n",
    "label_preds = torch.cat(\n",
    "    [torch.stack([preds for preds in batch_of_preds], dim=0)\n",
    "     for batch_of_preds in batches_of_preds],\n",
    "    dim=1)\n",
    "\n",
    "print()\n",
    "print(label_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:08:10.806306Z",
     "start_time": "2019-06-23T13:08:10.739345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   0,  ...,   0,   1, 237],\n",
      "        [  0,   3, 248,  ...,   0,   0,   0],\n",
      "        [  0, 225,   0,  ...,   0,   2,   5],\n",
      "        ...,\n",
      "        [250,   0,   0,  ...,   0,  19,   0],\n",
      "        [  0,   6,   1,  ...,   0,   8,   2],\n",
      "        [  0,   0,   0,  ...,   0, 204,   0]])\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=label_preds.numpy()))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:08:10.832593Z",
     "start_time": "2019-06-23T13:08:10.809284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 6, 9, 0])\n",
      "\n",
      "Noisy Accuracy Against Predictions: 0.973111093044281\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "\n",
    "noise_dist = dists.Laplace(loc=torch.zeros([], dtype=torch.float),\n",
    "                           scale=torch.full([], 1 / epsilon, dtype=torch.float))\n",
    "\n",
    "noisy_counts = label_counts.float() + noise_dist.sample([10, label_counts.size(1)])\n",
    "\n",
    "generated_labels = noisy_counts.argmax(dim=0)\n",
    "print(generated_labels)\n",
    "print()\n",
    "print(\"Noisy Accuracy Against Predictions:\", (generated_labels == label_counts.argmax(dim=0)).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:41:25.929692Z",
     "start_time": "2019-06-22T14:41:25.926220Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:41:27.070385Z",
     "start_time": "2019-06-22T14:41:27.042094Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(max_train_subset_size, n_new_labels_per_epoch, n_updates_per_epoch, lr, weight_decay, epsilon):\n",
    "    spec_dict = {\n",
    "        \"max_size\": max_train_subset_size,\n",
    "        \"n_new_labels\": n_new_labels_per_epoch,\n",
    "        \"n_updates\": n_updates_per_epoch,\n",
    "        \"lr\": lr,\n",
    "        \"wd\": weight_decay,\n",
    "        \"eps\": epsilon\n",
    "    }\n",
    "\n",
    "    student = MNISTClassifier().to(device)\n",
    "    \n",
    "    laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "    init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "    n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "    student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "    student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "    student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "    student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                                   batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "    student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    for i_epoch in range(n_total_epochs):\n",
    "        if i_epoch == 0:\n",
    "            new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "        else:\n",
    "            max_probs_list = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, _ in student_unlabeled_dataloader:\n",
    "                    imgs = imgs.to(device)\n",
    "\n",
    "                    outs  = student(imgs)\n",
    "                    probs = outs.softmax(dim=1)\n",
    "\n",
    "                    max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "            max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "\n",
    "            new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                                 max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "        for idx in new_label_indices:\n",
    "            student_labeled_dataset.indices.append(idx)\n",
    "            student_unlabeled_dataset.indices.remove(idx)\n",
    "            label_pred_counts = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28))\n",
    "            noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "            mnist_testset.targets[idx] = noisy_label\n",
    "\n",
    "        student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "\n",
    "        for i_update in range(n_updates_per_epoch):\n",
    "            imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs  = student(imgs)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "            student_optimizer.zero_grad()\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "    student.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    for imgs, labels in test_dataloader:\n",
    "        instance_count += imgs.size(0)\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs  = student(imgs)\n",
    "\n",
    "        total_loss += criterion(outs, labels).item()\n",
    "\n",
    "        preds = outs.argmax(dim=1)\n",
    "\n",
    "        correct_count += (preds == labels).sum().item()\n",
    "\n",
    "    print(spec_dict)\n",
    "    print(\"    Average Loss:\", total_loss / instance_count)\n",
    "    print(\"    Average Accuracy:\", correct_count / instance_count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T10:14:30.677003Z",
     "start_time": "2019-06-22T18:53:40.077118Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.7401377468109132\n",
      "    Average Accuracy: 0.546\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6192414531707764\n",
      "    Average Accuracy: 0.598\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.3291448612213133\n",
      "    Average Accuracy: 0.42\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6666455268859863\n",
      "    Average Accuracy: 0.635\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.186118989944458\n",
      "    Average Accuracy: 0.576\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.083424431800842\n",
      "    Average Accuracy: 0.565\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.9740135078430177\n",
      "    Average Accuracy: 0.54\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.780796588897705\n",
      "    Average Accuracy: 0.614\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.333002468109131\n",
      "    Average Accuracy: 0.607\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.5493446760177614\n",
      "    Average Accuracy: 0.623\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.5529471187591555\n",
      "    Average Accuracy: 0.583\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 4.124790925979614\n",
      "    Average Accuracy: 0.577\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.4653964862823488\n",
      "    Average Accuracy: 0.461\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8325468455553054\n",
      "    Average Accuracy: 0.745\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0905081558227538\n",
      "    Average Accuracy: 0.686\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.141450685501099\n",
      "    Average Accuracy: 0.462\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.486404764175415\n",
      "    Average Accuracy: 0.639\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5598610877990722\n",
      "    Average Accuracy: 0.654\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.2102609958648682\n",
      "    Average Accuracy: 0.592\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.9464950733184814\n",
      "    Average Accuracy: 0.667\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.379995590209961\n",
      "    Average Accuracy: 0.527\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.405684555053711\n",
      "    Average Accuracy: 0.609\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.680110988616943\n",
      "    Average Accuracy: 0.526\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9180739040374757\n",
      "    Average Accuracy: 0.699\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.699709240436554\n",
      "    Average Accuracy: 0.64\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.3473614463806154\n",
      "    Average Accuracy: 0.453\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.454219192504883\n",
      "    Average Accuracy: 0.472\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4010999753475188\n",
      "    Average Accuracy: 0.682\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6387133526802062\n",
      "    Average Accuracy: 0.672\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 4.965353168487549\n",
      "    Average Accuracy: 0.486\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 4.2070146102905275\n",
      "    Average Accuracy: 0.608\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 9.85022982788086\n",
      "    Average Accuracy: 0.372\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.996346893310547\n",
      "    Average Accuracy: 0.55\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.1764465789794922\n",
      "    Average Accuracy: 0.579\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 6.2786216487884525\n",
      "    Average Accuracy: 0.472\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 5.748927448272705\n",
      "    Average Accuracy: 0.497\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.739273078918457\n",
      "    Average Accuracy: 0.521\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.862466100215912\n",
      "    Average Accuracy: 0.608\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1512760090827943\n",
      "    Average Accuracy: 0.702\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 4.137546363830566\n",
      "    Average Accuracy: 0.522\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.5253553619384768\n",
      "    Average Accuracy: 0.607\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.8562746648788453\n",
      "    Average Accuracy: 0.624\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.9841701126098634\n",
      "    Average Accuracy: 0.631\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 6.172054733276367\n",
      "    Average Accuracy: 0.455\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9455275030136108\n",
      "    Average Accuracy: 0.68\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.9135834350585936\n",
      "    Average Accuracy: 0.6\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.783567737579346\n",
      "    Average Accuracy: 0.53\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 6.999378635406494\n",
      "    Average Accuracy: 0.428\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.8460706520080565\n",
      "    Average Accuracy: 0.516\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6499288291931153\n",
      "    Average Accuracy: 0.489\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7608674087524414\n",
      "    Average Accuracy: 0.506\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5292851343154907\n",
      "    Average Accuracy: 0.619\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.4454770641326906\n",
      "    Average Accuracy: 0.472\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average Loss: 1.9830959701538087\n",
      "    Average Accuracy: 0.511\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.449305709838867\n",
      "    Average Accuracy: 0.587\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.409902581214905\n",
      "    Average Accuracy: 0.544\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7087656302452088\n",
      "    Average Accuracy: 0.633\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.440125967025757\n",
      "    Average Accuracy: 0.606\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.882114326477051\n",
      "    Average Accuracy: 0.492\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.2087627201080324\n",
      "    Average Accuracy: 0.582\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6133767528533935\n",
      "    Average Accuracy: 0.533\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2733058438301086\n",
      "    Average Accuracy: 0.623\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.6329941082000732\n",
      "    Average Accuracy: 0.582\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.151214666366577\n",
      "    Average Accuracy: 0.636\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1950795941352845\n",
      "    Average Accuracy: 0.706\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.496966907501221\n",
      "    Average Accuracy: 0.586\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.257553406715393\n",
      "    Average Accuracy: 0.559\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.4931689224243163\n",
      "    Average Accuracy: 0.621\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.2408401489257814\n",
      "    Average Accuracy: 0.579\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.866673231124878\n",
      "    Average Accuracy: 0.59\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.906812976360321\n",
      "    Average Accuracy: 0.648\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.3634278545379637\n",
      "    Average Accuracy: 0.522\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1720455741882325\n",
      "    Average Accuracy: 0.675\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.735775390625\n",
      "    Average Accuracy: 0.543\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.644306869506836\n",
      "    Average Accuracy: 0.592\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.78405620098114\n",
      "    Average Accuracy: 0.664\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.993754774093628\n",
      "    Average Accuracy: 0.66\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2295933485031127\n",
      "    Average Accuracy: 0.717\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6177977256774903\n",
      "    Average Accuracy: 0.662\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.4926607036590576\n",
      "    Average Accuracy: 0.6\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.3822066850662234\n",
      "    Average Accuracy: 0.595\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 6.246274265289307\n",
      "    Average Accuracy: 0.487\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.514245460510254\n",
      "    Average Accuracy: 0.489\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.8528312397003175\n",
      "    Average Accuracy: 0.632\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.1620253734588624\n",
      "    Average Accuracy: 0.565\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.8408157415390014\n",
      "    Average Accuracy: 0.599\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3804886322021483\n",
      "    Average Accuracy: 0.629\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4906978969573974\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6531211957931518\n",
      "    Average Accuracy: 0.654\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4277763624191284\n",
      "    Average Accuracy: 0.713\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.6254089164733885\n",
      "    Average Accuracy: 0.551\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.988618461608887\n",
      "    Average Accuracy: 0.578\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.6437946395874024\n",
      "    Average Accuracy: 0.666\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.7008828010559083\n",
      "    Average Accuracy: 0.67\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.199667224884033\n",
      "    Average Accuracy: 0.602\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 4.389561170578003\n",
      "    Average Accuracy: 0.555\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6896837186813354\n",
      "    Average Accuracy: 0.535\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.06330926322937\n",
      "    Average Accuracy: 0.425\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.6936836395263672\n",
      "    Average Accuracy: 0.438\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.606799313545227\n",
      "    Average Accuracy: 0.603\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.243610842704773\n",
      "    Average Accuracy: 0.621\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1007434339523317\n",
      "    Average Accuracy: 0.675\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 4.408468597412109\n",
      "    Average Accuracy: 0.453\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.299236835479736\n",
      "    Average Accuracy: 0.466\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.154673433303833\n",
      "    Average Accuracy: 0.545\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.39579345703125\n",
      "    Average Accuracy: 0.504\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.576787998199463\n",
      "    Average Accuracy: 0.502\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 4.808572399139404\n",
      "    Average Accuracy: 0.445\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0773349990844727\n",
      "    Average Accuracy: 0.641\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.391078387737274\n",
      "    Average Accuracy: 0.583\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7164187660217285\n",
      "    Average Accuracy: 0.547\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0420264544487\n",
      "    Average Accuracy: 0.701\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.8005458850860596\n",
      "    Average Accuracy: 0.549\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2012626948356628\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.000740716934204\n",
      "    Average Accuracy: 0.532\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5548620681762695\n",
      "    Average Accuracy: 0.658\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.450326234817505\n",
      "    Average Accuracy: 0.528\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.209861078262329\n",
      "    Average Accuracy: 0.579\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.684038444519043\n",
      "    Average Accuracy: 0.647\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5319290475845337\n",
      "    Average Accuracy: 0.684\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5864994974136353\n",
      "    Average Accuracy: 0.524\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2634576168060303\n",
      "    Average Accuracy: 0.589\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4656716279983522\n",
      "    Average Accuracy: 0.614\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.1655344400405885\n",
      "    Average Accuracy: 0.565\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.7414220790863038\n",
      "    Average Accuracy: 0.631\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.214033908843994\n",
      "    Average Accuracy: 0.544\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.567675819396973\n",
      "    Average Accuracy: 0.582\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.829150938034058\n",
      "    Average Accuracy: 0.519\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.8606939144134522\n",
      "    Average Accuracy: 0.663\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 4.692129467010498\n",
      "    Average Accuracy: 0.592\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.40466677570343\n",
      "    Average Accuracy: 0.586\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.274138696670532\n",
      "    Average Accuracy: 0.597\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.664393364429474\n",
      "    Average Accuracy: 0.555\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2376435079574586\n",
      "    Average Accuracy: 0.638\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3396145353317261\n",
      "    Average Accuracy: 0.619\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.624924771308899\n",
      "    Average Accuracy: 0.607\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.7176040687561036\n",
      "    Average Accuracy: 0.639\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4775474395751953\n",
      "    Average Accuracy: 0.649\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5868838682174682\n",
      "    Average Accuracy: 0.658\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.014406837463379\n",
      "    Average Accuracy: 0.664\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9518637607097626\n",
      "    Average Accuracy: 0.652\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.3777387866973876\n",
      "    Average Accuracy: 0.597\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.145638538837433\n",
      "    Average Accuracy: 0.561\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.329975799560547\n",
      "    Average Accuracy: 0.605\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.7870616264343262\n",
      "    Average Accuracy: 0.46\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4242882833480834\n",
      "    Average Accuracy: 0.51\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.343678524017334\n",
      "    Average Accuracy: 0.353\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.3812462120056153\n",
      "    Average Accuracy: 0.278\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.036198175430298\n",
      "    Average Accuracy: 0.547\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.100702226638794\n",
      "    Average Accuracy: 0.409\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.000119649887085\n",
      "    Average Accuracy: 0.546\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.524942892074585\n",
      "    Average Accuracy: 0.486\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.81928000831604\n",
      "    Average Accuracy: 0.521\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 4.313498237609863\n",
      "    Average Accuracy: 0.396\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.4954788513183592\n",
      "    Average Accuracy: 0.32\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 16.301899810791017\n",
      "    Average Accuracy: 0.198\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.917881534576416\n",
      "    Average Accuracy: 0.451\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.9557297954559325\n",
      "    Average Accuracy: 0.435\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7006924972534179\n",
      "    Average Accuracy: 0.44\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6362253456115723\n",
      "    Average Accuracy: 0.646\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average Loss: 1.7249375\n",
      "    Average Accuracy: 0.595\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.671211252212524\n",
      "    Average Accuracy: 0.432\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.7682519617080688\n",
      "    Average Accuracy: 0.616\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.35464435005188\n",
      "    Average Accuracy: 0.585\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.2872038650512696\n",
      "    Average Accuracy: 0.467\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.9423513832092287\n",
      "    Average Accuracy: 0.536\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.565483946800232\n",
      "    Average Accuracy: 0.578\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.359956970214844\n",
      "    Average Accuracy: 0.502\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2093828430175781\n",
      "    Average Accuracy: 0.694\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2022462253570556\n",
      "    Average Accuracy: 0.614\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7496028089523314\n",
      "    Average Accuracy: 0.447\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6210718536376953\n",
      "    Average Accuracy: 0.568\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2018890266418456\n",
      "    Average Accuracy: 0.641\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7644394817352296\n",
      "    Average Accuracy: 0.53\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.8013961668014526\n",
      "    Average Accuracy: 0.613\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.170860216140747\n",
      "    Average Accuracy: 0.643\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7742691535949706\n",
      "    Average Accuracy: 0.701\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.4608665704727173\n",
      "    Average Accuracy: 0.61\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.3524391040802004\n",
      "    Average Accuracy: 0.501\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.0606256484985352\n",
      "    Average Accuracy: 0.583\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1394178013801575\n",
      "    Average Accuracy: 0.677\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3626329898834229\n",
      "    Average Accuracy: 0.614\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.067189594268799\n",
      "    Average Accuracy: 0.452\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.477684356689453\n",
      "    Average Accuracy: 0.624\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6002735571861266\n",
      "    Average Accuracy: 0.606\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.6339126300811768\n",
      "    Average Accuracy: 0.572\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.9708129806518555\n",
      "    Average Accuracy: 0.637\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.369847855567932\n",
      "    Average Accuracy: 0.522\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.4028212938308715\n",
      "    Average Accuracy: 0.589\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.67425457239151\n",
      "    Average Accuracy: 0.692\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.0135597915649415\n",
      "    Average Accuracy: 0.678\n",
      "\n",
      "{'max_size': 50, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.1033689765930177\n",
      "    Average Accuracy: 0.593\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9750415241718292\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6581851801872254\n",
      "    Average Accuracy: 0.803\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8006666903495788\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4221329760551453\n",
      "    Average Accuracy: 0.694\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4670644130706787\n",
      "    Average Accuracy: 0.71\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3299939674139023\n",
      "    Average Accuracy: 0.716\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4833761839866637\n",
      "    Average Accuracy: 0.734\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.719645097732544\n",
      "    Average Accuracy: 0.711\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.346254835128784\n",
      "    Average Accuracy: 0.711\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2630223644971847\n",
      "    Average Accuracy: 0.815\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.087577736377716\n",
      "    Average Accuracy: 0.689\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5225937876701354\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9593718690872193\n",
      "    Average Accuracy: 0.776\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.076933711051941\n",
      "    Average Accuracy: 0.736\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2201423091888428\n",
      "    Average Accuracy: 0.691\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.3574774131774903\n",
      "    Average Accuracy: 0.632\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4565757570266724\n",
      "    Average Accuracy: 0.73\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9246183747053146\n",
      "    Average Accuracy: 0.801\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.5420462579727174\n",
      "    Average Accuracy: 0.658\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4712959384918214\n",
      "    Average Accuracy: 0.783\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.7688907852172853\n",
      "    Average Accuracy: 0.688\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.2719326028823854\n",
      "    Average Accuracy: 0.75\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.9050000867843628\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9419033735990525\n",
      "    Average Accuracy: 0.743\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0188584852218627\n",
      "    Average Accuracy: 0.769\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.7361435236930847\n",
      "    Average Accuracy: 0.718\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2476792407035828\n",
      "    Average Accuracy: 0.718\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.008960277557373\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.5009667797088624\n",
      "    Average Accuracy: 0.711\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3198235169649124\n",
      "    Average Accuracy: 0.742\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.7811973669528962\n",
      "    Average Accuracy: 0.773\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.111424388885498\n",
      "    Average Accuracy: 0.603\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7113081994056702\n",
      "    Average Accuracy: 0.775\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.9632327508926393\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.7248662676811217\n",
      "    Average Accuracy: 0.713\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.872545069694519\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.314836341381073\n",
      "    Average Accuracy: 0.755\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3404313926696778\n",
      "    Average Accuracy: 0.767\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9538179290294647\n",
      "    Average Accuracy: 0.803\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.7129923720359803\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.8947981462478638\n",
      "    Average Accuracy: 0.726\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3730684955120087\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.940996460914612\n",
      "    Average Accuracy: 0.708\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.604289806008339\n",
      "    Average Accuracy: 0.707\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.0839274511337282\n",
      "    Average Accuracy: 0.73\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.116428957104683\n",
      "    Average Accuracy: 0.686\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.746395433425904\n",
      "    Average Accuracy: 0.582\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.757439285516739\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.334320703983307\n",
      "    Average Accuracy: 0.65\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1002685136795043\n",
      "    Average Accuracy: 0.736\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.057018033504486\n",
      "    Average Accuracy: 0.702\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4311737070083619\n",
      "    Average Accuracy: 0.679\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7617567460536957\n",
      "    Average Accuracy: 0.793\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.962721785902977\n",
      "    Average Accuracy: 0.784\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.3534667797088622\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6178889503479004\n",
      "    Average Accuracy: 0.739\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.7167657798528673\n",
      "    Average Accuracy: 0.696\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.138036081314087\n",
      "    Average Accuracy: 0.659\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.33916737139225\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9198019230365753\n",
      "    Average Accuracy: 0.741\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9026922948360443\n",
      "    Average Accuracy: 0.769\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.404971701622009\n",
      "    Average Accuracy: 0.505\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.06618914437294\n",
      "    Average Accuracy: 0.72\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8935319614410401\n",
      "    Average Accuracy: 0.792\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.075047078371048\n",
      "    Average Accuracy: 0.763\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.048831045985222\n",
      "    Average Accuracy: 0.793\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6810428230464458\n",
      "    Average Accuracy: 0.769\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4291913909912108\n",
      "    Average Accuracy: 0.753\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5716447217464447\n",
      "    Average Accuracy: 0.754\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1859392564296722\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 4.1126876583099365\n",
      "    Average Accuracy: 0.645\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.2726873140335084\n",
      "    Average Accuracy: 0.613\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0588307313919068\n",
      "    Average Accuracy: 0.72\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3542578439712525\n",
      "    Average Accuracy: 0.738\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.050151355743408\n",
      "    Average Accuracy: 0.571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4294540231227875\n",
      "    Average Accuracy: 0.741\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.097004559993744\n",
      "    Average Accuracy: 0.794\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2301035461425782\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6357698297500611\n",
      "    Average Accuracy: 0.744\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.7134089258313179\n",
      "    Average Accuracy: 0.757\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.100827702522278\n",
      "    Average Accuracy: 0.775\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1860402212142944\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.419971049785614\n",
      "    Average Accuracy: 0.779\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1331275364160538\n",
      "    Average Accuracy: 0.808\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.0752022333145144\n",
      "    Average Accuracy: 0.621\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5211332537531852\n",
      "    Average Accuracy: 0.757\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4270554242134095\n",
      "    Average Accuracy: 0.725\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4924788010120391\n",
      "    Average Accuracy: 0.761\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5758857135772706\n",
      "    Average Accuracy: 0.693\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5588311338424683\n",
      "    Average Accuracy: 0.767\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5563422651290895\n",
      "    Average Accuracy: 0.797\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5392681437730789\n",
      "    Average Accuracy: 0.792\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.327008183479309\n",
      "    Average Accuracy: 0.773\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.5155947980880735\n",
      "    Average Accuracy: 0.739\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0564608807563782\n",
      "    Average Accuracy: 0.825\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.305237940311432\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7205443681478501\n",
      "    Average Accuracy: 0.778\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.953320220708847\n",
      "    Average Accuracy: 0.713\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9786933236122132\n",
      "    Average Accuracy: 0.712\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.885077163219452\n",
      "    Average Accuracy: 0.753\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8315945129394531\n",
      "    Average Accuracy: 0.757\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7663220491409302\n",
      "    Average Accuracy: 0.776\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8607121281623841\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1073813027143478\n",
      "    Average Accuracy: 0.782\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1202214064598084\n",
      "    Average Accuracy: 0.754\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.3733908615112305\n",
      "    Average Accuracy: 0.735\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 5.976042819976807\n",
      "    Average Accuracy: 0.517\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.1758412895202635\n",
      "    Average Accuracy: 0.674\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0614414955377578\n",
      "    Average Accuracy: 0.698\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9070538663864136\n",
      "    Average Accuracy: 0.771\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9929665086269379\n",
      "    Average Accuracy: 0.738\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0551306000351905\n",
      "    Average Accuracy: 0.726\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2234489269256592\n",
      "    Average Accuracy: 0.741\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2091707453131675\n",
      "    Average Accuracy: 0.72\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0246699721813202\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4573462152481078\n",
      "    Average Accuracy: 0.754\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1684706959724427\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5353944687843322\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.8128570880889892\n",
      "    Average Accuracy: 0.717\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.0584930000305177\n",
      "    Average Accuracy: 0.576\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9934162803888321\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.764778965473175\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7624887228012085\n",
      "    Average Accuracy: 0.602\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2568247785568238\n",
      "    Average Accuracy: 0.76\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9926958210468292\n",
      "    Average Accuracy: 0.765\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.199896785736084\n",
      "    Average Accuracy: 0.756\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5559327006340027\n",
      "    Average Accuracy: 0.746\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2980635466575623\n",
      "    Average Accuracy: 0.782\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2363315143585205\n",
      "    Average Accuracy: 0.779\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.9784038939476014\n",
      "    Average Accuracy: 0.736\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.1566335678100588\n",
      "    Average Accuracy: 0.649\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9763067915439605\n",
      "    Average Accuracy: 0.748\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.086678268313408\n",
      "    Average Accuracy: 0.742\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9244445152282715\n",
      "    Average Accuracy: 0.745\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.752202555179596\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9995389640331268\n",
      "    Average Accuracy: 0.78\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8388774127364159\n",
      "    Average Accuracy: 0.825\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2605889873504639\n",
      "    Average Accuracy: 0.734\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9305425201654434\n",
      "    Average Accuracy: 0.829\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1975964552164078\n",
      "    Average Accuracy: 0.796\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0126088511943818\n",
      "    Average Accuracy: 0.815\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.560208305358887\n",
      "    Average Accuracy: 0.679\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4356713585853578\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.2952133617401125\n",
      "    Average Accuracy: 0.719\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1877972383499145\n",
      "    Average Accuracy: 0.584\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1784650325775146\n",
      "    Average Accuracy: 0.597\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7503981971740723\n",
      "    Average Accuracy: 0.426\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.378961172103882\n",
      "    Average Accuracy: 0.661\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6057913987636566\n",
      "    Average Accuracy: 0.821\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8946481575965881\n",
      "    Average Accuracy: 0.729\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0277745604515076\n",
      "    Average Accuracy: 0.752\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2725520763397218\n",
      "    Average Accuracy: 0.655\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1975728335380553\n",
      "    Average Accuracy: 0.707\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.781513396501541\n",
      "    Average Accuracy: 0.674\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2758663992881776\n",
      "    Average Accuracy: 0.655\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9841248836517333\n",
      "    Average Accuracy: 0.585\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0235939235687257\n",
      "    Average Accuracy: 0.712\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0714775247573853\n",
      "    Average Accuracy: 0.667\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8246441392898559\n",
      "    Average Accuracy: 0.731\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0504113869667053\n",
      "    Average Accuracy: 0.744\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9949446091651917\n",
      "    Average Accuracy: 0.736\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.827784827709198\n",
      "    Average Accuracy: 0.804\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6803098773956299\n",
      "    Average Accuracy: 0.835\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8835886075496674\n",
      "    Average Accuracy: 0.76\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9508253991603851\n",
      "    Average Accuracy: 0.766\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.8229997024536133\n",
      "    Average Accuracy: 0.683\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6300734255313873\n",
      "    Average Accuracy: 0.781\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.000717458486557\n",
      "    Average Accuracy: 0.776\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8567557888031005\n",
      "    Average Accuracy: 0.733\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.014641704082489\n",
      "    Average Accuracy: 0.691\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9514933843612671\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2628440418243407\n",
      "    Average Accuracy: 0.709\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.719367561340332\n",
      "    Average Accuracy: 0.661\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.721762876033783\n",
      "    Average Accuracy: 0.803\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9969156160354614\n",
      "    Average Accuracy: 0.776\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3278131312131882\n",
      "    Average Accuracy: 0.715\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6706913588047028\n",
      "    Average Accuracy: 0.833\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2874602494239806\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2423923752307893\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.040746992111206\n",
      "    Average Accuracy: 0.807\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7754284819960594\n",
      "    Average Accuracy: 0.778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8879588589668274\n",
      "    Average Accuracy: 0.749\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9231351819038391\n",
      "    Average Accuracy: 0.726\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0679701032638549\n",
      "    Average Accuracy: 0.703\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7244054468870162\n",
      "    Average Accuracy: 0.806\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6762572232484817\n",
      "    Average Accuracy: 0.838\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5854909162521362\n",
      "    Average Accuracy: 0.716\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.9099354152679444\n",
      "    Average Accuracy: 0.664\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.8468182554244996\n",
      "    Average Accuracy: 0.688\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.505095962047577\n",
      "    Average Accuracy: 0.757\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1471535575389862\n",
      "    Average Accuracy: 0.802\n",
      "\n",
      "{'max_size': 100, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.19992169713974\n",
      "    Average Accuracy: 0.805\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1276212533712386\n",
      "    Average Accuracy: 0.732\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7545633151531219\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0308111337423325\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8130882151126861\n",
      "    Average Accuracy: 0.834\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9805161378383637\n",
      "    Average Accuracy: 0.835\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8180602387189865\n",
      "    Average Accuracy: 0.823\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2707763149738311\n",
      "    Average Accuracy: 0.805\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3046520529985428\n",
      "    Average Accuracy: 0.802\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4231336636543275\n",
      "    Average Accuracy: 0.789\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5152057060301305\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 4.191396586060524\n",
      "    Average Accuracy: 0.671\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9451418298482895\n",
      "    Average Accuracy: 0.856\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9552681005001068\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8858159122467041\n",
      "    Average Accuracy: 0.831\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7234485877752304\n",
      "    Average Accuracy: 0.806\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9414672276973725\n",
      "    Average Accuracy: 0.81\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.710857126712799\n",
      "    Average Accuracy: 0.732\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.741069515183568\n",
      "    Average Accuracy: 0.882\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.425255401134491\n",
      "    Average Accuracy: 0.832\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.7101113653182984\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.718550914645195\n",
      "    Average Accuracy: 0.8\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.9506439304351806\n",
      "    Average Accuracy: 0.786\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.392648244380951\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.2272984881997107\n",
      "    Average Accuracy: 0.797\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0783168948292732\n",
      "    Average Accuracy: 0.792\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8478757839202881\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7333453837484122\n",
      "    Average Accuracy: 0.856\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9891312444210052\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5257733371257782\n",
      "    Average Accuracy: 0.797\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1803908443450928\n",
      "    Average Accuracy: 0.822\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1746054836511612\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.5988534524440765\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.448469078361988\n",
      "    Average Accuracy: 0.863\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.071145367606543\n",
      "    Average Accuracy: 0.886\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 3.011624576091766\n",
      "    Average Accuracy: 0.75\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.9295496143698692\n",
      "    Average Accuracy: 0.828\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9770334135144949\n",
      "    Average Accuracy: 0.829\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9571684522628784\n",
      "    Average Accuracy: 0.824\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0256088345050811\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.078374433517456\n",
      "    Average Accuracy: 0.763\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2917996131181717\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3052386159896852\n",
      "    Average Accuracy: 0.815\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.6990147406458855\n",
      "    Average Accuracy: 0.788\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.409909659266472\n",
      "    Average Accuracy: 0.857\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 2.0123518241643907\n",
      "    Average Accuracy: 0.811\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 3.335244556427002\n",
      "    Average Accuracy: 0.721\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2559509642124176\n",
      "    Average Accuracy: 0.855\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 2, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 4.51027382183075\n",
      "    Average Accuracy: 0.743\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8500543215274811\n",
      "    Average Accuracy: 0.778\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6811417953968049\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.792516170501709\n",
      "    Average Accuracy: 0.804\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6222136490941048\n",
      "    Average Accuracy: 0.866\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7111735619306564\n",
      "    Average Accuracy: 0.821\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8888194392323494\n",
      "    Average Accuracy: 0.807\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6816632701158524\n",
      "    Average Accuracy: 0.873\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8764623494148255\n",
      "    Average Accuracy: 0.84\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6082711843252182\n",
      "    Average Accuracy: 0.876\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.42979203081131\n",
      "    Average Accuracy: 0.801\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9492549481391906\n",
      "    Average Accuracy: 0.811\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8949098281264305\n",
      "    Average Accuracy: 0.848\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7297157931923867\n",
      "    Average Accuracy: 0.847\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7027114564180375\n",
      "    Average Accuracy: 0.85\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8870828142166137\n",
      "    Average Accuracy: 0.807\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8157321981787682\n",
      "    Average Accuracy: 0.825\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0660973210334779\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0901397262886166\n",
      "    Average Accuracy: 0.81\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.153309254914522\n",
      "    Average Accuracy: 0.845\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.797487009525299\n",
      "    Average Accuracy: 0.741\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8846050744056702\n",
      "    Average Accuracy: 0.852\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.8827939224243164\n",
      "    Average Accuracy: 0.791\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.5118799810409547\n",
      "    Average Accuracy: 0.737\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4905409579277038\n",
      "    Average Accuracy: 0.783\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7871846654415131\n",
      "    Average Accuracy: 0.843\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9802232875823974\n",
      "    Average Accuracy: 0.769\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9397203896045685\n",
      "    Average Accuracy: 0.807\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5229047316908837\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0208034687042236\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8556043964028358\n",
      "    Average Accuracy: 0.834\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5166535762548448\n",
      "    Average Accuracy: 0.821\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.1678193795681\n",
      "    Average Accuracy: 0.84\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.3419692079424859\n",
      "    Average Accuracy: 0.844\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.0907375786304474\n",
      "    Average Accuracy: 0.849\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2195265591144562\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5124775227308274\n",
      "    Average Accuracy: 0.837\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9375044361352921\n",
      "    Average Accuracy: 0.817\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8653259665966034\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8198809475339949\n",
      "    Average Accuracy: 0.836\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1568825104236602\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9636828589439392\n",
      "    Average Accuracy: 0.838\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0117417174577712\n",
      "    Average Accuracy: 0.834\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.1273860733509062\n",
      "    Average Accuracy: 0.777\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.6260655899047851\n",
      "    Average Accuracy: 0.832\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.4626394300460814\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 2.056984129905701\n",
      "    Average Accuracy: 0.817\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 2.161579474449158\n",
      "    Average Accuracy: 0.791\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 150, 'n_new_labels': 3, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 3.0882794016897677\n",
      "    Average Accuracy: 0.73\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7720988602638245\n",
      "    Average Accuracy: 0.773\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.047406002998352\n",
      "    Average Accuracy: 0.743\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7022094553709031\n",
      "    Average Accuracy: 0.783\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6987470054030418\n",
      "    Average Accuracy: 0.817\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8359587993621826\n",
      "    Average Accuracy: 0.784\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5241292974948883\n",
      "    Average Accuracy: 0.688\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.187560102701187\n",
      "    Average Accuracy: 0.787\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.077162232875824\n",
      "    Average Accuracy: 0.791\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.740540633559227\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.015710990846157\n",
      "    Average Accuracy: 0.823\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.5682842112779617\n",
      "    Average Accuracy: 0.882\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9376655197143555\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.697198900103569\n",
      "    Average Accuracy: 0.807\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.5675485241413116\n",
      "    Average Accuracy: 0.852\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1988883512020112\n",
      "    Average Accuracy: 0.731\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.4555959045886993\n",
      "    Average Accuracy: 0.691\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.4639971660375595\n",
      "    Average Accuracy: 0.744\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.8979224321842194\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.1419762427806854\n",
      "    Average Accuracy: 0.818\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9417752112448216\n",
      "    Average Accuracy: 0.811\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7415118235349655\n",
      "    Average Accuracy: 0.856\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.5636202117055655\n",
      "    Average Accuracy: 0.788\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5052175296843051\n",
      "    Average Accuracy: 0.788\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.215744069337845\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6114923615455627\n",
      "    Average Accuracy: 0.852\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9185823655128479\n",
      "    Average Accuracy: 0.771\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9371127882003785\n",
      "    Average Accuracy: 0.755\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.5977588113546372\n",
      "    Average Accuracy: 0.867\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8503119456768036\n",
      "    Average Accuracy: 0.808\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5155527657270431\n",
      "    Average Accuracy: 0.734\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7162806534767151\n",
      "    Average Accuracy: 0.853\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8022681440114975\n",
      "    Average Accuracy: 0.848\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1546340864896774\n",
      "    Average Accuracy: 0.828\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8766504636406899\n",
      "    Average Accuracy: 0.867\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2658415902256965\n",
      "    Average Accuracy: 0.838\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1406691236495972\n",
      "    Average Accuracy: 0.809\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9460865397453309\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9720335608720779\n",
      "    Average Accuracy: 0.799\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.9727426415681839\n",
      "    Average Accuracy: 0.783\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9386158696711063\n",
      "    Average Accuracy: 0.806\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0916100006103515\n",
      "    Average Accuracy: 0.791\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.7424713733792305\n",
      "    Average Accuracy: 0.847\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9363485548496246\n",
      "    Average Accuracy: 0.848\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.094518774986267\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.7893558168411254\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.54615927028656\n",
      "    Average Accuracy: 0.79\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5058640765547753\n",
      "    Average Accuracy: 0.817\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 5, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2417908375263214\n",
      "    Average Accuracy: 0.86\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8019043555259705\n",
      "    Average Accuracy: 0.728\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0646213517189025\n",
      "    Average Accuracy: 0.75\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.5445747722387314\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.4674360640645027\n",
      "    Average Accuracy: 0.845\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.7000357268452644\n",
      "    Average Accuracy: 0.796\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6823592698574066\n",
      "    Average Accuracy: 0.791\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.980935721874237\n",
      "    Average Accuracy: 0.764\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6335765900611877\n",
      "    Average Accuracy: 0.827\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.2554666647911072\n",
      "    Average Accuracy: 0.747\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.6527966257333756\n",
      "    Average Accuracy: 0.843\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.2814258420467377\n",
      "    Average Accuracy: 0.778\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 10, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1801514310836791\n",
      "    Average Accuracy: 0.754\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7330874199867249\n",
      "    Average Accuracy: 0.778\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9710474441051483\n",
      "    Average Accuracy: 0.744\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.597863528907299\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.5413207726478577\n",
      "    Average Accuracy: 0.855\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.5983721254467964\n",
      "    Average Accuracy: 0.833\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0099417164325715\n",
      "    Average Accuracy: 0.726\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.166844783425331\n",
      "    Average Accuracy: 0.779\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6416290240287781\n",
      "    Average Accuracy: 0.855\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.928446500197053\n",
      "    Average Accuracy: 0.805\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8161423040628433\n",
      "    Average Accuracy: 0.822\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5959464535713195\n",
      "    Average Accuracy: 0.752\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 20, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.5101990355849266\n",
      "    Average Accuracy: 0.754\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.9354995114207267\n",
      "    Average Accuracy: 0.768\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.5887220791578293\n",
      "    Average Accuracy: 0.842\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6831031153202057\n",
      "    Average Accuracy: 0.826\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.130291190803051\n",
      "    Average Accuracy: 0.743\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.8620209544971585\n",
      "    Average Accuracy: 0.83\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.5667900562882423\n",
      "    Average Accuracy: 0.861\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.3229694335460662\n",
      "    Average Accuracy: 0.762\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.3306851124763488\n",
      "    Average Accuracy: 0.78\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6826640267372132\n",
      "    Average Accuracy: 0.865\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.806145710349083\n",
      "    Average Accuracy: 0.853\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.9079428038597107\n",
      "    Average Accuracy: 0.843\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 30, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6510312492847443\n",
      "    Average Accuracy: 0.873\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8032379841804504\n",
      "    Average Accuracy: 0.802\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6202567402124405\n",
      "    Average Accuracy: 0.819\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.005, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.6329331645965576\n",
      "    Average Accuracy: 0.845\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.7579023769497871\n",
      "    Average Accuracy: 0.833\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 0.6277668159604073\n",
      "    Average Accuracy: 0.869\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.01, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 0.42033066998422147\n",
      "    Average Accuracy: 0.892\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 0.8115568598508834\n",
      "    Average Accuracy: 0.842\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.5987836456298827\n",
      "    Average Accuracy: 0.751\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.02, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.0653335145115852\n",
      "    Average Accuracy: 0.812\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.05}\n",
      "    Average Loss: 1.2155409533977508\n",
      "    Average Accuracy: 0.786\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.07}\n",
      "    Average Loss: 1.0485830461978913\n",
      "    Average Accuracy: 0.816\n",
      "\n",
      "{'max_size': 150, 'n_new_labels': 10, 'n_updates': 40, 'lr': 0.03, 'wd': 0, 'eps': 0.1}\n",
      "    Average Loss: 1.1520790413022042\n",
      "    Average Accuracy: 0.827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_spec = {\n",
    "        \"max_train_subset_size\":  [50, 100, 150],\n",
    "        \"n_new_labels_per_epoch\": [2, 3, 5, 10],\n",
    "        \"n_updates_per_epoch\":    [10, 20, 30, 40],\n",
    "        \"lr\":                     [5e-3, 1e-2, 2e-2, 3e-2],\n",
    "        \"weight_decay\":           [0],\n",
    "        \"epsilon\":                [0.05, 0.07, 0.1]\n",
    "}\n",
    "\n",
    "spec_iter = itertools.product(grid_spec[\"max_train_subset_size\"],\n",
    "                              grid_spec[\"n_new_labels_per_epoch\"],\n",
    "                              grid_spec[\"n_updates_per_epoch\"],\n",
    "                              grid_spec[\"lr\"],\n",
    "                              grid_spec[\"weight_decay\"],\n",
    "                              grid_spec[\"epsilon\"])\n",
    "\n",
    "n_specs = np.prod([len(options) for options in grid_spec.values()])\n",
    "\n",
    "for i, spec in enumerate(spec_iter):\n",
    "    print(\"{:d}/{:d}\".format(i, n_specs-1), end='\\r')\n",
    "    train(*spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:08:10.848464Z",
     "start_time": "2019-06-23T13:08:10.835569Z"
    }
   },
   "outputs": [],
   "source": [
    "student = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:09:43.476347Z",
     "start_time": "2019-06-23T13:08:10.851441Z"
    },
    "code_folding": [
     26
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19 - Number of Labeled Data: 5\n",
      "    Update 0 - Loss = 2.220031, Accuracy = 0.0\n",
      "    Update 1 - Loss = 1.248176, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.754863, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.422651, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.251692, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.154266, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.085805, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.044131, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.023445, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.013550, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.008267, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005395, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003596, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002460, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.001749, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001303, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.000998, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.000784, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.000633, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.000517, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.000428, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.000360, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.000306, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.000262, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000228, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000201, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000178, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000160, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000145, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000131, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000120, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000111, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000103, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000096, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000090, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000084, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000080, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000076, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000072, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000068, Accuracy = 1.0\n",
      "Epoch 1/19 - Number of Labeled Data: 10\n",
      "    Update 0 - Loss = 3.997422, Accuracy = 0.6\n",
      "    Update 1 - Loss = 3.289622, Accuracy = 0.8\n",
      "    Update 2 - Loss = 2.601430, Accuracy = 0.8\n",
      "    Update 3 - Loss = 1.985002, Accuracy = 0.8\n",
      "    Update 4 - Loss = 1.427226, Accuracy = 0.8\n",
      "    Update 5 - Loss = 0.925052, Accuracy = 0.8\n",
      "    Update 6 - Loss = 0.515073, Accuracy = 0.8\n",
      "    Update 7 - Loss = 0.302755, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.362571, Accuracy = 0.9\n",
      "    Update 9 - Loss = 0.364725, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.272596, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.228725, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.189999, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.146279, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.110030, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.086975, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.072450, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.061406, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.051249, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.040915, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.031994, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.025212, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.019912, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.015652, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.012203, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.009779, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.007923, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.006552, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.005526, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004724, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004107, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003604, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003191, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.002843, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002547, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002290, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.002065, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001869, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001697, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001545, Accuracy = 1.0\n",
      "Epoch 2/19 - Number of Labeled Data: 15\n",
      "    Update 0 - Loss = 2.303638, Accuracy = 0.7333\n",
      "    Update 1 - Loss = 1.833592, Accuracy = 0.7333\n",
      "    Update 2 - Loss = 1.347206, Accuracy = 0.7333\n",
      "    Update 3 - Loss = 0.857326, Accuracy = 0.7333\n",
      "    Update 4 - Loss = 0.479797, Accuracy = 0.8667\n",
      "    Update 5 - Loss = 0.335739, Accuracy = 0.9333\n",
      "    Update 6 - Loss = 0.411127, Accuracy = 0.8\n",
      "    Update 7 - Loss = 0.386202, Accuracy = 0.8667\n",
      "    Update 8 - Loss = 0.285723, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.231981, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.207949, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.192151, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.181259, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.166752, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.141495, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.112482, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.085441, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.063176, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.046833, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.037770, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.032416, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.028962, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.024548, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.019386, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.014925, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.011311, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.008732, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.006925, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.005659, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.004740, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.004045, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.003509, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.003064, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.002687, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.002379, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.002123, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001903, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001716, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001559, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001429, Accuracy = 1.0\n",
      "Epoch 3/19 - Number of Labeled Data: 20\n",
      "    Update 0 - Loss = 0.917083, Accuracy = 0.8\n",
      "    Update 1 - Loss = 0.720564, Accuracy = 0.9\n",
      "    Update 2 - Loss = 0.523484, Accuracy = 0.9\n",
      "    Update 3 - Loss = 0.363599, Accuracy = 0.95\n",
      "    Update 4 - Loss = 0.241562, Accuracy = 0.95\n",
      "    Update 5 - Loss = 0.156218, Accuracy = 0.95\n",
      "    Update 6 - Loss = 0.088378, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.041571, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.032103, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.039972, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.047962, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.044076, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.032446, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.021519, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.015336, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.012125, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.010202, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.008915, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.007908, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.007050, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.006294, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.005549, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.004864, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.004266, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.003763, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.003326, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002949, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002628, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002359, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002134, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001939, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001768, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001622, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001495, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001384, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001290, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001208, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001137, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001074, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001019, Accuracy = 1.0\n",
      "Epoch 4/19 - Number of Labeled Data: 25\n",
      "    Update 0 - Loss = 0.341503, Accuracy = 0.84\n",
      "    Update 1 - Loss = 0.188876, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.083014, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.049759, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.036766, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.029317, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.028478, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 7 - Loss = 0.028449, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.026527, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.021562, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.016046, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.011540, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.008572, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.006749, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.005537, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004710, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004162, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003767, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003516, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003339, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003224, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003144, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003071, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002996, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002908, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002797, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002668, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002523, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002370, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002216, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.002067, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001931, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001806, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001691, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001587, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001494, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001409, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001334, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001267, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001208, Accuracy = 1.0\n",
      "Epoch 5/19 - Number of Labeled Data: 30\n",
      "    Update 0 - Loss = 0.339424, Accuracy = 0.8333\n",
      "    Update 1 - Loss = 0.161464, Accuracy = 0.9667\n",
      "    Update 2 - Loss = 0.082407, Accuracy = 0.9667\n",
      "    Update 3 - Loss = 0.058407, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.050695, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.036571, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.026241, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.020777, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.019962, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.019058, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.013414, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.008415, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.006055, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.005051, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004485, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004084, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003781, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003533, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003346, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003231, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003168, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.003115, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.003051, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002966, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002857, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.002730, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.002585, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.002430, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.002271, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.002119, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001974, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001840, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001721, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001610, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001508, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001416, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.001333, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.001257, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.001189, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.001128, Accuracy = 1.0\n",
      "Epoch 6/19 - Number of Labeled Data: 35\n",
      "    Update 0 - Loss = 0.298389, Accuracy = 0.8857\n",
      "    Update 1 - Loss = 0.157541, Accuracy = 0.9429\n",
      "    Update 2 - Loss = 0.055007, Accuracy = 0.9714\n",
      "    Update 3 - Loss = 0.023138, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.028245, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.035002, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.030033, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.022022, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.017001, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.014372, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.012353, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.009754, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.007011, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004901, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003744, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003217, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003031, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003024, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003104, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003155, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.003123, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002982, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002743, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002460, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.002183, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001950, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001758, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001609, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001491, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001397, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001323, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001256, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001195, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.001138, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.001083, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.001031, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000983, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000937, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000893, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000852, Accuracy = 1.0\n",
      "Epoch 7/19 - Number of Labeled Data: 40\n",
      "    Update 0 - Loss = 0.176331, Accuracy = 0.925\n",
      "    Update 1 - Loss = 0.092872, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.038208, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.015773, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.008310, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.007210, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.008091, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.008681, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.007708, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.005982, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004589, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003730, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003396, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003400, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003547, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003665, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003726, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003604, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003334, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002996, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002637, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002329, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002059, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001824, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001630, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001465, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001330, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001220, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001131, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001059, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001002, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000954, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000915, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000883, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000855, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000830, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000807, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000785, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000764, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000744, Accuracy = 1.0\n",
      "Epoch 8/19 - Number of Labeled Data: 45\n",
      "    Update 0 - Loss = 0.196851, Accuracy = 0.9111\n",
      "    Update 1 - Loss = 0.097570, Accuracy = 0.9778\n",
      "    Update 2 - Loss = 0.030127, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.010861, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.009489, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.016115, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.024016, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.025030, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.018503, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.011407, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.006819, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004298, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.002966, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002306, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 14 - Loss = 0.001915, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001692, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001565, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001499, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001473, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001486, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001520, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001556, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001568, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001548, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001499, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001425, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001337, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001244, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001153, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001069, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000994, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000926, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000867, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000816, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000772, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000734, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000700, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000670, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000643, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000618, Accuracy = 1.0\n",
      "Epoch 9/19 - Number of Labeled Data: 50\n",
      "    Update 0 - Loss = 0.181476, Accuracy = 0.92\n",
      "    Update 1 - Loss = 0.096396, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.041414, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.019175, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.019342, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.026595, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.018289, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.009817, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.006597, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.006417, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.006171, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005152, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003857, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002842, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002182, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001824, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001690, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001701, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001791, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001908, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002007, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002053, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002032, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001944, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001807, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001647, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001487, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001342, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001215, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001108, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001019, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000945, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000880, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000825, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000776, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000733, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000696, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000664, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000634, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000608, Accuracy = 1.0\n",
      "Epoch 10/19 - Number of Labeled Data: 55\n",
      "    Update 0 - Loss = 0.083737, Accuracy = 0.9636\n",
      "    Update 1 - Loss = 0.048305, Accuracy = 0.9818\n",
      "    Update 2 - Loss = 0.020567, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.009881, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.007012, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.006052, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.006838, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.008425, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.009216, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.008520, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.007177, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005855, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004835, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004028, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003372, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002818, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002358, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001996, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001734, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001538, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001386, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001253, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001130, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001017, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000922, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000846, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000786, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000740, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000705, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000678, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000657, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000641, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000625, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000610, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000593, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000575, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000556, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000538, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000519, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000500, Accuracy = 1.0\n",
      "Epoch 11/19 - Number of Labeled Data: 60\n",
      "    Update 0 - Loss = 0.249657, Accuracy = 0.9167\n",
      "    Update 1 - Loss = 0.125420, Accuracy = 0.95\n",
      "    Update 2 - Loss = 0.047726, Accuracy = 0.9833\n",
      "    Update 3 - Loss = 0.022426, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.016475, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.017969, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.024475, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.027833, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.016485, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.009411, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.006598, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005455, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.005027, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004793, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.004579, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.004271, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.003985, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.003637, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003294, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002943, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002615, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002320, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002042, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001803, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001608, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001452, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001326, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001225, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001143, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001074, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001011, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000954, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000899, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000850, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000805, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000761, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000721, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000682, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000647, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000613, Accuracy = 1.0\n",
      "Epoch 12/19 - Number of Labeled Data: 65\n",
      "    Update 0 - Loss = 0.443762, Accuracy = 0.9231\n",
      "    Update 1 - Loss = 0.294552, Accuracy = 0.9538\n",
      "    Update 2 - Loss = 0.175009, Accuracy = 0.9846\n",
      "    Update 3 - Loss = 0.128604, Accuracy = 0.9692\n",
      "    Update 4 - Loss = 0.065826, Accuracy = 0.9846\n",
      "    Update 5 - Loss = 0.037182, Accuracy = 0.9846\n",
      "    Update 6 - Loss = 0.060777, Accuracy = 0.9846\n",
      "    Update 7 - Loss = 0.034863, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.015755, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.013366, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.011682, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.008221, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.006279, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.005697, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.005416, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.005157, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.004823, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.004437, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.003938, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.003410, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002961, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 21 - Loss = 0.002630, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002374, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002140, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001901, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001656, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001436, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001251, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001108, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000995, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000906, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000835, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000779, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000734, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000697, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000666, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000638, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000614, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000592, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000573, Accuracy = 1.0\n",
      "Epoch 13/19 - Number of Labeled Data: 70\n",
      "    Update 0 - Loss = 0.171946, Accuracy = 0.9286\n",
      "    Update 1 - Loss = 0.104677, Accuracy = 0.9857\n",
      "    Update 2 - Loss = 0.047462, Accuracy = 0.9857\n",
      "    Update 3 - Loss = 0.014179, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.005027, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.006731, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.010197, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.012630, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.012323, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.010009, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.007540, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.005537, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004119, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003251, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002701, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002397, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002298, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002353, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002517, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002716, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002835, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002812, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.002612, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.002294, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001956, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001664, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001431, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001247, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001105, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000995, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000909, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000839, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000782, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000734, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000693, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000658, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000627, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000599, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000573, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000550, Accuracy = 1.0\n",
      "Epoch 14/19 - Number of Labeled Data: 75\n",
      "    Update 0 - Loss = 0.100570, Accuracy = 0.9467\n",
      "    Update 1 - Loss = 0.039866, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.012142, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.008107, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.012221, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.015260, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.012385, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.009551, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.007231, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.005570, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004800, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004225, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003602, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003018, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002498, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002104, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001834, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001664, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001535, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001432, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001333, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001233, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001132, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001040, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000959, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000890, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000828, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000775, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000730, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000689, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000653, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000621, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000592, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000566, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000542, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000520, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000500, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000482, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000464, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000449, Accuracy = 1.0\n",
      "Epoch 15/19 - Number of Labeled Data: 80\n",
      "    Update 0 - Loss = 0.095515, Accuracy = 0.95\n",
      "    Update 1 - Loss = 0.023324, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.005925, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.005250, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.010325, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.013345, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.008884, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.005115, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.003710, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.003409, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.003690, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.004040, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.004092, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.003790, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003330, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002905, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002595, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002407, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002296, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002222, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002158, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002074, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001973, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001849, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001713, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001584, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001465, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001361, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001272, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001199, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.001138, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.001084, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.001036, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000991, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000947, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000905, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000865, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000826, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000789, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000754, Accuracy = 1.0\n",
      "Epoch 16/19 - Number of Labeled Data: 85\n",
      "    Update 0 - Loss = 0.181924, Accuracy = 0.9647\n",
      "    Update 1 - Loss = 0.092524, Accuracy = 0.9647\n",
      "    Update 2 - Loss = 0.025021, Accuracy = 0.9882\n",
      "    Update 3 - Loss = 0.012039, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.017059, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.019195, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.016002, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.011415, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.008522, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.008165, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.008722, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.007324, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.005340, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.004251, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.003637, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.003163, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002791, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002546, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002395, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002286, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.002167, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.002029, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001854, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001673, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001497, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001336, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001196, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001076, Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Update 28 - Loss = 0.000980, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000910, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000859, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000821, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000795, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000775, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000757, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000738, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000718, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000696, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000672, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000647, Accuracy = 1.0\n",
      "Epoch 17/19 - Number of Labeled Data: 90\n",
      "    Update 0 - Loss = 0.164338, Accuracy = 0.9444\n",
      "    Update 1 - Loss = 0.104738, Accuracy = 0.9889\n",
      "    Update 2 - Loss = 0.054309, Accuracy = 0.9889\n",
      "    Update 3 - Loss = 0.011782, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.011469, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.031673, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.027237, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.011243, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.005975, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.004582, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.004226, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.003852, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.003198, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002526, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.001964, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001536, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001266, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001105, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001026, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001008, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001028, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001069, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001111, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001141, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001147, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001128, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001092, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001046, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000996, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000948, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000904, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000862, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000822, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000783, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000746, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000710, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000675, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000643, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000613, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000585, Accuracy = 1.0\n",
      "Epoch 18/19 - Number of Labeled Data: 95\n",
      "    Update 0 - Loss = 0.163300, Accuracy = 0.9474\n",
      "    Update 1 - Loss = 0.091790, Accuracy = 0.9789\n",
      "    Update 2 - Loss = 0.041981, Accuracy = 0.9789\n",
      "    Update 3 - Loss = 0.016656, Accuracy = 0.9895\n",
      "    Update 4 - Loss = 0.005391, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.013136, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.022156, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.015039, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.007516, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.003966, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.002682, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.002289, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.002231, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.002319, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.002486, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.002662, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.002753, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.002641, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.002353, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.002013, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001706, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001478, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001322, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001223, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.001164, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.001128, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.001100, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.001071, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.001039, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.001002, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000958, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000910, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000859, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000807, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000755, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000706, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000662, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000623, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000588, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000558, Accuracy = 1.0\n",
      "Epoch 19/19 - Number of Labeled Data: 100\n",
      "    Update 0 - Loss = 0.064089, Accuracy = 0.97\n",
      "    Update 1 - Loss = 0.023088, Accuracy = 1.0\n",
      "    Update 2 - Loss = 0.009550, Accuracy = 1.0\n",
      "    Update 3 - Loss = 0.006902, Accuracy = 1.0\n",
      "    Update 4 - Loss = 0.010047, Accuracy = 1.0\n",
      "    Update 5 - Loss = 0.012101, Accuracy = 1.0\n",
      "    Update 6 - Loss = 0.008642, Accuracy = 1.0\n",
      "    Update 7 - Loss = 0.006061, Accuracy = 1.0\n",
      "    Update 8 - Loss = 0.004366, Accuracy = 1.0\n",
      "    Update 9 - Loss = 0.003309, Accuracy = 1.0\n",
      "    Update 10 - Loss = 0.002666, Accuracy = 1.0\n",
      "    Update 11 - Loss = 0.002239, Accuracy = 1.0\n",
      "    Update 12 - Loss = 0.001947, Accuracy = 1.0\n",
      "    Update 13 - Loss = 0.001756, Accuracy = 1.0\n",
      "    Update 14 - Loss = 0.001676, Accuracy = 1.0\n",
      "    Update 15 - Loss = 0.001670, Accuracy = 1.0\n",
      "    Update 16 - Loss = 0.001710, Accuracy = 1.0\n",
      "    Update 17 - Loss = 0.001743, Accuracy = 1.0\n",
      "    Update 18 - Loss = 0.001722, Accuracy = 1.0\n",
      "    Update 19 - Loss = 0.001635, Accuracy = 1.0\n",
      "    Update 20 - Loss = 0.001498, Accuracy = 1.0\n",
      "    Update 21 - Loss = 0.001342, Accuracy = 1.0\n",
      "    Update 22 - Loss = 0.001189, Accuracy = 1.0\n",
      "    Update 23 - Loss = 0.001053, Accuracy = 1.0\n",
      "    Update 24 - Loss = 0.000939, Accuracy = 1.0\n",
      "    Update 25 - Loss = 0.000845, Accuracy = 1.0\n",
      "    Update 26 - Loss = 0.000769, Accuracy = 1.0\n",
      "    Update 27 - Loss = 0.000707, Accuracy = 1.0\n",
      "    Update 28 - Loss = 0.000656, Accuracy = 1.0\n",
      "    Update 29 - Loss = 0.000613, Accuracy = 1.0\n",
      "    Update 30 - Loss = 0.000573, Accuracy = 1.0\n",
      "    Update 31 - Loss = 0.000537, Accuracy = 1.0\n",
      "    Update 32 - Loss = 0.000505, Accuracy = 1.0\n",
      "    Update 33 - Loss = 0.000476, Accuracy = 1.0\n",
      "    Update 34 - Loss = 0.000450, Accuracy = 1.0\n",
      "    Update 35 - Loss = 0.000427, Accuracy = 1.0\n",
      "    Update 36 - Loss = 0.000408, Accuracy = 1.0\n",
      "    Update 37 - Loss = 0.000391, Accuracy = 1.0\n",
      "    Update 38 - Loss = 0.000376, Accuracy = 1.0\n",
      "    Update 39 - Loss = 0.000362, Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "max_train_subset_size  = 100\n",
    "n_new_labels_per_epoch = 5\n",
    "n_updates_per_epoch    = 40\n",
    "lr                     = 2e-2\n",
    "weight_decay           = 0\n",
    "epsilon                = 0.05\n",
    "\n",
    "laplace_noise = dists.Laplace(torch.zeros([], dtype=torch.float), torch.tensor(1 / epsilon, dtype=torch.float))\n",
    "\n",
    "init_subset_size = n_new_labels_per_epoch + (max_train_subset_size % n_new_labels_per_epoch)\n",
    "n_total_epochs   = max_train_subset_size // n_new_labels_per_epoch\n",
    "\n",
    "student_unlabeled_dataset    = data.Subset(mnist_testset, list(student_dataset.indices))\n",
    "student_unlabeled_dataloader = data.DataLoader(student_unlabeled_dataset, batch_size=1024, shuffle=False, drop_last=False)\n",
    "student_labeled_dataset      = data.Subset(mnist_testset, [])\n",
    "student_labeled_dataloader   = data.DataLoader(student_labeled_dataset,\n",
    "                                               batch_sampler=data.BatchSampler(data.SequentialSampler(student_unlabeled_dataset), init_subset_size, True))\n",
    "\n",
    "student_optimizer            = optim.Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion                    = nn.CrossEntropyLoss()\n",
    "\n",
    "student.train()\n",
    "\n",
    "teacher_preds = []\n",
    "noisy_labels  = []\n",
    "student_train_history = {'n_labels': {}, 'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_total_epochs):\n",
    "    if i_epoch == 0:\n",
    "        new_label_indices = random.sample(student_unlabeled_dataset.indices, init_subset_size)\n",
    "\n",
    "    else:\n",
    "        max_probs_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in student_unlabeled_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "\n",
    "                outs  = student(imgs)\n",
    "                probs = outs.softmax(dim=1)\n",
    "\n",
    "                max_probs_list.append(probs.max(dim=1)[0].cpu())\n",
    "\n",
    "        max_probs_tensor = torch.cat(max_probs_list, dim=0)\n",
    "        \n",
    "        new_label_indices = [student_unlabeled_dataset.indices[idx] for idx in\n",
    "                             max_probs_tensor.topk(n_new_labels_per_epoch, largest=False, sorted=False)[1]]\n",
    "\n",
    "    for idx in new_label_indices:\n",
    "        student_labeled_dataset.indices.append(idx)\n",
    "        student_unlabeled_dataset.indices.remove(idx)\n",
    "        label_pred_counts = aggregate_counts(mnist_testset[idx][0].view(1, 1, 28, 28))\n",
    "        noisy_label = (label_pred_counts.float() + laplace_noise.sample(label_pred_counts.size())).argmax(dim=0)\n",
    "        mnist_testset.targets[idx] = noisy_label\n",
    "        teacher_preds.append(label_pred_counts)\n",
    "        noisy_labels.append(noisy_label)\n",
    "        \n",
    "    student_labeled_dataloader.batch_sampler.batch_size = len(student_labeled_dataset)\n",
    "    \n",
    "    print(\"Epoch {:d}/{:d} - Number of Labeled Data: {:d}\".format(i_epoch, n_total_epochs-1, len(student_labeled_dataset)))\n",
    "\n",
    "    student_train_history['n_labels'][i_epoch] = init_subset_size + (i_epoch * n_new_labels_per_epoch)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i_update in range(n_updates_per_epoch):\n",
    "        imgs, labels = next(iter(student_labeled_dataloader))\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = student(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(\"    Update {:d} - Loss = {:.6f}, Accuracy = {:.4}\".format(i_update, loss.item(), accuracy))\n",
    "\n",
    "    student_train_history['avg_losses'][i_epoch]     = losses\n",
    "    student_train_history['avg_accuracies'][i_epoch] = accuracies\n",
    "\n",
    "teacher_preds = torch.stack(teacher_preds, dim=1)\n",
    "noisy_labels  = torch.tensor(noisy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:09:43.833442Z",
     "start_time": "2019-06-23T13:09:43.477835Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/33\n",
      "Average Loss: 1.3769125180244446\n",
      "Average Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "student.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "n_batches = len(test_dataloader)\n",
    "for i, (imgs, labels) in enumerate(test_dataloader):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs   = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = student(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:09:49.911416Z",
     "start_time": "2019-06-23T13:09:43.835427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 5.302585092994046\n",
      "Data Dependent Epsilon: 5.30258509299405\n"
     ]
    }
   ],
   "source": [
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds, noisy_labels, epsilon)\n",
    "print(\"Data Independent Epsilon:\", data_indep_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Labels Using Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T13:04:10.946546Z",
     "start_time": "2019-06-22T13:03:49.746547Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/17 - Teacher 249/249\n",
      "tensor([[7, 0, 1,  ..., 6, 9, 0],\n",
      "        [7, 0, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        ...,\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 2, 1,  ..., 6, 9, 0],\n",
      "        [7, 0, 1,  ..., 6, 9, 0]])\n"
     ]
    }
   ],
   "source": [
    "for model in teachers:\n",
    "    model.eval()\n",
    "\n",
    "dataloader = data.DataLoader(student_dataset, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "batches_of_preds = []\n",
    "\n",
    "n_batches = len(dataloader)\n",
    "_prev_str_len = 0\n",
    "for i, (imgs, _) in enumerate(dataloader):\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    batch_of_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(teachers):\n",
    "            _progress_str = \"Batch {:d}/{:d} - Teacher {:d}/{:d}\".format(i, n_batches-1, j, n_teachers-1)\n",
    "            print(_progress_str + ' ' * (_prev_str_len - len(_progress_str)), end='\\r')\n",
    "            _prev_str_len = len(_progress_str)\n",
    "\n",
    "            outs  = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            batch_of_preds.append(preds.cpu())\n",
    "    \n",
    "    batches_of_preds.append(batch_of_preds)\n",
    "        \n",
    "label_preds = torch.cat(\n",
    "    [torch.stack([preds for preds in batch_of_preds], dim=0)\n",
    "     for batch_of_preds in batches_of_preds],\n",
    "    dim=1)\n",
    "\n",
    "print()\n",
    "print(label_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T16:40:06.332084Z",
     "start_time": "2019-06-20T16:40:06.325637Z"
    }
   },
   "source": [
    "### Get Label Counts for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T13:04:11.005107Z",
     "start_time": "2019-06-22T13:04:10.948032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   4,   0,  ...,   0,   1, 232],\n",
      "        [  0,   5, 248,  ...,   0,   0,   0],\n",
      "        [  0, 213,   1,  ...,   0,   1,   7],\n",
      "        ...,\n",
      "        [248,   0,   0,  ...,   0,  26,   0],\n",
      "        [  0,   7,   0,  ...,   0,   8,   0],\n",
      "        [  0,   0,   0,  ...,   0, 192,   0]])\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.from_numpy(np.apply_along_axis(lambda x: np.bincount(x, minlength=10), axis=0, arr=label_preds.numpy()))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Labels from Noisy Counts with a Certain $\\epsilon$ Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:37:11.761761Z",
     "start_time": "2019-06-21T13:37:11.745428Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 6, 9, 0])\n",
      "\n",
      "Noisy Accuracy Against Predictions: 0.9427777528762817\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "\n",
    "noise_dist = dists.Laplace(loc=torch.zeros([], dtype=torch.float),\n",
    "                           scale=torch.full([], 1 / epsilon, dtype=torch.float))\n",
    "\n",
    "noisy_counts = label_counts.float() + noise_dist.sample([10, label_counts.size(1)])\n",
    "\n",
    "generated_labels = noisy_counts.argmax(dim=0)\n",
    "print(generated_labels)\n",
    "print()\n",
    "print(\"Noisy Accuracy Against Predictions:\", (generated_labels == label_counts.argmax(dim=0)).float().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PATE Analysis to Check Information Leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:41:50.200151Z",
     "start_time": "2019-06-21T13:41:07.951830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.30258509299405, 5.302585092994046)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pate.perform_analysis(label_preds[:, :100], generated_labels[:100], epsilon, delta=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the Generated Labels to the DP Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset.targets[dp_dataset.indices] = generated_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the DP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "lr       = 3e-3\n",
    "n_epochs = 10\n",
    "\n",
    "dp_optimizer = optim.Adam(dp_model.parameters(), lr=lr)\n",
    "criterion    = nn.CrossEntropyLoss()\n",
    "\n",
    "dp_model.train()\n",
    "\n",
    "dp_train_history = {'avg_losses':{}, 'avg_accuracies': {}}\n",
    "for i_epoch in range(n_epochs):\n",
    "    instance_count = 0\n",
    "    total_loss     = 0.\n",
    "    correct_count  = 0.\n",
    "\n",
    "    n_batches = len(dp_dataloader)\n",
    "    _prev_str_len = 0\n",
    "    for i, (imgs, labels) in enumerate(dp_dataloader):\n",
    "        _batch_str = \"Epoch {:d}/{:d}: ({:d}/{:d})\".format(i_epoch, n_epochs-1, i, n_batches-1)\n",
    "        print(_batch_str + ' ' * (_prev_str_len - len(_batch_str)), end='\\r')\n",
    "        _prev_str_len = len(_batch_str)\n",
    "\n",
    "        instance_count += imgs.size(0)\n",
    "\n",
    "        imgs   = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs  = dp_model(imgs)\n",
    "        preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "        dp_optimizer.zero_grad()\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        dp_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        correct_count += (preds == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / instance_count\n",
    "    avg_accuracy = correct_count / instance_count\n",
    "\n",
    "    print()\n",
    "    print(\"    Avg Loss: {:.6f}\".format(avg_loss))\n",
    "    print(\"    Avg Accuracy: {:.4f}\".format(avg_accuracy))\n",
    "    print()\n",
    "\n",
    "    dp_train_history['avg_losses'][i_epoch]     = avg_loss\n",
    "    dp_train_history['avg_accuracies'][i_epoch] = avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Result Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "dp_model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "instance_count = 0\n",
    "total_loss     = 0.\n",
    "correct_count  = 0.\n",
    "# test_dataloader     = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "n_batches = len(dataloader)\n",
    "for i, (imgs, labels) in enumerate(data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)):\n",
    "    print(\"Batch {:d}/{:d}\".format(i, n_batches-1), end='\\r')\n",
    "\n",
    "    instance_count += imgs.size(0)\n",
    "    \n",
    "    imgs = imgs.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs  = model(imgs)\n",
    "    \n",
    "    total_loss += criterion(outs, labels).item()\n",
    "\n",
    "    preds = outs.argmax(dim=1)\n",
    "    \n",
    "    correct_count += (preds == labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(\"Average Loss:\", total_loss / instance_count)\n",
    "print(\"Average Accuracy:\", correct_count / instance_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "    1. Split the training dataset into `n + 1` smaller datasets where `n` is the number of teacher models\n",
    "    2. Define a Dataset class and a DataLoader that can give batches of data for all `n` teacher datasets\n",
    "2. Define Model(s)\n",
    "    1. A simple ConvNet for both the main model and all teacher models\n",
    "    2. If too slow: custom `nn.Module` that can process `n` batches at once for all `n` teachers\n",
    "3. Train Teachers\n",
    "4. Label Unlabeled Training Dataset in a Differentially Private Manner\n",
    "    1. Generate raw labels\n",
    "    2. PATE analysis to find a proper `epsilon` value\n",
    "    3. Add proper noise to the label counts\n",
    "    4. Take the labels with most counts\n",
    "5. Train the Main Model On the Training Dataset with Generated Labels\n",
    "6. Test on the Test Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
